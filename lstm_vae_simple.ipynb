{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Lakes' model on a single dataset with linear decoder"
      ],
      "metadata": {
        "id": "sf946hpvhCfS"
      },
      "id": "sf946hpvhCfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mLxnQ-qHr",
        "outputId": "38cd6756-330d-44c5-f035-fca0ec751902"
      },
      "id": "3i2mLxnQ-qHr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install Bio --quiet\n",
        "!pip install keras==3.0.0 --upgrade --quiet"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.275033900Z",
          "start_time": "2023-10-29T05:21:04.751989100Z"
        },
        "id": "1373a93c978d2fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7da2066-77fd-43b7-fd4d-aa11336aff98"
      },
      "id": "1373a93c978d2fb5"
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import keras\n",
        "from keras import backend as K, layers, activations\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "SQQNsD3Dfz7z"
      },
      "id": "SQQNsD3Dfz7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nphKeyspBbHX",
        "outputId": "40b34c7b-7461-4548-9d74-511e2421445a"
      },
      "id": "nphKeyspBbHX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9Mcj8HqXRo",
        "outputId": "dbeba010-d424-465c-a334-811e7fe258aa"
      },
      "id": "vR9Mcj8HqXRo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "nTavCEWq6jXX"
      },
      "id": "nTavCEWq6jXX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "du6GuldEgp52"
      },
      "id": "du6GuldEgp52"
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "folder_path = 'drive/MyDrive/ae_training'\n",
        "file_name1 = f'{folder_path}/card1_1273x130.fasta'\n",
        "file_name2 = f'{folder_path}/drsm1_1376x177.fasta'\n",
        "file_name3 = f'{folder_path}/rd1_935x221.fasta'\n",
        "file_name4 = f'{folder_path}/drsm3_718x103_testing.fasta'\n",
        "\n",
        "amino_acids_str = ' ACDEFGHIKLMNPQRSTVWY-'\n",
        "amino_acids = [' ', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "               'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
        "\n",
        "onehot_encoder = OneHotEncoder(categories=[amino_acids])\n",
        "onehot_encoder.fit(np.array(list(amino_acids_str)).reshape(-1, 1))\n",
        "\n",
        "# Hyperparameters\n",
        "max_len = 221\n",
        "num_epochs = 30\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "5Yjt2lUQwFGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac96d2b-4a0f-49a7-e16a-66b8604408f2"
      },
      "id": "5Yjt2lUQwFGV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def parse_fasta(file_path) -> list:\n",
        "    \"Parse a fasta file into an array of Seq\"\n",
        "    sequences = []\n",
        "    with open(file_path, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(record.seq)\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def integer_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of integers\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    encoding = [amino_acids.index(aa) for aa in sequence]\n",
        "    # Pad the sequence to the specified maximum length\n",
        "    if len(encoding) < max_length:\n",
        "        encoding += [0] * (max_length - len(encoding))\n",
        "    return torch.tensor(encoding).reshape(-1, 1)\n",
        "\n",
        "\n",
        "def integer_decode(int_seq) -> str:\n",
        "    \"Decode an integer encoded sequence back to a sequence of amino acids\"\n",
        "    # Convert the torch tensor to a list of integers\n",
        "    encoded_list = int_seq.flatten().tolist()\n",
        "    # Decode each integer back to the corresponding amino acid\n",
        "    decoded_sequence = ''.join([amino_acids[i] for i in encoded_list])\n",
        "    return decoded_sequence\n",
        "\n",
        "\n",
        "def onehot_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of one-hot vectors\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    # Pad the sequence with whitespaces\n",
        "    padding = ' ' * (max_length - len(sequence))\n",
        "    sequence += padding\n",
        "    protein_sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
        "    one_hot_encoded_sequence = onehot_encoder.transform(protein_sequence_array)\n",
        "    one_hot_encoded_array = one_hot_encoded_sequence.toarray()\n",
        "    return torch.tensor(one_hot_encoded_array)  # Whitespace is [1,0,...,0] for now\n",
        "\n",
        "\n",
        "def onehot_decode(onehot_seq: torch.tensor) -> str:\n",
        "    \"Decode a one-hot encoded sequence back to a sequence of amino acids\"\n",
        "    original_seq = onehot_encoder.inverse_transform(onehot_seq)\n",
        "    s = [''.join(c) for c in original_seq]\n",
        "    return ''.join(s)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.319409200Z",
          "start_time": "2023-10-29T05:21:08.296000400Z"
        },
        "id": "2525961040f75438"
      },
      "id": "2525961040f75438"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:09.164320800Z",
          "start_time": "2023-10-29T05:21:08.311283200Z"
        },
        "id": "55bb307a28da7571",
        "outputId": "de13fba2-6ec8-41b1-dba9-aaeedb1e0538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55bb307a28da7571"
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]  # onehot encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIVmYtGNyIf",
        "outputId": "910588a0-54f9-4700-be6f-94da87b2127a"
      },
      "id": "NaIVmYtGNyIf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        ...,\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yfhfB6K4PVIq",
        "outputId": "b03e9d86-175c-45b4-a41f-58f29cbab907"
      },
      "id": "yfhfB6K4PVIq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "int_encoded_sequences = [integer_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(int_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPM4Fsb3HDIO",
        "outputId": "c92dd5d8-cbc4-40c7-d928-be9e53ad6afe"
      },
      "id": "IPM4Fsb3HDIO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integer_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "woxfrJVxY9Va",
        "outputId": "4dcec0c2-e0fb-4980-e19d-a0d518db5abe"
      },
      "id": "woxfrJVxY9Va",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequences1 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "# sequences2 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "sequences3 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "\n",
        "# data = torch.cat((sequences1, sequences2, sequences3))\n",
        "data = torch.cat((sequences3,))\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPbKvpm_iShN",
        "outputId": "bf045184-6b2a-47e1-9cb8-ff3f2bbbe04b"
      },
      "id": "vPbKvpm_iShN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([935, 221, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataloaders"
      ],
      "metadata": {
        "id": "ruWPTFpWgiKO"
      },
      "id": "ruWPTFpWgiKO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the training dataset as in PyTorch `DataLoader`.\n",
        "\n",
        "Ideally, the model (as `keras.Model`) should be instantiated as a PyTorch `Module` in PyTorch backend."
      ],
      "metadata": {
        "id": "o8_fLUlbjbEn"
      },
      "id": "o8_fLUlbjbEn"
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.encoding = onehot_encode\n",
        "\n",
        "        # sequences1 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "        # sequences2 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "        sequences3 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "        # self.data = torch.cat((sequences1, sequences2, sequences3))\n",
        "        self.data = torch.cat((sequences3,))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # self.data = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name4)])[:,:,1:]\n",
        "        self.data = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "ShVn_fXNTFy1"
      },
      "id": "ShVn_fXNTFy1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch Datasets\n",
        "train_dataset = TrainDataset()\n",
        "val_dataset = TestDataset()\n",
        "\n",
        "# Create DataLoaders for the Datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c-3Hl4NElUe4"
      },
      "id": "c-3Hl4NElUe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the LSTM Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "ItsoiY3OY1Ve"
      },
      "id": "ItsoiY3OY1Ve"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rewrite the code to build the model: **Protein sequence LSTM Variational AutoEncoder (VAE)**\n",
        "\n",
        "Write it in Keras 3 as subclass of `keras.Model` to handle variable length sequences (and missing characters).\n",
        "\n",
        "Sources:\n",
        "- VAE in Keras 3: https://keras.io/examples/generative/vae/\n",
        "- LSTM Autoencoder: https://machinelearningmastery.com/lstm-autoencoders/\n",
        "- Variable length: https://machinelearningmastery.com/handle-missing-timesteps-sequence-prediction-problems-python/\n"
      ],
      "metadata": {
        "id": "4AKZbyCahwZ6"
      },
      "id": "4AKZbyCahwZ6"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KZcoro0Zu9-A"
      },
      "id": "KZcoro0Zu9-A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling layer"
      ],
      "metadata": {
        "id": "AZq4z0JnvBa2"
      },
      "id": "AZq4z0JnvBa2"
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"Uses (z_mean, z_log_var) to sample z, the vector encoding a sequence.\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = keras.ops.shape(z_mean)[0]\n",
        "        dim = keras.ops.shape(z_mean)[1]\n",
        "        epsilon = keras.random.normal(shape=(batch, dim))\n",
        "        return z_mean + keras.ops.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "F2UKmYnRqiW0"
      },
      "id": "F2UKmYnRqiW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "K-OeJWfDvX-t"
      },
      "id": "K-OeJWfDvX-t"
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64\n",
        "# input_shape = (max_len, 1)  # (max_len, 1) for integer encoding\n",
        "input_shape = (max_len, 21)  # (max_len, 21) for one-hot encoding\n",
        "\n",
        "encoder_inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Masking(mask_value=0.0)(encoder_inputs)\n",
        "z_mean = layers.LSTM(latent_dim, activation='relu',\n",
        "                     input_shape=input_shape, name=\"z_mean\")(x)\n",
        "z_log_var = layers.LSTM(latent_dim, activation='relu',\n",
        "                        input_shape=input_shape, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "wwthT3fRvcoK",
        "outputId": "d42f57c7-ac34-48cd-daa9-57530b8e7dcd"
      },
      "id": "wwthT3fRvcoK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (\u001b[38;5;33mAny\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mLSTM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (\u001b[38;5;33mSampling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n",
              "│                           │                        │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n",
              "│                           │                        │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "KRsFMEjV2cwN"
      },
      "id": "KRsFMEjV2cwN"
    },
    {
      "cell_type": "code",
      "source": [
        "# latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "# x = layers.RepeatVector(max_len)(latent_inputs)\n",
        "# x = layers.LSTM(latent_dim, activation='relu', return_sequences=True)(x)\n",
        "# x = layers.TimeDistributed(layers.Dense(21))(x)\n",
        "# decoder_outputs = layers.Softmax()(x)\n",
        "# decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "# decoder.summary()\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128)(latent_inputs)\n",
        "x = layers.Dense(221)(x)\n",
        "x = layers.Dense(221 * 21)(x)\n",
        "x = layers.Reshape((221, 21))(x)\n",
        "decoder_outputs = layers.Softmax()(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "RyVG3dRg2ejP",
        "outputId": "04be3059-ac7b-4093-c3ca-2a5ae575f3ec"
      },
      "id": "RyVG3dRg2ejP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │       \u001b[38;5;34m8,320\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m)                   │      \u001b[38;5;34m28,509\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4641\u001b[0m)                  │   \u001b[38;5;34m1,030,302\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>)                   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">28,509</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4641</span>)                  │   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,030,302</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,067,131\u001b[0m (4.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,131</span> (4.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,067,131\u001b[0m (4.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,131</span> (4.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Model"
      ],
      "metadata": {
        "id": "hFntz4ZJ5trY"
      },
      "id": "hFntz4ZJ5trY"
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]"
      ],
      "metadata": {
        "id": "mob3gBeT5BMS"
      },
      "id": "mob3gBeT5BMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LJ67OFHcMxia"
      },
      "id": "LJ67OFHcMxia"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder, decoder).to(device)\n",
        "model.load_weights(f'{folder_path}/vae-simple.weights.h5', skip_mismatch=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    for i, x in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        x = x.to(device)\n",
        "        z_mean, z_log_var, z = model.encoder(x)\n",
        "        reconstruction = model.decoder(z)\n",
        "\n",
        "        # Compute reconstruction loss and kl divergence\n",
        "        # x = activations.sigmoid(x / 4)\n",
        "        # reconstruction = activations.sigmoid(reconstruction / 4)\n",
        "        # print(reconstruction)\n",
        "\n",
        "        reconstruction_loss = keras.ops.mean(\n",
        "            keras.ops.sum(\n",
        "                keras.losses.binary_crossentropy(x, reconstruction),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "        kl_loss = -0.5 * (1 + z_log_var - keras.ops.square(z_mean) - keras.ops.exp(z_log_var))\n",
        "        kl_loss = keras.ops.mean(keras.ops.sum(kl_loss, axis=1))\n",
        "\n",
        "        # Backprop and optimize\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_dataloader), reconstruction_loss.item(), kl_loss.item()))\n",
        "\n",
        "model.save_weights(f'{folder_path}/vae-simple.weights.h5', overwrite=True)"
      ],
      "metadata": {
        "id": "yu-aFtsi_aR8"
      },
      "id": "yu-aFtsi_aR8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "BbcsXjoPfyZl"
      },
      "id": "BbcsXjoPfyZl"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder, decoder).to(device)\n",
        "model.load_weights(f'{folder_path}/vae-simple.weights.h5', skip_mismatch=False)"
      ],
      "metadata": {
        "id": "CcJBt_aNhlEG"
      },
      "id": "CcJBt_aNhlEG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for i, x in enumerate(val_dataloader):\n",
        "        x = x.to(device)\n",
        "        z_mean, z_log_var, z = model.encoder(x)\n",
        "        reconstruction = model.decoder(z)\n",
        "\n",
        "        reconstruction_loss = keras.ops.mean(\n",
        "            keras.ops.sum(\n",
        "                keras.losses.binary_crossentropy(x, reconstruction),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print (\"Step [{}/{}], Reconst Loss: {:.4f}\"\n",
        "                .format(i+1, len(val_dataloader), reconstruction_loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7D6GrP3f4go",
        "outputId": "fb411f3b-b6df-4d61-b5ad-e7a6ba072737"
      },
      "id": "S7D6GrP3f4go",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [1/8], Reconst Loss: 19.7697\n",
            "Step [2/8], Reconst Loss: 12.9240\n",
            "Step [3/8], Reconst Loss: 14.2191\n",
            "Step [4/8], Reconst Loss: 11.9006\n",
            "Step [5/8], Reconst Loss: 14.1742\n",
            "Step [6/8], Reconst Loss: 11.6779\n",
            "Step [7/8], Reconst Loss: 10.4778\n",
            "Step [8/8], Reconst Loss: 11.4295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name3)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWiuSxtzhC61",
        "outputId": "5b3c0c19-0d0d-4d6a-c149-64a989eb875c"
      },
      "id": "DWiuSxtzhC61",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([935, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSeecvE9i8jX",
        "outputId": "4d71e60c-c1bc-4faf-bdac-aa17fd43dfa8"
      },
      "id": "BSeecvE9i8jX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin = onehot_decode(data[0])\n",
        "origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UdwK0OMRjC_l",
        "outputId": "f6617400-ee9c-47c2-c332-380c631f999b"
      },
      "id": "UdwK0OMRjC_l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-FANSLYKLNCVG-CSTTFCMSSD-I-K-KVYS---NYMAFDPAAW-------------------------------------QFFTV--ESK--KKKPNSYLSEDT--Q--PLSIL--KC-----A-K--C--VTTVIGKA---YKMRGVY------LPQIDVKSVFFVEE----NS-SE----------------SKT--AKKWSSVEQELFYV-GEA-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[0][:,1:].reshape(1, 221, 21)\n",
        "z_mean, z_log_var, z = model.encoder(x)\n",
        "reconst = model.decoder(z_mean)\n",
        "reconst.reshape(221, 21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p6eYc1XjZuD",
        "outputId": "4261f39d-29f9-4240-a4e1-1ee87583c289"
      },
      "id": "_p6eYc1XjZuD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3024e-06, 1.2420e-06, 1.1734e-06,  ..., 1.0581e-06, 9.6972e-07,\n",
              "         9.9934e-01],\n",
              "        [6.3325e-03, 8.3627e-07, 6.2426e-02,  ..., 8.7345e-04, 1.5985e-02,\n",
              "         2.9862e-01],\n",
              "        [1.3382e-02, 8.1546e-04, 1.0301e-01,  ..., 8.7649e-07, 1.7583e-03,\n",
              "         2.8733e-01],\n",
              "        ...,\n",
              "        [5.6290e-02, 8.3085e-07, 3.0076e-01,  ..., 8.6538e-07, 9.2334e-07,\n",
              "         4.5644e-02],\n",
              "        [5.0494e-03, 6.4836e-07, 6.7131e-07,  ..., 6.6579e-07, 2.5962e-03,\n",
              "         4.4311e-02],\n",
              "        [7.2389e-07, 6.5524e-07, 6.7681e-07,  ..., 5.7198e-07, 6.6830e-07,\n",
              "         9.9426e-01]], device='cuda:0', grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconst.cpu().detach().numpy()\n",
        "reconst = keras.utils.to_categorical(np.argmax(reconst.cpu().detach().numpy(), axis=2), 21)\n",
        "reconst = reconst.reshape(221, 21)\n",
        "reconst = np.hstack((np.zeros((reconst.shape[0], 1)), reconst))\n",
        "reconst = onehot_decode(reconst)"
      ],
      "metadata": {
        "id": "DEin5btHlP7_"
      },
      "id": "DEin5btHlP7_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "A8bUqDH45xM1",
        "outputId": "83d42348-7088-4a15-8a38-952b97570a24"
      },
      "id": "A8bUqDH45xM1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'--NPSLVKLLCKN-CKVLVCSGSD-I-R-VIEGM--HHVNVNPAFK-------------------------------------ELYIV--REN--KPLQKKF--ADY--E--PNGEI--IC-----K-N--C-------GQD---WGIMMVY-KGLD-LPCLKIKN-FVVET----PT--G---------------KKQY---KKWKEVP---FTF-PDF-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}