{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSfQlfz5Igv7","executionInfo":{"status":"ok","timestamp":1711050267958,"user_tz":300,"elapsed":24888,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"b958e127-3780-4ec6-8dd1-cad82656ce3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/vae-asr\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/Shareddrives/vae-asr/"]},{"cell_type":"code","source":["import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import sys\n","sys.path.append('/content/drive/Shareddrives/vae-asr/modules')\n","from model import VAE\n","# help(VAE)\n","from data import MSA_Dataset\n","# help(MSA_Dataset)"],"metadata":{"id":"R-GOwm_6UzX5","executionInfo":{"status":"ok","timestamp":1711050277056,"user_tz":300,"elapsed":7361,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Run script to pre-process the VAE"],"metadata":{"id":"Vi44uGh0NNp6"}},{"cell_type":"markdown","source":["Query sequence for PF00565_full: SND1_HUMAN/552-660\n","\n","Query sequence for PF00041_full: TENA_HUMAN/804-884 (this is the same choice as original paper: https://github.com/BrooksResearchGroup-UM/PEVAE_Paper/blob/master/pfam_msa/script/proc_msa.py)\n","\n","Query sequence for PF00067_full: A0A8J5V3X2_ZIZPA/310-424 (chosen for its sparsity so that eliminating sequences that have too many gaps where the query sequence has a letter does not result in very few remaining sequences)\n","\n"],"metadata":{"id":"0PQ7HpcrYFeY"}},{"cell_type":"code","source":["MSA_id = \"PF00067_full\"\n","query_seq_id = \"A0A8J5V3X2_ZIZPA/310-424\""],"metadata":{"id":"EN-zbfv3ZxON","executionInfo":{"status":"ok","timestamp":1711050279808,"user_tz":300,"elapsed":4,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# !grep {query_seq_id} data/pevae_real/{MSA_id}.txt"],"metadata":{"id":"VxrahoStZ1G-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The script writes the processed MSA objects as `.pkl` files in the `output/` directory."],"metadata":{"id":"EMYnCbwMQKJz"}},{"cell_type":"code","source":["! python scripts/proc_msa.py data/pevae_real/{MSA_id}.txt {query_seq_id}"],"metadata":{"id":"7BKMaf8SMwZz","executionInfo":{"status":"ok","timestamp":1711043632794,"user_tz":240,"elapsed":16994,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"765099c4-f966-418e-aeb3-a9417d394228"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# of sequences in raw MSA: 17984\n"]}]},{"cell_type":"markdown","source":["Check resulting processed MSA"],"metadata":{"id":"qucqkBzF7l7b"}},{"cell_type":"code","source":["#Number of sequences\n","! wc -l ./output/{MSA_id}/seq_msa_char.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDNoCErd8fyY","executionInfo":{"status":"ok","timestamp":1711045024307,"user_tz":240,"elapsed":228,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"21b42699-d390-4f04-8e0f-84f7a298a1cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9767 ./output/PF00067_full/seq_msa_char.txt\n"]}]},{"cell_type":"code","source":["#First few sequences\n","!head -n 25 ./output/PF00067_full/seq_msa_char.txt | awk '{print $2}'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZmW-JGv6uGN","executionInfo":{"status":"ok","timestamp":1711050286606,"user_tz":300,"elapsed":2008,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"3e37d1e0-7337-4188-b3c7-257d133609e8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["RVHKEIDEVIGPDRPPMMEDRVKMPYTDAVVHEVQRSMDLAPAVPHKVMRDTEFHNYHIPEGTLVLPLISSVLADPQLWKNPNHFDPENFLDDAGHFQKNDAYECY.\n","KILQEIKTNLPRTSDSMQYYLNKLVYLRGALYEAMRLYPPVPERMSPI.NPDKLPSHKVDASMKILIFIYALGRMEAVWEDALEFKPERWVSKTGIEEPSYKRMKHG\n","KAQEEIRASLGTKGKVEEEDLHQLQYLKSVVKETWRLHSPAPLLPRESVRHSRIHGYDILPNTRVYVNAWGIAKDPKSWDDPEEFIPERFMDGPIDYGHNFELHLV.\n","KVKKELTDVVGLDRTVEEFHLPNLRYLNAVIKETFRLHPALPLVPRCSGKSITVGGYTIPKGSRVFLNIWSIHRDPHIWDNPLQFQPDRFLNDPDDYGSDFRLLI..\n","KAVDELDMVVGKERLVEESDIHSLTYLKACIREAFRIHPYHPNPSHVAIADITIAGFMIPKGSHIILSRIGLGRNPRAWDNPLEFRPERHLKNTNLVEPELRLLMQA\n","RLASEIRSTFSSRCIRAGHELHNCKYLRAVIDETMRMSPSSLPAWRS.QDVFTVDGHVIPPGTQVGSSRYAVQHNEAFFPEPFKFQPERWLSSEDARAMRRAAGNLG\n","RCREEVQMLLREREEIEWEDLSQLPFLTMCIKESLRLHPPVTVISRCTTQDVVLPDRVIPKGNICTISIFGIHHNPSVWPEPEVYNPFRFDPETPQKRSPLARAEEG\n","KLSLELERAELSGAVVSSEQAQNLAYLRACIREALRFAPTVSQLPRLAPRDTELHGEHVPPGYSVSTSPWVLGRSERLYPDAHVYRPERWLEAAEEQYWDRNAEVRS\n","RLAAEVDSARRQSTIIPADLCDRLPFLDAVVKETLRLYAPIPSQPRTSTRDMTVDGHLIPAGTVVSCQAYSLHRNPDVFRHPYKFNPDRWLAGDAEVEMRRWPTATS\n","KARSEINHNVQG.RLLDDSDLAKLPYLHCIINETLRMHPAAPLVPHSSSKECTVGGYTVPRETVLYANIGAIHRDPKVWIDPDKFMPERFEGVQSEKEMGFKPLIAM\n","RCREEIQSLLGDGTSIAWDHLGQMPYTTMCIKEALRLYPPVPAIVREFSKPITFSDRSLPAGIVLSLSFYGLHHNPKVWPNPEVFDPSRFAPGSA..QHSHALH...\n","KAQAEIDSVIGNDRLPTFADRDQLPYVNAIALEALRWHTVAPGIPHRVMQDDIYNGYFIPKGTLVIANIWQMSHDPAVYPDPMVFKPERYLGKEP..QMDPSSKFRC\n","KLYKEISSVCGNGD.VTKEALANMSYLKACVRETMRIYSPTSGSYRRFDKDVVVGGYHIPAGTELVLCFQQMCEDPRFFKSPEKFLPERFMRDDTKNTNPFAKNAVP\n","KLFEECKTVPSD.....LQRLDQMPILHSIVQEACRLHSAIPSEPRYVPQEATLRDVEIPPGTIVSCQPWSLHLLETPFANPRQFNPARWLRDETLTKMNNSQQQTD\n","KVQEELDSVVGRERLLSWTDKQNLPYLDATIQELYRTAALFLTTMYSNFKETTIEGYRIPERSAIVSNLYSIHFDPELFPNPQKFDPGRFLNSEGKRKVEGGYAKDI\n","RIADEVVKATNVKGNITEEALDKMQYLHAALTETLRLYPAVPLDGKFCFSDDTFPDLSIRKGDTISYQPWAMGRMKFIWEDAEDFRPERWLNENGQQESPFKLHVDG\n","RIRDEVVELFPSG.IPDADSLPLLKTLNMVIQEVLRLYPPAAFVSREAYEDIQIGNLNVPKGVCLWTLIPTMNRDPENWPDANEFKPERFSEGLSKAKYPQAYRMII\n","ALHAEITAALGQGSHSSASALSQLPLLKAVLKEVLRLYPVVPGNSRVPDKDIRVGDYIIPKNTLVTLCHYATSRDPAQFPEPNAFRPARWLGE.GPAPHPFAF....\n","EVLDEVDECMGDGVGVDLEGSRRARVLHAALCETMRLYPPVADSKHAVEDDVLPDGTRVGRGDRVTYFPYGMGRMESIWVDAGEFRPGRWLAAAADGVSPFKAPEGS\n","AVKKEFSKISGQDSCPLLDRLQHTPVFDSALEETLRLS.AAPFITREVVQTLHMADYKLRSGDRVCLFPISPQMDPEIHQEPQRFKYDRFLNQEGGRRLKYYLAI..\n","KLYEEIKSKTGGGGEVSEEDVHDMPYLKAVVLEGLRKHPPAHLLPHKAAEDMDVGGYLIPKGTIVNFMVAEMGRDEKEWEKPMEFMPERFLRPCGITNKGIRPLRVR\n","RLTDEIDEMSAVGKRIRYAEAQQLPYLVACCKEGMRMHPSVGTLPRVVPPGCQIAGQWFPGGLRVGVNAAVVHFDKAIFEDADQYNPDRWLREDA.VNMDRYGFRTM\n","KLRDEIQTSKCSER.ITFQESQAMPYLQAVIKEALRVHSAVGPLWRVVPVGAQINGRFFPPGSQVGVNPWVVHYNKDVFPDPASFRPERWIDADENLIMNEMTLNMS\n","RLFAELQAAYPDMKTANVQDLEKLPFLSACIYESLRIAVPVSDLPRVVTGDWHFKGYVIPNGTTVSSNAVAVHFNEQIFPEAHEFKPERWLDAEGRFKLEQWPIGHD\n","EILKEIKGKSGM...PVFEEVKDMVYTHAALCECMRLYPPVPLDGKTAVDDDILPDTVVKKGTAVTYHPYAMGRMEKIWSDWAEFKPERWLQRDEVGRDPYTFQPSL\n"]}]},{"cell_type":"markdown","source":["## Load data and instantiate dataset"],"metadata":{"id":"fmIWSH0HVyn5"}},{"cell_type":"code","source":["## read multiple sequence alignment in binary representation\n","with open(f\"./output/{MSA_id}/seq_msa_binary.pkl\", 'rb') as file_handle:\n","    msa_binary = torch.tensor(pickle.load(file_handle))\n","# Number of sequences\n","n_seq = msa_binary.shape[0]\n","# Dimensions of one-hot encoding\n","nl = msa_binary.shape[1]\n","nc = msa_binary.shape[2]\n","# Print shape\n","msa_binary.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twjfbRCybyvp","executionInfo":{"status":"ok","timestamp":1711050292350,"user_tz":300,"elapsed":3621,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"b6faa758-b861-4bac-a33b-5dabccd2a00e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([9767, 107, 21])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["## each sequence has a label\n","with open(f\"./output/{MSA_id}/keys_list.pkl\", 'rb') as file_handle:\n","    msa_keys = pickle.load(file_handle)\n","msa_keys[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5is5eYwzcS2Z","executionInfo":{"status":"ok","timestamp":1711050294959,"user_tz":300,"elapsed":1402,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"7b3c9db8-ac92-4a28-d4c5-dccf6f21c78f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A0A8C4CNX3_9TELE/41-498',\n"," 'A0A6D2KQW5_9BRAS/30-513',\n"," 'A0A8K0MXP5_COCNU/37-492',\n"," 'A0A6P5YD73_DURZI/55-522',\n"," 'A0A0D3FSJ4_9ORYZ/51-514',\n"," 'A0A2V1DIY2_9PLEO/30-468',\n"," 'A0A8J6AVG1_GALPY/899-1088',\n"," 'A0A168DGB0_CORFA/1-418',\n"," 'A0A8H6P498_9EURO/256-505',\n"," 'A0A7J6X3X1_THATH/28-493']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["## sequences in msa are weighted\n","with open(f\"./output/{MSA_id}/seq_weight.pkl\", 'rb') as file_handle:\n","    seq_weight = pickle.load(file_handle)\n","seq_weight = seq_weight.astype(np.float32)\n","seq_weight[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXklarQlbVpH","executionInfo":{"status":"ok","timestamp":1711050297593,"user_tz":300,"elapsed":1145,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"24284b39-0b15-4ac7-fd1c-fe9795d07028"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.3613485e-04, 2.0739369e-04, 8.0609527e-05, 5.5940869e-05,\n","       1.0388179e-04, 1.8525257e-04, 5.8904512e-05, 1.3547979e-04,\n","       7.5113967e-05, 6.1428691e-05], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["data = MSA_Dataset(msa_binary, seq_weight, msa_keys)\n","# Show a random sample\n","data[100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfNcfuWpf6p1","executionInfo":{"status":"ok","timestamp":1711050299441,"user_tz":300,"elapsed":2,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"9fccbd05-c891-43ae-e9fc-83ab21b1a628"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 1., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]),\n"," 0.00010963139,\n"," 'A0A0L1IWY7_ASPNO/723-1184')"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["We see that an item of the dataset contains the one-hot representation of the sequence, the weight assigned to the sequence (explained later), and the name of the sequence"],"metadata":{"id":"lRsWJdQnh0ia"}},{"cell_type":"markdown","source":["## Instantiate model"],"metadata":{"id":"mL486WPSWwry"}},{"cell_type":"code","source":["# For architecture hyper-parameters, we rely on the defaults in the class definition\n","model = VAE(nl = nl, nc = nc)"],"metadata":{"id":"f6wWCLXIWIOq","executionInfo":{"status":"ok","timestamp":1711050303402,"user_tz":300,"elapsed":558,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Let's check that our model processes data the way we want it to"],"metadata":{"id":"IayZ9owwiMzN"}},{"cell_type":"code","source":["#Encoding\n","one_hot_ary = data[100][0]\n","batch_one_hot_ary = torch.unsqueeze(one_hot_ary, 0)\n","latent_parameters = model.encoder(batch_one_hot_ary)\n","print(f\"Mean and variance of latent vector:\")\n","print(latent_parameters)\n","#Decoding\n","mn_z = latent_parameters[0]\n","recon_log_probs = model.decoder(mn_z)\n","print(f\"Decoded output has shape {recon_log_probs.shape} and is given by:\")\n","print(recon_log_probs)\n","probs = torch.exp(recon_log_probs.squeeze())\n","print(\"The probability for each amino acid in each position is:\")\n","print(probs)\n","print(\"Rows should sum to 1: \")\n","print(torch.sum(probs, dim = 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3qcR_u-a5aE","executionInfo":{"status":"ok","timestamp":1711050304899,"user_tz":300,"elapsed":4,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"b51a4689-3582-49d0-a7ba-e9b92d43d0c5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean and variance of latent vector:\n","(tensor([[-0.0527, -0.0751,  0.0152,  0.0453,  0.0385,  0.0269, -0.0496,  0.0290,\n","          0.0537, -0.0373]], grad_fn=<AddmmBackward0>), tensor([[1.0361, 1.0326, 0.9614, 1.0208, 0.9312, 0.9865, 0.9874, 1.0559, 1.0398,\n","         0.9403]], grad_fn=<ExpBackward0>))\n","Decoded output has shape torch.Size([1, 107, 21]) and is given by:\n","tensor([[[-3.0824, -3.0549, -3.0310,  ..., -3.0695, -3.0602, -2.9696],\n","         [-3.0324, -3.0406, -2.9755,  ..., -3.0392, -3.0747, -3.0012],\n","         [-2.9559, -3.0641, -3.0779,  ..., -3.0183, -3.1161, -3.1453],\n","         ...,\n","         [-3.0220, -2.9869, -3.0441,  ..., -3.1165, -3.0509, -3.1168],\n","         [-3.1018, -3.0550, -2.9844,  ..., -3.0875, -2.9788, -3.1343],\n","         [-3.1583, -3.0194, -3.0490,  ..., -3.0659, -3.0218, -3.0178]]],\n","       grad_fn=<LogSoftmaxBackward0>)\n","The probability for each amino acid in each position is:\n","tensor([[0.0459, 0.0471, 0.0483,  ..., 0.0464, 0.0469, 0.0513],\n","        [0.0482, 0.0478, 0.0510,  ..., 0.0479, 0.0462, 0.0497],\n","        [0.0520, 0.0467, 0.0461,  ..., 0.0489, 0.0443, 0.0431],\n","        ...,\n","        [0.0487, 0.0504, 0.0476,  ..., 0.0443, 0.0473, 0.0443],\n","        [0.0450, 0.0471, 0.0506,  ..., 0.0456, 0.0509, 0.0435],\n","        [0.0425, 0.0488, 0.0474,  ..., 0.0466, 0.0487, 0.0489]],\n","       grad_fn=<ExpBackward0>)\n","Rows should sum to 1: \n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","       grad_fn=<SumBackward1>)\n"]}]},{"cell_type":"markdown","source":["## Train model"],"metadata":{"id":"G_WRwRp3iYcG"}},{"cell_type":"markdown","source":["We'll use K-fold cross validation to evaluate the training of the VAE. What this means in practice is that we partition the data into K equal-sized folds. Then for each fold, we train the VAE (for 30 epochs) using all data outside that fold and evaluate the trained model with the data from the fold."],"metadata":{"id":"Zb9-5QC1kon9"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","K= 5\n","# Initialize the k-fold cross validation\n","kf = KFold(n_splits=K, shuffle=True)"],"metadata":{"id":"YKFPSpNokn5-","executionInfo":{"status":"ok","timestamp":1711050308423,"user_tz":300,"elapsed":974,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for fold, (train_idx, valid_idx) in enumerate(kf.split(data)):\n","    print(f\"Fold {fold + 1}\")\n","    print(\"Indices of first 10 validation examples:\")\n","    print(valid_idx[:10])\n","    print(\"-------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTBdf0A1zo3g","executionInfo":{"status":"ok","timestamp":1711050309969,"user_tz":300,"elapsed":299,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"8653b742-f9c9-4448-8d8c-d1e6b2b1f262"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Indices of first 10 validation examples:\n","[ 1  6 13 17 20 25 26 27 29 38]\n","-------\n","Fold 2\n","Indices of first 10 validation examples:\n","[ 0  3 11 12 22 34 35 43 46 48]\n","-------\n","Fold 3\n","Indices of first 10 validation examples:\n","[ 5 14 15 16 19 23 33 39 40 41]\n","-------\n","Fold 4\n","Indices of first 10 validation examples:\n","[ 2  4  8 10 18 24 31 37 42 45]\n","-------\n","Fold 5\n","Indices of first 10 validation examples:\n","[ 7  9 21 28 30 32 36 66 67 68]\n","-------\n"]}]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","if device == \"cuda\":\n","  model.cuda()\n","\n","# Training hyperparameters\n","num_epochs = 500\n","weight_decay = 0.01\n","dim_lat = 64\n","batch_size = 128\n","verbose = False\n","\n","# Define how to do an epoch of training\n","def train(model, device, train_loader, optimizer, epoch, verbose):\n","\n","  model.train()\n","  running_loss = []\n","\n","  for batch_idx, (msa, weight, _) in enumerate(train_loader):\n","    msa, weight = msa.to(device), weight.to(device)\n","    optimizer.zero_grad()\n","    loss = (-1)*model.compute_weighted_elbo(msa, weight)\n","    loss.backward()\n","    optimizer.step()\n","    loss_scalar = loss.data.item()\n","    if verbose:\n","      print(\"Epoch: {:>4}, Step: {:>4}, loss: {:>4.2f}\".format(epoch, batch_idx, loss_scalar), \\\n","            flush = True)\n","    running_loss.append(loss_scalar)\n","\n","  return running_loss\n","\n","# Define how to evaluate the model on the validation data\n","def eval(model, device, valid_loader, recon = False):\n","\n","  model.eval()\n","  elbos = []\n","  if recon:\n","    recon_accs = []\n","  with torch.no_grad():\n","    for (msa, _, _) in valid_loader:\n","      msa = msa.to(device)\n","      # compute elbo loss\n","      elbo = model.compute_elbo_with_multiple_samples(msa, 100)\n","      elbo_scalar = torch.sum(elbo).data.item()\n","      elbos.append(elbo_scalar)\n","\n","\n","      if recon:\n","        # compute proportion of amino acids correctly reconstructed\n","        real = torch.argmax(msa, -1)\n","        mu, sigma = model.encoder(msa)\n","        p = torch.exp(model.decoder(mu))\n","        preds = torch.argmax(p, -1)\n","        recon_acc = torch.sum(real == preds)/real.nelement()\n","        recon_acc_scalar = recon_acc.data.item()\n","        recon_accs.append(recon_acc_scalar)\n","\n","  return elbos, recon_accs\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dM6BF_Zixnz3","executionInfo":{"status":"ok","timestamp":1711050357450,"user_tz":300,"elapsed":299,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"9457f836-f729-4599-b59a-86ec801c795b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["train_loss = {}\n","valid_elbos = {}\n","valid_recon_accs = {}\n","for fold, (train_idx, valid_idx) in enumerate(kf.split(data)):\n","\n","  print(f\"Fold {fold + 1}\")\n","  print(\"-------\")\n","\n","  # put the training and validation data into separate dataloaders\n","  train_loader = DataLoader(dataset = data,\n","                           batch_size = batch_size,\n","                           sampler = torch.utils.data.SubsetRandomSampler(train_idx))\n","\n","  valid_loader = DataLoader(dataset = data,\n","                           batch_size = batch_size,\n","                           sampler = torch.utils.data.SubsetRandomSampler(valid_idx))\n","\n","  # Instantiate a new model for this fold\n","  model = VAE(nl=nl, nc=nc, dim_latent_vars=dim_lat).to(device)\n","  optimizer = optim.Adam(model.parameters(), weight_decay = weight_decay)\n","\n","  # Define a key in the dictionaries for storing the losses and elbos for this fold\n","  train_loss[fold+1] = []\n","  valid_elbos[fold+1] = []\n","  valid_recon_accs[fold+1] = []\n","  for epoch in range(num_epochs):\n","\n","    batch_elbos, batch_recon_accs = eval(model, device, valid_loader, recon = True)\n","    epoch_val_elbo = np.mean(batch_elbos)\n","    epoch_val_recon_acc = np.mean(batch_recon_accs)\n","    print(f\"Validation elbo for fold {fold + 1}, epoch {epoch}: {epoch_val_elbo}\")\n","    print(f\"Reconstruction accuracy for fold {fold + 1}, epoch {epoch}: {epoch_val_recon_acc}\")\n","    valid_elbos[fold+1].append(epoch_val_elbo)\n","    valid_recon_accs[fold+1].append(epoch_val_recon_acc)\n","\n","    batch_losses = train(model, device, train_loader, optimizer, epoch, verbose)\n","    epoch_ave_train_loss = np.mean(batch_losses)\n","    print(f\"Training loss for fold {fold + 1}, epoch {epoch}: {epoch_ave_train_loss}\")\n","    train_loss[fold+1].append(epoch_ave_train_loss)\n","\n","\n","\n","  model.cpu()\n","  torch.save(model.state_dict(), \"./output/{}/vae_fold{}_dimlat{}_{}_{:.2f}.model\".format(MSA_id, fold+1, dim_lat, num_epochs, weight_decay))\n"],"metadata":{"id":"xXVreHkyyW3q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711051851770,"user_tz":300,"elapsed":1491270,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"a3b3f75a-8574-40d7-dd19-a5e52677c505"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Reconstruction accuracy for fold 2, epoch 335: 0.5605549104511738\n","Training loss for fold 2, epoch 335: 143.55004636702998\n","Validation elbo for fold 2, epoch 336: -19938.99217722197\n","Reconstruction accuracy for fold 2, epoch 336: 0.5599039532244205\n","Training loss for fold 2, epoch 336: 143.16799594509988\n","Validation elbo for fold 2, epoch 337: -19834.848408748083\n","Reconstruction accuracy for fold 2, epoch 337: 0.5603772066533566\n","Training loss for fold 2, epoch 337: 143.5374490061114\n","Validation elbo for fold 2, epoch 338: -19930.474148821726\n","Reconstruction accuracy for fold 2, epoch 338: 0.5592277720570564\n","Training loss for fold 2, epoch 338: 142.8678224625126\n","Validation elbo for fold 2, epoch 339: -19910.544875164873\n","Reconstruction accuracy for fold 2, epoch 339: 0.5617319941520691\n","Training loss for fold 2, epoch 339: 143.5664323376071\n","Validation elbo for fold 2, epoch 340: -19905.49307876776\n","Reconstruction accuracy for fold 2, epoch 340: 0.5601208508014679\n","Training loss for fold 2, epoch 340: 142.43324488978232\n","Validation elbo for fold 2, epoch 341: -19873.46698163551\n","Reconstruction accuracy for fold 2, epoch 341: 0.5615451596677303\n","Training loss for fold 2, epoch 341: 142.79608831098002\n","Validation elbo for fold 2, epoch 342: -19860.31270314539\n","Reconstruction accuracy for fold 2, epoch 342: 0.5613666549324989\n","Training loss for fold 2, epoch 342: 141.87627497026998\n","Validation elbo for fold 2, epoch 343: -19898.64454036515\n","Reconstruction accuracy for fold 2, epoch 343: 0.561001855880022\n","Training loss for fold 2, epoch 343: 142.98103627850932\n","Validation elbo for fold 2, epoch 344: -19891.137015175143\n","Reconstruction accuracy for fold 2, epoch 344: 0.5608794540166855\n","Training loss for fold 2, epoch 344: 143.34840577648532\n","Validation elbo for fold 2, epoch 345: -19822.62853635422\n","Reconstruction accuracy for fold 2, epoch 345: 0.5629249103367329\n","Training loss for fold 2, epoch 345: 143.33788914834298\n","Validation elbo for fold 2, epoch 346: -19905.273604395585\n","Reconstruction accuracy for fold 2, epoch 346: 0.5600824728608131\n","Training loss for fold 2, epoch 346: 142.9137554783975\n","Validation elbo for fold 2, epoch 347: -19837.779922002363\n","Reconstruction accuracy for fold 2, epoch 347: 0.5611205101013184\n","Training loss for fold 2, epoch 347: 143.12383885537423\n","Validation elbo for fold 2, epoch 348: -19877.985025791728\n","Reconstruction accuracy for fold 2, epoch 348: 0.5596441142261028\n","Training loss for fold 2, epoch 348: 144.2732659616778\n","Validation elbo for fold 2, epoch 349: -19841.387252238063\n","Reconstruction accuracy for fold 2, epoch 349: 0.5610329955816269\n","Training loss for fold 2, epoch 349: 143.0248682575841\n","Validation elbo for fold 2, epoch 350: -19881.133551360563\n","Reconstruction accuracy for fold 2, epoch 350: 0.5595552660524845\n","Training loss for fold 2, epoch 350: 142.9814192248929\n","Validation elbo for fold 2, epoch 351: -19865.356087041833\n","Reconstruction accuracy for fold 2, epoch 351: 0.5636824257671833\n","Training loss for fold 2, epoch 351: 142.37784773303616\n","Validation elbo for fold 2, epoch 352: -19840.362498958006\n","Reconstruction accuracy for fold 2, epoch 352: 0.5627979449927807\n","Training loss for fold 2, epoch 352: 143.00737442508822\n","Validation elbo for fold 2, epoch 353: -19830.402280605333\n","Reconstruction accuracy for fold 2, epoch 353: 0.561070304363966\n","Training loss for fold 2, epoch 353: 143.2135930215159\n","Validation elbo for fold 2, epoch 354: -19891.01749537336\n","Reconstruction accuracy for fold 2, epoch 354: 0.5615159049630165\n","Training loss for fold 2, epoch 354: 143.4693476769232\n","Validation elbo for fold 2, epoch 355: -19865.975874293566\n","Reconstruction accuracy for fold 2, epoch 355: 0.564144678413868\n","Training loss for fold 2, epoch 355: 143.5416403739683\n","Validation elbo for fold 2, epoch 356: -19836.521361401698\n","Reconstruction accuracy for fold 2, epoch 356: 0.5620589479804039\n","Training loss for fold 2, epoch 356: 142.7438263431672\n","Validation elbo for fold 2, epoch 357: -19854.04592124711\n","Reconstruction accuracy for fold 2, epoch 357: 0.5624567680060863\n","Training loss for fold 2, epoch 357: 142.69776965725808\n","Validation elbo for fold 2, epoch 358: -19830.785119295004\n","Reconstruction accuracy for fold 2, epoch 358: 0.5640308633446693\n","Training loss for fold 2, epoch 358: 142.4828636415543\n","Validation elbo for fold 2, epoch 359: -19880.324265657204\n","Reconstruction accuracy for fold 2, epoch 359: 0.5629922933876514\n","Training loss for fold 2, epoch 359: 142.04182483303933\n","Validation elbo for fold 2, epoch 360: -19883.5104267054\n","Reconstruction accuracy for fold 2, epoch 360: 0.5616627410054207\n","Training loss for fold 2, epoch 360: 142.71886234898722\n","Validation elbo for fold 2, epoch 361: -19875.000849997257\n","Reconstruction accuracy for fold 2, epoch 361: 0.5617803074419498\n","Training loss for fold 2, epoch 361: 142.6191552685153\n","Validation elbo for fold 2, epoch 362: -19855.732921381496\n","Reconstruction accuracy for fold 2, epoch 362: 0.5596830360591412\n","Training loss for fold 2, epoch 362: 142.36706001527847\n","Validation elbo for fold 2, epoch 363: -19863.67024989199\n","Reconstruction accuracy for fold 2, epoch 363: 0.5631122812628746\n","Training loss for fold 2, epoch 363: 142.7170946674962\n","Validation elbo for fold 2, epoch 364: -19861.13979491961\n","Reconstruction accuracy for fold 2, epoch 364: 0.5655287280678749\n","Training loss for fold 2, epoch 364: 143.26224960819368\n","Validation elbo for fold 2, epoch 365: -19854.04405334415\n","Reconstruction accuracy for fold 2, epoch 365: 0.5642531216144562\n","Training loss for fold 2, epoch 365: 142.93600623838364\n","Validation elbo for fold 2, epoch 366: -19855.17028867464\n","Reconstruction accuracy for fold 2, epoch 366: 0.5624674968421459\n","Training loss for fold 2, epoch 366: 142.804873927947\n","Validation elbo for fold 2, epoch 367: -19891.20062635898\n","Reconstruction accuracy for fold 2, epoch 367: 0.5627225153148174\n","Training loss for fold 2, epoch 367: 143.60526078747165\n","Validation elbo for fold 2, epoch 368: -19836.388698001418\n","Reconstruction accuracy for fold 2, epoch 368: 0.5638668462634087\n","Training loss for fold 2, epoch 368: 143.15477088189894\n","Validation elbo for fold 2, epoch 369: -19891.585240353947\n","Reconstruction accuracy for fold 2, epoch 369: 0.5603049956262112\n","Training loss for fold 2, epoch 369: 143.8961887974893\n","Validation elbo for fold 2, epoch 370: -19867.912221173327\n","Reconstruction accuracy for fold 2, epoch 370: 0.5638716854155064\n","Training loss for fold 2, epoch 370: 142.08313652776903\n","Validation elbo for fold 2, epoch 371: -19849.759941290038\n","Reconstruction accuracy for fold 2, epoch 371: 0.5636899434030056\n","Training loss for fold 2, epoch 371: 142.84122651623142\n","Validation elbo for fold 2, epoch 372: -19900.37881681379\n","Reconstruction accuracy for fold 2, epoch 372: 0.5604142472147942\n","Training loss for fold 2, epoch 372: 142.52252787928427\n","Validation elbo for fold 2, epoch 373: -19863.47169008552\n","Reconstruction accuracy for fold 2, epoch 373: 0.5619059428572655\n","Training loss for fold 2, epoch 373: 142.43483918712985\n","Validation elbo for fold 2, epoch 374: -19862.665494014094\n","Reconstruction accuracy for fold 2, epoch 374: 0.5637170635163784\n","Training loss for fold 2, epoch 374: 142.21753434211976\n","Validation elbo for fold 2, epoch 375: -19877.07258447413\n","Reconstruction accuracy for fold 2, epoch 375: 0.5632677040994167\n","Training loss for fold 2, epoch 375: 142.74984691989036\n","Validation elbo for fold 2, epoch 376: -19876.246461835297\n","Reconstruction accuracy for fold 2, epoch 376: 0.5632473006844521\n","Training loss for fold 2, epoch 376: 142.40949889152282\n","Validation elbo for fold 2, epoch 377: -19852.20076726071\n","Reconstruction accuracy for fold 2, epoch 377: 0.564382515847683\n","Training loss for fold 2, epoch 377: 142.58489338044197\n","Validation elbo for fold 2, epoch 378: -19890.449294924147\n","Reconstruction accuracy for fold 2, epoch 378: 0.5598693341016769\n","Training loss for fold 2, epoch 378: 142.60796442339498\n","Validation elbo for fold 2, epoch 379: -19888.816928910863\n","Reconstruction accuracy for fold 2, epoch 379: 0.5628567337989807\n","Training loss for fold 2, epoch 379: 142.5183383572486\n","Validation elbo for fold 2, epoch 380: -19879.42521507634\n","Reconstruction accuracy for fold 2, epoch 380: 0.5623332895338535\n","Training loss for fold 2, epoch 380: 142.54106041692918\n","Validation elbo for fold 2, epoch 381: -19931.570688934597\n","Reconstruction accuracy for fold 2, epoch 381: 0.5599992536008358\n","Training loss for fold 2, epoch 381: 142.98742712697674\n","Validation elbo for fold 2, epoch 382: -19883.975412719818\n","Reconstruction accuracy for fold 2, epoch 382: 0.5629123076796532\n","Training loss for fold 2, epoch 382: 142.7163655680995\n","Validation elbo for fold 2, epoch 383: -19861.752323630477\n","Reconstruction accuracy for fold 2, epoch 383: 0.5630266517400742\n","Training loss for fold 2, epoch 383: 142.84226337555916\n","Validation elbo for fold 2, epoch 384: -19856.901389614475\n","Reconstruction accuracy for fold 2, epoch 384: 0.560596514493227\n","Training loss for fold 2, epoch 384: 143.11193269298923\n","Validation elbo for fold 2, epoch 385: -19884.867904485713\n","Reconstruction accuracy for fold 2, epoch 385: 0.5629670582711697\n","Training loss for fold 2, epoch 385: 142.3613020373929\n","Validation elbo for fold 2, epoch 386: -19843.58591746669\n","Reconstruction accuracy for fold 2, epoch 386: 0.5656339526176453\n","Training loss for fold 2, epoch 386: 141.96362157021798\n","Validation elbo for fold 2, epoch 387: -19816.047733718144\n","Reconstruction accuracy for fold 2, epoch 387: 0.5621443092823029\n","Training loss for fold 2, epoch 387: 142.1059092860068\n","Validation elbo for fold 2, epoch 388: -19860.670895358293\n","Reconstruction accuracy for fold 2, epoch 388: 0.5642955452203751\n","Training loss for fold 2, epoch 388: 141.37333716115643\n","Validation elbo for fold 2, epoch 389: -19827.80862755997\n","Reconstruction accuracy for fold 2, epoch 389: 0.5628022365272045\n","Training loss for fold 2, epoch 389: 142.39884444205993\n","Validation elbo for fold 2, epoch 390: -19836.86829051273\n","Reconstruction accuracy for fold 2, epoch 390: 0.5652696862816811\n","Training loss for fold 2, epoch 390: 141.97811397429436\n","Validation elbo for fold 2, epoch 391: -19805.898456115734\n","Reconstruction accuracy for fold 2, epoch 391: 0.5647277161478996\n","Training loss for fold 2, epoch 391: 141.96280079503214\n","Validation elbo for fold 2, epoch 392: -19893.656927824108\n","Reconstruction accuracy for fold 2, epoch 392: 0.5612179450690746\n","Training loss for fold 2, epoch 392: 142.58478681502802\n","Validation elbo for fold 2, epoch 393: -19886.767654805353\n","Reconstruction accuracy for fold 2, epoch 393: 0.5623289830982685\n","Training loss for fold 2, epoch 393: 143.34037276237243\n","Validation elbo for fold 2, epoch 394: -19908.431147250452\n","Reconstruction accuracy for fold 2, epoch 394: 0.5638775900006294\n","Training loss for fold 2, epoch 394: 142.31881935365737\n","Validation elbo for fold 2, epoch 395: -19844.37829260496\n","Reconstruction accuracy for fold 2, epoch 395: 0.5634786933660507\n","Training loss for fold 2, epoch 395: 142.74138419858872\n","Validation elbo for fold 2, epoch 396: -19877.948664836636\n","Reconstruction accuracy for fold 2, epoch 396: 0.5619051307439804\n","Training loss for fold 2, epoch 396: 141.6736085953251\n","Validation elbo for fold 2, epoch 397: -19873.3926722301\n","Reconstruction accuracy for fold 2, epoch 397: 0.5629088059067726\n","Training loss for fold 2, epoch 397: 142.02716519755703\n","Validation elbo for fold 2, epoch 398: -19879.83998685568\n","Reconstruction accuracy for fold 2, epoch 398: 0.5609178319573402\n","Training loss for fold 2, epoch 398: 141.56583576817667\n","Validation elbo for fold 2, epoch 399: -19840.98700425234\n","Reconstruction accuracy for fold 2, epoch 399: 0.5634604394435883\n","Training loss for fold 2, epoch 399: 141.7208985359438\n","Validation elbo for fold 2, epoch 400: -19919.022370010836\n","Reconstruction accuracy for fold 2, epoch 400: 0.5623263120651245\n","Training loss for fold 2, epoch 400: 142.56015740671467\n","Validation elbo for fold 2, epoch 401: -19862.917375540317\n","Reconstruction accuracy for fold 2, epoch 401: 0.5623107366263866\n","Training loss for fold 2, epoch 401: 142.2056822007702\n","Validation elbo for fold 2, epoch 402: -19884.683275107636\n","Reconstruction accuracy for fold 2, epoch 402: 0.5621118247509003\n","Training loss for fold 2, epoch 402: 141.64194033222813\n","Validation elbo for fold 2, epoch 403: -19860.00018795392\n","Reconstruction accuracy for fold 2, epoch 403: 0.5614678524434566\n","Training loss for fold 2, epoch 403: 141.75112336681735\n","Validation elbo for fold 2, epoch 404: -19873.341790112172\n","Reconstruction accuracy for fold 2, epoch 404: 0.5624618642032146\n","Training loss for fold 2, epoch 404: 142.24169355823147\n","Validation elbo for fold 2, epoch 405: -19830.724382049684\n","Reconstruction accuracy for fold 2, epoch 405: 0.5629547014832497\n","Training loss for fold 2, epoch 405: 142.32517279348065\n","Validation elbo for fold 2, epoch 406: -19818.930239615853\n","Reconstruction accuracy for fold 2, epoch 406: 0.5649099871516228\n","Training loss for fold 2, epoch 406: 141.99021394791143\n","Validation elbo for fold 2, epoch 407: -19819.90086387271\n","Reconstruction accuracy for fold 2, epoch 407: 0.5673978328704834\n","Training loss for fold 2, epoch 407: 141.57856492073304\n","Validation elbo for fold 2, epoch 408: -19843.348446931857\n","Reconstruction accuracy for fold 2, epoch 408: 0.5638770498335361\n","Training loss for fold 2, epoch 408: 141.9142301005702\n","Validation elbo for fold 2, epoch 409: -19848.778724751603\n","Reconstruction accuracy for fold 2, epoch 409: 0.561944056302309\n","Training loss for fold 2, epoch 409: 141.76866174513293\n","Validation elbo for fold 2, epoch 410: -19840.442917860586\n","Reconstruction accuracy for fold 2, epoch 410: 0.5614007450640202\n","Training loss for fold 2, epoch 410: 141.62112845143963\n","Validation elbo for fold 2, epoch 411: -19906.406204621355\n","Reconstruction accuracy for fold 2, epoch 411: 0.5624264366924763\n","Training loss for fold 2, epoch 411: 141.5805050019295\n","Validation elbo for fold 2, epoch 412: -19852.189342110516\n","Reconstruction accuracy for fold 2, epoch 412: 0.5627517774701118\n","Training loss for fold 2, epoch 412: 142.32531578310073\n","Validation elbo for fold 2, epoch 413: -19837.33526474835\n","Reconstruction accuracy for fold 2, epoch 413: 0.5641938000917435\n","Training loss for fold 2, epoch 413: 141.18117375527657\n","Validation elbo for fold 2, epoch 414: -19878.776314813644\n","Reconstruction accuracy for fold 2, epoch 414: 0.5624382458627224\n","Training loss for fold 2, epoch 414: 141.89805295390468\n","Validation elbo for fold 2, epoch 415: -19870.14320870235\n","Reconstruction accuracy for fold 2, epoch 415: 0.5636000223457813\n","Training loss for fold 2, epoch 415: 142.55068489813036\n","Validation elbo for fold 2, epoch 416: -19880.923697547507\n","Reconstruction accuracy for fold 2, epoch 416: 0.5605745129287243\n","Training loss for fold 2, epoch 416: 142.7112954662692\n","Validation elbo for fold 2, epoch 417: -19873.20965648446\n","Reconstruction accuracy for fold 2, epoch 417: 0.5611717738211155\n","Training loss for fold 2, epoch 417: 141.80664554719002\n","Validation elbo for fold 2, epoch 418: -19858.702286327458\n","Reconstruction accuracy for fold 2, epoch 418: 0.5603860728442669\n","Training loss for fold 2, epoch 418: 142.2918979275611\n","Validation elbo for fold 2, epoch 419: -19875.099179739776\n","Reconstruction accuracy for fold 2, epoch 419: 0.5631393976509571\n","Training loss for fold 2, epoch 419: 142.30990182199787\n","Validation elbo for fold 2, epoch 420: -19878.353031774976\n","Reconstruction accuracy for fold 2, epoch 420: 0.5627155415713787\n","Training loss for fold 2, epoch 420: 142.091371720837\n","Validation elbo for fold 2, epoch 421: -19835.982883034663\n","Reconstruction accuracy for fold 2, epoch 421: 0.5657891109585762\n","Training loss for fold 2, epoch 421: 140.78510136758126\n","Validation elbo for fold 2, epoch 422: -19846.01059913777\n","Reconstruction accuracy for fold 2, epoch 422: 0.5627823770046234\n","Training loss for fold 2, epoch 422: 141.34354499078566\n","Validation elbo for fold 2, epoch 423: -19872.740207939896\n","Reconstruction accuracy for fold 2, epoch 423: 0.5651861988008022\n","Training loss for fold 2, epoch 423: 141.88828339115267\n","Validation elbo for fold 2, epoch 424: -19845.37987915214\n","Reconstruction accuracy for fold 2, epoch 424: 0.5614603348076344\n","Training loss for fold 2, epoch 424: 141.86586256950133\n","Validation elbo for fold 2, epoch 425: -19898.803069187357\n","Reconstruction accuracy for fold 2, epoch 425: 0.5633825957775116\n","Training loss for fold 2, epoch 425: 141.30562689996535\n","Validation elbo for fold 2, epoch 426: -20008.12981791028\n","Reconstruction accuracy for fold 2, epoch 426: 0.5611599572002888\n","Training loss for fold 2, epoch 426: 141.9284670429845\n","Validation elbo for fold 2, epoch 427: -19935.24816954467\n","Reconstruction accuracy for fold 2, epoch 427: 0.5626057460904121\n","Training loss for fold 2, epoch 427: 141.62257889778382\n","Validation elbo for fold 2, epoch 428: -19865.13970814044\n","Reconstruction accuracy for fold 2, epoch 428: 0.5626105852425098\n","Training loss for fold 2, epoch 428: 141.58240558255105\n","Validation elbo for fold 2, epoch 429: -19848.177844333026\n","Reconstruction accuracy for fold 2, epoch 429: 0.5630687922239304\n","Training loss for fold 2, epoch 429: 141.9064670685799\n","Validation elbo for fold 2, epoch 430: -19844.719780834646\n","Reconstruction accuracy for fold 2, epoch 430: 0.5670467168092728\n","Training loss for fold 2, epoch 430: 142.03565634450604\n","Validation elbo for fold 2, epoch 431: -19890.4504871271\n","Reconstruction accuracy for fold 2, epoch 431: 0.5624567680060863\n","Training loss for fold 2, epoch 431: 141.64126574608588\n","Validation elbo for fold 2, epoch 432: -19820.107342432508\n","Reconstruction accuracy for fold 2, epoch 432: 0.5636075437068939\n","Training loss for fold 2, epoch 432: 141.87608657344694\n","Validation elbo for fold 2, epoch 433: -19899.93417297495\n","Reconstruction accuracy for fold 2, epoch 433: 0.561788909137249\n","Training loss for fold 2, epoch 433: 141.2072512718939\n","Validation elbo for fold 2, epoch 434: -19902.84051527924\n","Reconstruction accuracy for fold 2, epoch 434: 0.5624409280717373\n","Training loss for fold 2, epoch 434: 141.6468240061114\n","Validation elbo for fold 2, epoch 435: -19819.83287916509\n","Reconstruction accuracy for fold 2, epoch 435: 0.5659923143684864\n","Training loss for fold 2, epoch 435: 141.11850972329415\n","Validation elbo for fold 2, epoch 436: -19881.876763235938\n","Reconstruction accuracy for fold 2, epoch 436: 0.5635355971753597\n","Training loss for fold 2, epoch 436: 141.14663487095987\n","Validation elbo for fold 2, epoch 437: -19870.16020921948\n","Reconstruction accuracy for fold 2, epoch 437: 0.5630921460688114\n","Training loss for fold 2, epoch 437: 141.4453334193076\n","Validation elbo for fold 2, epoch 438: -19833.976578928097\n","Reconstruction accuracy for fold 2, epoch 438: 0.5668792128562927\n","Training loss for fold 2, epoch 438: 141.06732879146452\n","Validation elbo for fold 2, epoch 439: -19859.92548618842\n","Reconstruction accuracy for fold 2, epoch 439: 0.5615687929093838\n","Training loss for fold 2, epoch 439: 140.97220291629915\n","Validation elbo for fold 2, epoch 440: -19844.78729236331\n","Reconstruction accuracy for fold 2, epoch 440: 0.5673049464821815\n","Training loss for fold 2, epoch 440: 141.6616737611832\n","Validation elbo for fold 2, epoch 441: -19882.462245722745\n","Reconstruction accuracy for fold 2, epoch 441: 0.5647164396941662\n","Training loss for fold 2, epoch 441: 141.6881290558846\n","Validation elbo for fold 2, epoch 442: -19864.040071807976\n","Reconstruction accuracy for fold 2, epoch 442: 0.5643543228507042\n","Training loss for fold 2, epoch 442: 141.6488668380245\n","Validation elbo for fold 2, epoch 443: -19861.27741695914\n","Reconstruction accuracy for fold 2, epoch 443: 0.563594926148653\n","Training loss for fold 2, epoch 443: 141.42180375129945\n","Validation elbo for fold 2, epoch 444: -19861.798183547115\n","Reconstruction accuracy for fold 2, epoch 444: 0.560934741050005\n","Training loss for fold 2, epoch 444: 141.01072163735665\n","Validation elbo for fold 2, epoch 445: -19885.73046024391\n","Reconstruction accuracy for fold 2, epoch 445: 0.5612010322511196\n","Training loss for fold 2, epoch 445: 141.58832906907605\n","Validation elbo for fold 2, epoch 446: -19904.684186388316\n","Reconstruction accuracy for fold 2, epoch 446: 0.5621827021241188\n","Training loss for fold 2, epoch 446: 142.60759968911447\n","Validation elbo for fold 2, epoch 447: -19837.766484856736\n","Reconstruction accuracy for fold 2, epoch 447: 0.5623488575220108\n","Training loss for fold 2, epoch 447: 140.61494814965033\n","Validation elbo for fold 2, epoch 448: -19821.384756843196\n","Reconstruction accuracy for fold 2, epoch 448: 0.5610499009490013\n","Training loss for fold 2, epoch 448: 140.7701776566044\n","Validation elbo for fold 2, epoch 449: -19837.279464491243\n","Reconstruction accuracy for fold 2, epoch 449: 0.5658994317054749\n","Training loss for fold 2, epoch 449: 140.54801141062092\n","Validation elbo for fold 2, epoch 450: -19842.066810188622\n","Reconstruction accuracy for fold 2, epoch 450: 0.5635143928229809\n","Training loss for fold 2, epoch 450: 142.0688474101405\n","Validation elbo for fold 2, epoch 451: -19825.559361456286\n","Reconstruction accuracy for fold 2, epoch 451: 0.5653083436191082\n","Training loss for fold 2, epoch 451: 141.83571230980658\n","Validation elbo for fold 2, epoch 452: -19864.129544045656\n","Reconstruction accuracy for fold 2, epoch 452: 0.5638110190629959\n","Training loss for fold 2, epoch 452: 142.14447144539125\n","Validation elbo for fold 2, epoch 453: -19839.634949326955\n","Reconstruction accuracy for fold 2, epoch 453: 0.563129186630249\n","Training loss for fold 2, epoch 453: 141.71021566083354\n","Validation elbo for fold 2, epoch 454: -19891.47597667753\n","Reconstruction accuracy for fold 2, epoch 454: 0.562401469796896\n","Training loss for fold 2, epoch 454: 141.10188933341735\n","Validation elbo for fold 2, epoch 455: -19866.771202588287\n","Reconstruction accuracy for fold 2, epoch 455: 0.5643468089401722\n","Training loss for fold 2, epoch 455: 140.3567881430349\n","Validation elbo for fold 2, epoch 456: -19899.97856459928\n","Reconstruction accuracy for fold 2, epoch 456: 0.5652235224843025\n","Training loss for fold 2, epoch 456: 141.0736817390688\n","Validation elbo for fold 2, epoch 457: -19872.235306513117\n","Reconstruction accuracy for fold 2, epoch 457: 0.5601815208792686\n","Training loss for fold 2, epoch 457: 140.34478402906848\n","Validation elbo for fold 2, epoch 458: -19823.970489308736\n","Reconstruction accuracy for fold 2, epoch 458: 0.5623026825487614\n","Training loss for fold 2, epoch 458: 141.18967696159118\n","Validation elbo for fold 2, epoch 459: -19843.52186180376\n","Reconstruction accuracy for fold 2, epoch 459: 0.5639449618756771\n","Training loss for fold 2, epoch 459: 140.99508765435988\n","Validation elbo for fold 2, epoch 460: -19867.100273454198\n","Reconstruction accuracy for fold 2, epoch 460: 0.5629074685275555\n","Training loss for fold 2, epoch 460: 141.0384148628481\n","Validation elbo for fold 2, epoch 461: -19872.204673127762\n","Reconstruction accuracy for fold 2, epoch 461: 0.5640244223177433\n","Training loss for fold 2, epoch 461: 142.12757479759955\n","Validation elbo for fold 2, epoch 462: -19956.285068008474\n","Reconstruction accuracy for fold 2, epoch 462: 0.5597144402563572\n","Training loss for fold 2, epoch 462: 141.96154145271547\n","Validation elbo for fold 2, epoch 463: -19995.230296851714\n","Reconstruction accuracy for fold 2, epoch 463: 0.5613674707710743\n","Training loss for fold 2, epoch 463: 141.17934011643933\n","Validation elbo for fold 2, epoch 464: -19838.02477673077\n","Reconstruction accuracy for fold 2, epoch 464: 0.5611049272119999\n","Training loss for fold 2, epoch 464: 140.42996425013388\n","Validation elbo for fold 2, epoch 465: -19870.44345060445\n","Reconstruction accuracy for fold 2, epoch 465: 0.5626723133027554\n","Training loss for fold 2, epoch 465: 141.15782977688698\n","Validation elbo for fold 2, epoch 466: -19879.86467921631\n","Reconstruction accuracy for fold 2, epoch 466: 0.5634005777537823\n","Training loss for fold 2, epoch 466: 141.00331361832158\n","Validation elbo for fold 2, epoch 467: -19890.01942390944\n","Reconstruction accuracy for fold 2, epoch 467: 0.5635557286441326\n","Training loss for fold 2, epoch 467: 141.1508747223885\n","Validation elbo for fold 2, epoch 468: -19887.510761529127\n","Reconstruction accuracy for fold 2, epoch 468: 0.5629785992205143\n","Training loss for fold 2, epoch 468: 140.72036743164062\n","Validation elbo for fold 2, epoch 469: -19907.251094261635\n","Reconstruction accuracy for fold 2, epoch 469: 0.563124094158411\n","Training loss for fold 2, epoch 469: 141.38343195761405\n","Validation elbo for fold 2, epoch 470: -19873.643258424992\n","Reconstruction accuracy for fold 2, epoch 470: 0.5623853616416454\n","Training loss for fold 2, epoch 470: 140.84976405482138\n","Validation elbo for fold 2, epoch 471: -19868.711596618443\n","Reconstruction accuracy for fold 2, epoch 471: 0.5637911483645439\n","Training loss for fold 2, epoch 471: 141.5099011082803\n","Validation elbo for fold 2, epoch 472: -19872.518142790857\n","Reconstruction accuracy for fold 2, epoch 472: 0.5640815943479538\n","Training loss for fold 2, epoch 472: 140.5547235550419\n","Validation elbo for fold 2, epoch 473: -19838.40895263273\n","Reconstruction accuracy for fold 2, epoch 473: 0.5624030791223049\n","Training loss for fold 2, epoch 473: 140.4231710126323\n","Validation elbo for fold 2, epoch 474: -19873.1283402111\n","Reconstruction accuracy for fold 2, epoch 474: 0.5621040426194668\n","Training loss for fold 2, epoch 474: 140.7938712335402\n","Validation elbo for fold 2, epoch 475: -19860.62205823155\n","Reconstruction accuracy for fold 2, epoch 475: 0.5626264065504074\n","Training loss for fold 2, epoch 475: 140.40669348932082\n","Validation elbo for fold 2, epoch 476: -19855.92724154173\n","Reconstruction accuracy for fold 2, epoch 476: 0.5630824901163578\n","Training loss for fold 2, epoch 476: 140.53191424954323\n","Validation elbo for fold 2, epoch 477: -19854.083241282187\n","Reconstruction accuracy for fold 2, epoch 477: 0.5634000413119793\n","Training loss for fold 2, epoch 477: 140.240903669788\n","Validation elbo for fold 2, epoch 478: -19881.720909629672\n","Reconstruction accuracy for fold 2, epoch 478: 0.5621730200946331\n","Training loss for fold 2, epoch 478: 140.98088135257845\n","Validation elbo for fold 2, epoch 479: -19858.724493604823\n","Reconstruction accuracy for fold 2, epoch 479: 0.5620943829417229\n","Training loss for fold 2, epoch 479: 140.87861904021233\n","Validation elbo for fold 2, epoch 480: -19927.827540993334\n","Reconstruction accuracy for fold 2, epoch 480: 0.5597858466207981\n","Training loss for fold 2, epoch 480: 142.04507938508064\n","Validation elbo for fold 2, epoch 481: -19865.552205480617\n","Reconstruction accuracy for fold 2, epoch 481: 0.5638257786631584\n","Training loss for fold 2, epoch 481: 141.17237127980877\n","Validation elbo for fold 2, epoch 482: -19837.263283062435\n","Reconstruction accuracy for fold 2, epoch 482: 0.5634386986494064\n","Training loss for fold 2, epoch 482: 140.83114328692037\n","Validation elbo for fold 2, epoch 483: -19868.9321647362\n","Reconstruction accuracy for fold 2, epoch 483: 0.5637092851102352\n","Training loss for fold 2, epoch 483: 140.2922470338883\n","Validation elbo for fold 2, epoch 484: -19887.975293254796\n","Reconstruction accuracy for fold 2, epoch 484: 0.5615274496376514\n","Training loss for fold 2, epoch 484: 140.58189305951518\n","Validation elbo for fold 2, epoch 485: -19917.849525168658\n","Reconstruction accuracy for fold 2, epoch 485: 0.5641296394169331\n","Training loss for fold 2, epoch 485: 140.86690964237337\n","Validation elbo for fold 2, epoch 486: -19911.885775412604\n","Reconstruction accuracy for fold 2, epoch 486: 0.5620339810848236\n","Training loss for fold 2, epoch 486: 141.11559455625473\n","Validation elbo for fold 2, epoch 487: -19836.47533982267\n","Reconstruction accuracy for fold 2, epoch 487: 0.566564068198204\n","Training loss for fold 2, epoch 487: 140.84156380930256\n","Validation elbo for fold 2, epoch 488: -19861.681178470673\n","Reconstruction accuracy for fold 2, epoch 488: 0.565102182328701\n","Training loss for fold 2, epoch 488: 140.96685126519972\n","Validation elbo for fold 2, epoch 489: -19815.10137545113\n","Reconstruction accuracy for fold 2, epoch 489: 0.5616340264678001\n","Training loss for fold 2, epoch 489: 140.75062462591356\n","Validation elbo for fold 2, epoch 490: -19853.365641652344\n","Reconstruction accuracy for fold 2, epoch 490: 0.5626715049147606\n","Training loss for fold 2, epoch 490: 141.1012024418\n","Validation elbo for fold 2, epoch 491: -19852.058237617395\n","Reconstruction accuracy for fold 2, epoch 491: 0.5618001781404018\n","Training loss for fold 2, epoch 491: 140.48381399339246\n","Validation elbo for fold 2, epoch 492: -19876.70233731529\n","Reconstruction accuracy for fold 2, epoch 492: 0.5633302517235279\n","Training loss for fold 2, epoch 492: 140.24207773516255\n","Validation elbo for fold 2, epoch 493: -19911.374147040053\n","Reconstruction accuracy for fold 2, epoch 493: 0.5598355121910572\n","Training loss for fold 2, epoch 493: 141.3431905931042\n","Validation elbo for fold 2, epoch 494: -19861.807393371542\n","Reconstruction accuracy for fold 2, epoch 494: 0.5622471198439598\n","Training loss for fold 2, epoch 494: 140.31653016613376\n","Validation elbo for fold 2, epoch 495: -19849.497086651503\n","Reconstruction accuracy for fold 2, epoch 495: 0.5623848289251328\n","Training loss for fold 2, epoch 495: 139.9266939470845\n","Validation elbo for fold 2, epoch 496: -19865.903471297468\n","Reconstruction accuracy for fold 2, epoch 496: 0.5627297572791576\n","Training loss for fold 2, epoch 496: 140.59283594931327\n","Validation elbo for fold 2, epoch 497: -19911.29960591405\n","Reconstruction accuracy for fold 2, epoch 497: 0.5645059905946255\n","Training loss for fold 2, epoch 497: 140.53835604267735\n","Validation elbo for fold 2, epoch 498: -19870.18018426677\n","Reconstruction accuracy for fold 2, epoch 498: 0.5634419173002243\n","Training loss for fold 2, epoch 498: 140.35564484134798\n","Validation elbo for fold 2, epoch 499: -19976.758098285994\n","Reconstruction accuracy for fold 2, epoch 499: 0.560799453407526\n","Training loss for fold 2, epoch 499: 140.538634884742\n","Fold 3\n","-------\n","Validation elbo for fold 3, epoch 0: -39795.97023400273\n","Reconstruction accuracy for fold 3, epoch 0: 0.04466839833185077\n","Training loss for fold 3, epoch 0: 240.29936169039817\n","Validation elbo for fold 3, epoch 1: -26438.461590457726\n","Reconstruction accuracy for fold 3, epoch 1: 0.3714578431099653\n","Training loss for fold 3, epoch 1: 225.8285379717427\n","Validation elbo for fold 3, epoch 2: -26460.314424517805\n","Reconstruction accuracy for fold 3, epoch 2: 0.3681126106530428\n","Training loss for fold 3, epoch 2: 225.13822543236518\n","Validation elbo for fold 3, epoch 3: -26353.603626658605\n","Reconstruction accuracy for fold 3, epoch 3: 0.3804554343223572\n","Training loss for fold 3, epoch 3: 223.628908218876\n","Validation elbo for fold 3, epoch 4: -25751.413711540925\n","Reconstruction accuracy for fold 3, epoch 4: 0.3898378759622574\n","Training loss for fold 3, epoch 4: 222.2325943977602\n","Validation elbo for fold 3, epoch 5: -25661.308289064702\n","Reconstruction accuracy for fold 3, epoch 5: 0.3912974614650011\n","Training loss for fold 3, epoch 5: 221.2364762829196\n","Validation elbo for fold 3, epoch 6: -25568.121366158884\n","Reconstruction accuracy for fold 3, epoch 6: 0.3896097056567669\n","Training loss for fold 3, epoch 6: 219.72510430120653\n","Validation elbo for fold 3, epoch 7: -25355.401551035924\n","Reconstruction accuracy for fold 3, epoch 7: 0.3931961040943861\n","Training loss for fold 3, epoch 7: 219.23570276075793\n","Validation elbo for fold 3, epoch 8: -25218.661505002412\n","Reconstruction accuracy for fold 3, epoch 8: 0.39396938867866993\n","Training loss for fold 3, epoch 8: 218.1238523913968\n","Validation elbo for fold 3, epoch 9: -25097.825370778104\n","Reconstruction accuracy for fold 3, epoch 9: 0.39595003239810467\n","Training loss for fold 3, epoch 9: 216.95733421079575\n","Validation elbo for fold 3, epoch 10: -24933.17504354458\n","Reconstruction accuracy for fold 3, epoch 10: 0.4074919167906046\n","Training loss for fold 3, epoch 10: 214.88231338993197\n","Validation elbo for fold 3, epoch 11: -24773.105725567155\n","Reconstruction accuracy for fold 3, epoch 11: 0.40445561707019806\n","Training loss for fold 3, epoch 11: 213.99581712292087\n","Validation elbo for fold 3, epoch 12: -24565.56914597962\n","Reconstruction accuracy for fold 3, epoch 12: 0.4113931879401207\n","Training loss for fold 3, epoch 12: 211.48058934365548\n","Validation elbo for fold 3, epoch 13: -24301.19480612677\n","Reconstruction accuracy for fold 3, epoch 13: 0.4138975143432617\n","Training loss for fold 3, epoch 13: 208.89105027721774\n","Validation elbo for fold 3, epoch 14: -24047.998420660468\n","Reconstruction accuracy for fold 3, epoch 14: 0.4213405195623636\n","Training loss for fold 3, epoch 14: 207.33943422379033\n","Validation elbo for fold 3, epoch 15: -23828.995103885347\n","Reconstruction accuracy for fold 3, epoch 15: 0.4264008905738592\n","Training loss for fold 3, epoch 15: 205.75100806451613\n","Validation elbo for fold 3, epoch 16: -23679.881864985968\n","Reconstruction accuracy for fold 3, epoch 16: 0.42914997413754463\n","Training loss for fold 3, epoch 16: 204.9831781694966\n","Validation elbo for fold 3, epoch 17: -23566.16421334959\n","Reconstruction accuracy for fold 3, epoch 17: 0.43066418915987015\n","Training loss for fold 3, epoch 17: 203.59804239580708\n","Validation elbo for fold 3, epoch 18: -23509.350345478706\n","Reconstruction accuracy for fold 3, epoch 18: 0.43421394377946854\n","Training loss for fold 3, epoch 18: 202.9563256540606\n","Validation elbo for fold 3, epoch 19: -23369.512866234792\n","Reconstruction accuracy for fold 3, epoch 19: 0.4357935581356287\n","Training loss for fold 3, epoch 19: 201.5662406183058\n","Validation elbo for fold 3, epoch 20: -23249.811002779974\n","Reconstruction accuracy for fold 3, epoch 20: 0.440540436655283\n","Training loss for fold 3, epoch 20: 200.67698669433594\n","Validation elbo for fold 3, epoch 21: -23136.014750795974\n","Reconstruction accuracy for fold 3, epoch 21: 0.4497533440589905\n","Training loss for fold 3, epoch 21: 200.05952502835183\n","Validation elbo for fold 3, epoch 22: -23018.075669192214\n","Reconstruction accuracy for fold 3, epoch 22: 0.4558074213564396\n","Training loss for fold 3, epoch 22: 198.50426803096647\n","Validation elbo for fold 3, epoch 23: -22887.2153075342\n","Reconstruction accuracy for fold 3, epoch 23: 0.460999159142375\n","Training loss for fold 3, epoch 23: 197.89983146421372\n","Validation elbo for fold 3, epoch 24: -22754.891119173313\n","Reconstruction accuracy for fold 3, epoch 24: 0.470129644498229\n","Training loss for fold 3, epoch 24: 196.7661627492597\n","Validation elbo for fold 3, epoch 25: -22699.766332364186\n","Reconstruction accuracy for fold 3, epoch 25: 0.47061004117131233\n","Training loss for fold 3, epoch 25: 195.4781974054152\n","Validation elbo for fold 3, epoch 26: -22584.424363026847\n","Reconstruction accuracy for fold 3, epoch 26: 0.47331806272268295\n","Training loss for fold 3, epoch 26: 195.19174415834487\n","Validation elbo for fold 3, epoch 27: -22493.954910694032\n","Reconstruction accuracy for fold 3, epoch 27: 0.4745388329029083\n","Training loss for fold 3, epoch 27: 194.64763419858872\n","Validation elbo for fold 3, epoch 28: -22394.235989291352\n","Reconstruction accuracy for fold 3, epoch 28: 0.479133328422904\n","Training loss for fold 3, epoch 28: 193.60638353901524\n","Validation elbo for fold 3, epoch 29: -22324.301153376153\n","Reconstruction accuracy for fold 3, epoch 29: 0.4802715424448252\n","Training loss for fold 3, epoch 29: 192.49539430679815\n","Validation elbo for fold 3, epoch 30: -22268.76203617569\n","Reconstruction accuracy for fold 3, epoch 30: 0.48190716840326786\n","Training loss for fold 3, epoch 30: 191.84813247188444\n","Validation elbo for fold 3, epoch 31: -22191.470606759758\n","Reconstruction accuracy for fold 3, epoch 31: 0.485821021720767\n","Training loss for fold 3, epoch 31: 191.2603016514932\n","Validation elbo for fold 3, epoch 32: -22131.00979517909\n","Reconstruction accuracy for fold 3, epoch 32: 0.48484307900071144\n","Training loss for fold 3, epoch 32: 190.60846144153226\n","Validation elbo for fold 3, epoch 33: -22101.533121806468\n","Reconstruction accuracy for fold 3, epoch 33: 0.48824500665068626\n","Training loss for fold 3, epoch 33: 190.96893999653477\n","Validation elbo for fold 3, epoch 34: -22010.394473551045\n","Reconstruction accuracy for fold 3, epoch 34: 0.4904315508902073\n","Training loss for fold 3, epoch 34: 190.000606167701\n","Validation elbo for fold 3, epoch 35: -21954.364122111456\n","Reconstruction accuracy for fold 3, epoch 35: 0.49362618662416935\n","Training loss for fold 3, epoch 35: 188.69043707078504\n","Validation elbo for fold 3, epoch 36: -21888.028126171266\n","Reconstruction accuracy for fold 3, epoch 36: 0.4945773109793663\n","Training loss for fold 3, epoch 36: 187.48121520011657\n","Validation elbo for fold 3, epoch 37: -21841.123903744156\n","Reconstruction accuracy for fold 3, epoch 37: 0.4987323358654976\n","Training loss for fold 3, epoch 37: 187.40971497566468\n","Validation elbo for fold 3, epoch 38: -21733.451171518987\n","Reconstruction accuracy for fold 3, epoch 38: 0.49994453601539135\n","Training loss for fold 3, epoch 38: 186.15043467860067\n","Validation elbo for fold 3, epoch 39: -21682.534889423365\n","Reconstruction accuracy for fold 3, epoch 39: 0.5001760218292475\n","Training loss for fold 3, epoch 39: 185.1118407710906\n","Validation elbo for fold 3, epoch 40: -21640.819786531516\n","Reconstruction accuracy for fold 3, epoch 40: 0.5022544302046299\n","Training loss for fold 3, epoch 40: 184.9185069914787\n","Validation elbo for fold 3, epoch 41: -21590.62069751097\n","Reconstruction accuracy for fold 3, epoch 41: 0.5064306128770113\n","Training loss for fold 3, epoch 41: 183.7672591670867\n","Validation elbo for fold 3, epoch 42: -21535.54787024037\n","Reconstruction accuracy for fold 3, epoch 42: 0.5073065049946308\n","Training loss for fold 3, epoch 42: 183.021482406124\n","Validation elbo for fold 3, epoch 43: -21491.41341149132\n","Reconstruction accuracy for fold 3, epoch 43: 0.5083728097379208\n","Training loss for fold 3, epoch 43: 181.87806307884955\n","Validation elbo for fold 3, epoch 44: -21420.958232158497\n","Reconstruction accuracy for fold 3, epoch 44: 0.5099164806306362\n","Training loss for fold 3, epoch 44: 181.5119889782321\n","Validation elbo for fold 3, epoch 45: -21391.21502136662\n","Reconstruction accuracy for fold 3, epoch 45: 0.5132283829152584\n","Training loss for fold 3, epoch 45: 180.4745813185169\n","Validation elbo for fold 3, epoch 46: -21340.10698599222\n","Reconstruction accuracy for fold 3, epoch 46: 0.5124968588352203\n","Training loss for fold 3, epoch 46: 180.93461338166267\n","Validation elbo for fold 3, epoch 47: -21330.235109446712\n","Reconstruction accuracy for fold 3, epoch 47: 0.5141936056315899\n","Training loss for fold 3, epoch 47: 180.4785892117408\n","Validation elbo for fold 3, epoch 48: -21305.07589004375\n","Reconstruction accuracy for fold 3, epoch 48: 0.5147380325943232\n","Training loss for fold 3, epoch 48: 179.87105289582283\n","Validation elbo for fold 3, epoch 49: -21211.000354782944\n","Reconstruction accuracy for fold 3, epoch 49: 0.5181973446160555\n","Training loss for fold 3, epoch 49: 179.1651891892956\n","Validation elbo for fold 3, epoch 50: -21188.75728058071\n","Reconstruction accuracy for fold 3, epoch 50: 0.5188138168305159\n","Training loss for fold 3, epoch 50: 178.08130670362902\n","Validation elbo for fold 3, epoch 51: -21203.983163961486\n","Reconstruction accuracy for fold 3, epoch 51: 0.5192695967853069\n","Training loss for fold 3, epoch 51: 178.15648601901145\n","Validation elbo for fold 3, epoch 52: -21117.303605173038\n","Reconstruction accuracy for fold 3, epoch 52: 0.5217639617621899\n","Training loss for fold 3, epoch 52: 177.03765549198275\n","Validation elbo for fold 3, epoch 53: -21092.422954556343\n","Reconstruction accuracy for fold 3, epoch 53: 0.5205860659480095\n","Training loss for fold 3, epoch 53: 176.9440666937059\n","Validation elbo for fold 3, epoch 54: -21054.8542635799\n","Reconstruction accuracy for fold 3, epoch 54: 0.5244800113141537\n","Training loss for fold 3, epoch 54: 176.30665883710307\n","Validation elbo for fold 3, epoch 55: -21005.623604932753\n","Reconstruction accuracy for fold 3, epoch 55: 0.5240961313247681\n","Training loss for fold 3, epoch 55: 175.93558231476814\n","Validation elbo for fold 3, epoch 56: -20948.43699697756\n","Reconstruction accuracy for fold 3, epoch 56: 0.5261587798595428\n","Training loss for fold 3, epoch 56: 175.83555529194493\n","Validation elbo for fold 3, epoch 57: -20976.39701701021\n","Reconstruction accuracy for fold 3, epoch 57: 0.527748629450798\n","Training loss for fold 3, epoch 57: 174.6349841702369\n","Validation elbo for fold 3, epoch 58: -20901.299406080405\n","Reconstruction accuracy for fold 3, epoch 58: 0.5296331718564034\n","Training loss for fold 3, epoch 58: 174.77770405430948\n","Validation elbo for fold 3, epoch 59: -20938.362463317644\n","Reconstruction accuracy for fold 3, epoch 59: 0.5268576592206955\n","Training loss for fold 3, epoch 59: 174.01204779840285\n","Validation elbo for fold 3, epoch 60: -20858.103210492856\n","Reconstruction accuracy for fold 3, epoch 60: 0.5300094373524189\n","Training loss for fold 3, epoch 60: 173.42508968230217\n","Validation elbo for fold 3, epoch 61: -20856.807406161766\n","Reconstruction accuracy for fold 3, epoch 61: 0.528664480894804\n","Training loss for fold 3, epoch 61: 173.45809493526335\n","Validation elbo for fold 3, epoch 62: -20794.440376418326\n","Reconstruction accuracy for fold 3, epoch 62: 0.533271424472332\n","Training loss for fold 3, epoch 62: 173.12860550418978\n","Validation elbo for fold 3, epoch 63: -20769.579333390036\n","Reconstruction accuracy for fold 3, epoch 63: 0.5314587913453579\n","Training loss for fold 3, epoch 63: 172.32292815177672\n","Validation elbo for fold 3, epoch 64: -20779.382835266955\n","Reconstruction accuracy for fold 3, epoch 64: 0.5299058556556702\n","Training loss for fold 3, epoch 64: 172.70519059704196\n","Validation elbo for fold 3, epoch 65: -20779.334340808782\n","Reconstruction accuracy for fold 3, epoch 65: 0.5312936827540398\n","Training loss for fold 3, epoch 65: 171.52885240124118\n","Validation elbo for fold 3, epoch 66: -20701.00175606568\n","Reconstruction accuracy for fold 3, epoch 66: 0.5329590402543545\n","Training loss for fold 3, epoch 66: 170.97411469490297\n","Validation elbo for fold 3, epoch 67: -20664.954058449723\n","Reconstruction accuracy for fold 3, epoch 67: 0.5347068123519421\n","Training loss for fold 3, epoch 67: 170.87010906588645\n","Validation elbo for fold 3, epoch 68: -20655.91123759117\n","Reconstruction accuracy for fold 3, epoch 68: 0.5344764273613691\n","Training loss for fold 3, epoch 68: 170.91979192918348\n","Validation elbo for fold 3, epoch 69: -20651.439578183148\n","Reconstruction accuracy for fold 3, epoch 69: 0.5350019037723541\n","Training loss for fold 3, epoch 69: 170.07855199998426\n","Validation elbo for fold 3, epoch 70: -20635.379287407108\n","Reconstruction accuracy for fold 3, epoch 70: 0.5356521159410477\n","Training loss for fold 3, epoch 70: 170.06822721419795\n","Validation elbo for fold 3, epoch 71: -20621.760029970494\n","Reconstruction accuracy for fold 3, epoch 71: 0.5368439964950085\n","Training loss for fold 3, epoch 71: 169.55461760490172\n","Validation elbo for fold 3, epoch 72: -20602.457482201815\n","Reconstruction accuracy for fold 3, epoch 72: 0.537463091313839\n","Training loss for fold 3, epoch 72: 169.25025250834804\n","Validation elbo for fold 3, epoch 73: -20569.11054698831\n","Reconstruction accuracy for fold 3, epoch 73: 0.5375152230262756\n","Training loss for fold 3, epoch 73: 168.39776168331022\n","Validation elbo for fold 3, epoch 74: -20549.081457815664\n","Reconstruction accuracy for fold 3, epoch 74: 0.5391758792102337\n","Training loss for fold 3, epoch 74: 168.0707471293788\n","Validation elbo for fold 3, epoch 75: -20523.33647414342\n","Reconstruction accuracy for fold 3, epoch 75: 0.5395117588341236\n","Training loss for fold 3, epoch 75: 168.324334667575\n","Validation elbo for fold 3, epoch 76: -20520.96095435031\n","Reconstruction accuracy for fold 3, epoch 76: 0.5390952527523041\n","Training loss for fold 3, epoch 76: 168.03135262766193\n","Validation elbo for fold 3, epoch 77: -20520.898339150845\n","Reconstruction accuracy for fold 3, epoch 77: 0.5384045243263245\n","Training loss for fold 3, epoch 77: 167.12475536715598\n","Validation elbo for fold 3, epoch 78: -20470.848060881555\n","Reconstruction accuracy for fold 3, epoch 78: 0.5419190190732479\n","Training loss for fold 3, epoch 78: 167.16825472924018\n","Validation elbo for fold 3, epoch 79: -20460.000405195096\n","Reconstruction accuracy for fold 3, epoch 79: 0.5404169671237469\n","Training loss for fold 3, epoch 79: 166.86233495896863\n","Validation elbo for fold 3, epoch 80: -20428.670116002715\n","Reconstruction accuracy for fold 3, epoch 80: 0.5428463518619537\n","Training loss for fold 3, epoch 80: 165.81261764034147\n","Validation elbo for fold 3, epoch 81: -20437.92056326298\n","Reconstruction accuracy for fold 3, epoch 81: 0.5431909486651421\n","Training loss for fold 3, epoch 81: 166.4683611469884\n","Validation elbo for fold 3, epoch 82: -20426.013079267945\n","Reconstruction accuracy for fold 3, epoch 82: 0.5391379855573177\n","Training loss for fold 3, epoch 82: 165.47821094143777\n","Validation elbo for fold 3, epoch 83: -20416.35155211848\n","Reconstruction accuracy for fold 3, epoch 83: 0.5417995378375053\n","Training loss for fold 3, epoch 83: 165.65332080471902\n","Validation elbo for fold 3, epoch 84: -20363.256986020642\n","Reconstruction accuracy for fold 3, epoch 84: 0.5439519360661507\n","Training loss for fold 3, epoch 84: 165.1561796126827\n","Validation elbo for fold 3, epoch 85: -20334.705181804115\n","Reconstruction accuracy for fold 3, epoch 85: 0.543693482875824\n","Training loss for fold 3, epoch 85: 164.70532718781502\n","Validation elbo for fold 3, epoch 86: -20360.061138640966\n","Reconstruction accuracy for fold 3, epoch 86: 0.5449340231716633\n","Training loss for fold 3, epoch 86: 165.73353281328755\n","Validation elbo for fold 3, epoch 87: -20350.09939911683\n","Reconstruction accuracy for fold 3, epoch 87: 0.5409152135252953\n","Training loss for fold 3, epoch 87: 164.50723463489163\n","Validation elbo for fold 3, epoch 88: -20318.968045057136\n","Reconstruction accuracy for fold 3, epoch 88: 0.5442200675606728\n","Training loss for fold 3, epoch 88: 164.49608046008694\n","Validation elbo for fold 3, epoch 89: -20305.98736951614\n","Reconstruction accuracy for fold 3, epoch 89: 0.5454589575529099\n","Training loss for fold 3, epoch 89: 163.81799365628152\n","Validation elbo for fold 3, epoch 90: -20273.148188915176\n","Reconstruction accuracy for fold 3, epoch 90: 0.5449215807020664\n","Training loss for fold 3, epoch 90: 162.89931143483807\n","Validation elbo for fold 3, epoch 91: -20295.657772135284\n","Reconstruction accuracy for fold 3, epoch 91: 0.5438092239201069\n","Training loss for fold 3, epoch 91: 162.95660498834425\n","Validation elbo for fold 3, epoch 92: -20287.58549845627\n","Reconstruction accuracy for fold 3, epoch 92: 0.5448196679353714\n","Training loss for fold 3, epoch 92: 163.47051632788873\n","Validation elbo for fold 3, epoch 93: -20240.68377152522\n","Reconstruction accuracy for fold 3, epoch 93: 0.5487237051129341\n","Training loss for fold 3, epoch 93: 162.78851909022177\n","Validation elbo for fold 3, epoch 94: -20234.80468272765\n","Reconstruction accuracy for fold 3, epoch 94: 0.5465598255395889\n","Training loss for fold 3, epoch 94: 161.94170674970073\n","Validation elbo for fold 3, epoch 95: -20201.26313378776\n","Reconstruction accuracy for fold 3, epoch 95: 0.5496468879282475\n","Training loss for fold 3, epoch 95: 162.54711667952998\n","Validation elbo for fold 3, epoch 96: -20205.128323871195\n","Reconstruction accuracy for fold 3, epoch 96: 0.5485880486667156\n","Training loss for fold 3, epoch 96: 162.43345888199346\n","Validation elbo for fold 3, epoch 97: -20204.548752353574\n","Reconstruction accuracy for fold 3, epoch 97: 0.5474055856466293\n","Training loss for fold 3, epoch 97: 162.5157758651241\n","Validation elbo for fold 3, epoch 98: -20233.731194745444\n","Reconstruction accuracy for fold 3, epoch 98: 0.5506506897509098\n","Training loss for fold 3, epoch 98: 161.9440442977413\n","Validation elbo for fold 3, epoch 99: -20173.00469966077\n","Reconstruction accuracy for fold 3, epoch 99: 0.550773624330759\n","Training loss for fold 3, epoch 99: 161.7386504142515\n","Validation elbo for fold 3, epoch 100: -20178.645370614817\n","Reconstruction accuracy for fold 3, epoch 100: 0.5483457781374454\n","Training loss for fold 3, epoch 100: 161.70752666842552\n","Validation elbo for fold 3, epoch 101: -20182.166825561108\n","Reconstruction accuracy for fold 3, epoch 101: 0.5466978400945663\n","Training loss for fold 3, epoch 101: 161.48664831346082\n","Validation elbo for fold 3, epoch 102: -20199.63590615277\n","Reconstruction accuracy for fold 3, epoch 102: 0.548211220651865\n","Training loss for fold 3, epoch 102: 161.64564021941155\n","Validation elbo for fold 3, epoch 103: -20135.24962015068\n","Reconstruction accuracy for fold 3, epoch 103: 0.5509720556437969\n","Training loss for fold 3, epoch 103: 160.68678775910408\n","Validation elbo for fold 3, epoch 104: -20134.07558004539\n","Reconstruction accuracy for fold 3, epoch 104: 0.5519789196550846\n","Training loss for fold 3, epoch 104: 160.68370745258946\n","Validation elbo for fold 3, epoch 105: -20149.205909715965\n","Reconstruction accuracy for fold 3, epoch 105: 0.5498349592089653\n","Training loss for fold 3, epoch 105: 159.44910996960056\n","Validation elbo for fold 3, epoch 106: -20129.757974614284\n","Reconstruction accuracy for fold 3, epoch 106: 0.549768578261137\n","Training loss for fold 3, epoch 106: 160.9040485505135\n","Validation elbo for fold 3, epoch 107: -20175.337159982704\n","Reconstruction accuracy for fold 3, epoch 107: 0.5486942492425442\n","Training loss for fold 3, epoch 107: 160.74470692296183\n","Validation elbo for fold 3, epoch 108: -20103.728024376705\n","Reconstruction accuracy for fold 3, epoch 108: 0.5486351996660233\n","Training loss for fold 3, epoch 108: 159.65053066130608\n","Validation elbo for fold 3, epoch 109: -20082.475218495038\n","Reconstruction accuracy for fold 3, epoch 109: 0.5534144416451454\n","Training loss for fold 3, epoch 109: 159.7257460317304\n","Validation elbo for fold 3, epoch 110: -20062.348075229253\n","Reconstruction accuracy for fold 3, epoch 110: 0.5517244674265385\n","Training loss for fold 3, epoch 110: 159.1677984422253\n","Validation elbo for fold 3, epoch 111: -20072.971292313843\n","Reconstruction accuracy for fold 3, epoch 111: 0.5503517165780067\n","Training loss for fold 3, epoch 111: 158.65865768924837\n","Validation elbo for fold 3, epoch 112: -20092.13319165356\n","Reconstruction accuracy for fold 3, epoch 112: 0.5515264421701431\n","Training loss for fold 3, epoch 112: 159.1115720195155\n","Validation elbo for fold 3, epoch 113: -20088.061112666066\n","Reconstruction accuracy for fold 3, epoch 113: 0.5517092607915401\n","Training loss for fold 3, epoch 113: 159.12108144452495\n","Validation elbo for fold 3, epoch 114: -20077.682739569147\n","Reconstruction accuracy for fold 3, epoch 114: 0.5545301176607609\n","Training loss for fold 3, epoch 114: 158.38689299552672\n","Validation elbo for fold 3, epoch 115: -20076.064371025124\n","Reconstruction accuracy for fold 3, epoch 115: 0.5519176460802555\n","Training loss for fold 3, epoch 115: 158.37418660809917\n","Validation elbo for fold 3, epoch 116: -20054.90512519484\n","Reconstruction accuracy for fold 3, epoch 116: 0.5538363456726074\n","Training loss for fold 3, epoch 116: 158.53278990714782\n","Validation elbo for fold 3, epoch 117: -20014.519465115885\n","Reconstruction accuracy for fold 3, epoch 117: 0.5547746047377586\n","Training loss for fold 3, epoch 117: 157.98435703400642\n","Validation elbo for fold 3, epoch 118: -20102.976442678875\n","Reconstruction accuracy for fold 3, epoch 118: 0.5508987754583359\n","Training loss for fold 3, epoch 118: 158.7155018468057\n","Validation elbo for fold 3, epoch 119: -20032.387058156608\n","Reconstruction accuracy for fold 3, epoch 119: 0.5539006441831589\n","Training loss for fold 3, epoch 119: 157.8345579331921\n","Validation elbo for fold 3, epoch 120: -20026.49997329558\n","Reconstruction accuracy for fold 3, epoch 120: 0.5532035455107689\n","Training loss for fold 3, epoch 120: 157.74491783880418\n","Validation elbo for fold 3, epoch 121: -20031.956779619526\n","Reconstruction accuracy for fold 3, epoch 121: 0.5523312576115131\n","Training loss for fold 3, epoch 121: 157.65735404722153\n","Validation elbo for fold 3, epoch 122: -20044.88938535317\n","Reconstruction accuracy for fold 3, epoch 122: 0.5524544715881348\n","Training loss for fold 3, epoch 122: 157.12722655265563\n","Validation elbo for fold 3, epoch 123: -20017.4281782246\n","Reconstruction accuracy for fold 3, epoch 123: 0.5541126392781734\n","Training loss for fold 3, epoch 123: 157.20415509131647\n","Validation elbo for fold 3, epoch 124: -19994.986854763654\n","Reconstruction accuracy for fold 3, epoch 124: 0.5543424673378468\n","Training loss for fold 3, epoch 124: 157.50031920402282\n","Validation elbo for fold 3, epoch 125: -20001.457912688653\n","Reconstruction accuracy for fold 3, epoch 125: 0.5557703860104084\n","Training loss for fold 3, epoch 125: 157.0673323600523\n","Validation elbo for fold 3, epoch 126: -19980.02886944089\n","Reconstruction accuracy for fold 3, epoch 126: 0.5550156310200691\n","Training loss for fold 3, epoch 126: 156.9977313626197\n","Validation elbo for fold 3, epoch 127: -19981.269465237605\n","Reconstruction accuracy for fold 3, epoch 127: 0.552361823618412\n","Training loss for fold 3, epoch 127: 157.25865862446446\n","Validation elbo for fold 3, epoch 128: -20021.55300705099\n","Reconstruction accuracy for fold 3, epoch 128: 0.5555978044867516\n","Training loss for fold 3, epoch 128: 156.76322297127015\n","Validation elbo for fold 3, epoch 129: -19960.1217527563\n","Reconstruction accuracy for fold 3, epoch 129: 0.5543262921273708\n","Training loss for fold 3, epoch 129: 156.26455934586065\n","Validation elbo for fold 3, epoch 130: -19940.68472881439\n","Reconstruction accuracy for fold 3, epoch 130: 0.5569456703960896\n","Training loss for fold 3, epoch 130: 155.88569911833733\n","Validation elbo for fold 3, epoch 131: -20004.85536401552\n","Reconstruction accuracy for fold 3, epoch 131: 0.5571172721683979\n","Training loss for fold 3, epoch 131: 156.93263293850808\n","Validation elbo for fold 3, epoch 132: -19977.051809545203\n","Reconstruction accuracy for fold 3, epoch 132: 0.558306373655796\n","Training loss for fold 3, epoch 132: 156.20404692619078\n","Validation elbo for fold 3, epoch 133: -19963.376641880004\n","Reconstruction accuracy for fold 3, epoch 133: 0.5569433122873306\n","Training loss for fold 3, epoch 133: 156.6090624409337\n","Validation elbo for fold 3, epoch 134: -19983.6898624635\n","Reconstruction accuracy for fold 3, epoch 134: 0.5554373972117901\n","Training loss for fold 3, epoch 134: 156.50309876472718\n","Validation elbo for fold 3, epoch 135: -19978.797319992213\n","Reconstruction accuracy for fold 3, epoch 135: 0.555011622607708\n","Training loss for fold 3, epoch 135: 156.33827455582158\n","Validation elbo for fold 3, epoch 136: -19984.3319770409\n","Reconstruction accuracy for fold 3, epoch 136: 0.5544966533780098\n","Training loss for fold 3, epoch 136: 155.5476056991085\n","Validation elbo for fold 3, epoch 137: -19914.95826237822\n","Reconstruction accuracy for fold 3, epoch 137: 0.5563845038414001\n","Training loss for fold 3, epoch 137: 155.46129780430948\n","Validation elbo for fold 3, epoch 138: -19957.834721263298\n","Reconstruction accuracy for fold 3, epoch 138: 0.5570822842419147\n","Training loss for fold 3, epoch 138: 155.64953564059348\n","Validation elbo for fold 3, epoch 139: -19934.499250699308\n","Reconstruction accuracy for fold 3, epoch 139: 0.5539321713149548\n","Training loss for fold 3, epoch 139: 155.33196332377773\n","Validation elbo for fold 3, epoch 140: -19945.21066755718\n","Reconstruction accuracy for fold 3, epoch 140: 0.5586161315441132\n","Training loss for fold 3, epoch 140: 155.67171675159085\n","Validation elbo for fold 3, epoch 141: -19952.35092121661\n","Reconstruction accuracy for fold 3, epoch 141: 0.5571644268929958\n","Training loss for fold 3, epoch 141: 155.46644641507058\n","Validation elbo for fold 3, epoch 142: -19900.87562831323\n","Reconstruction accuracy for fold 3, epoch 142: 0.5562188439071178\n","Training loss for fold 3, epoch 142: 153.94029285061745\n","Validation elbo for fold 3, epoch 143: -19928.423802639096\n","Reconstruction accuracy for fold 3, epoch 143: 0.5582654513418674\n","Training loss for fold 3, epoch 143: 155.1094453873173\n","Validation elbo for fold 3, epoch 144: -19956.933940667663\n","Reconstruction accuracy for fold 3, epoch 144: 0.5589749775826931\n","Training loss for fold 3, epoch 144: 154.6810580838111\n","Validation elbo for fold 3, epoch 145: -19937.203643277637\n","Reconstruction accuracy for fold 3, epoch 145: 0.5582110993564129\n","Training loss for fold 3, epoch 145: 155.6450879496913\n","Validation elbo for fold 3, epoch 146: -19950.20194365424\n","Reconstruction accuracy for fold 3, epoch 146: 0.5594073943793774\n","Training loss for fold 3, epoch 146: 155.3675827518586\n","Validation elbo for fold 3, epoch 147: -19947.450764551937\n","Reconstruction accuracy for fold 3, epoch 147: 0.5568324141204357\n","Training loss for fold 3, epoch 147: 154.78621378252583\n","Validation elbo for fold 3, epoch 148: -19925.399673461645\n","Reconstruction accuracy for fold 3, epoch 148: 0.5559858344495296\n","Training loss for fold 3, epoch 148: 154.4684108611076\n","Validation elbo for fold 3, epoch 149: -19960.28520019517\n","Reconstruction accuracy for fold 3, epoch 149: 0.5564005449414253\n","Training loss for fold 3, epoch 149: 154.21358686877835\n","Validation elbo for fold 3, epoch 150: -19909.323234804833\n","Reconstruction accuracy for fold 3, epoch 150: 0.5591933317482471\n","Training loss for fold 3, epoch 150: 154.39724411502962\n","Validation elbo for fold 3, epoch 151: -19919.99041968589\n","Reconstruction accuracy for fold 3, epoch 151: 0.5574390664696693\n","Training loss for fold 3, epoch 151: 153.8405749413275\n","Validation elbo for fold 3, epoch 152: -19905.10275414282\n","Reconstruction accuracy for fold 3, epoch 152: 0.5579135045409203\n","Training loss for fold 3, epoch 152: 153.88578279556768\n","Validation elbo for fold 3, epoch 153: -19874.401583426406\n","Reconstruction accuracy for fold 3, epoch 153: 0.5604229643940926\n","Training loss for fold 3, epoch 153: 153.76045940768333\n","Validation elbo for fold 3, epoch 154: -19928.262760804\n","Reconstruction accuracy for fold 3, epoch 154: 0.5592118613421917\n","Training loss for fold 3, epoch 154: 154.35963366108555\n","Validation elbo for fold 3, epoch 155: -19856.68008580264\n","Reconstruction accuracy for fold 3, epoch 155: 0.5624608546495438\n","Training loss for fold 3, epoch 155: 154.34868695659023\n","Validation elbo for fold 3, epoch 156: -19863.973514019584\n","Reconstruction accuracy for fold 3, epoch 156: 0.5608599297702312\n","Training loss for fold 3, epoch 156: 153.4886009462418\n","Validation elbo for fold 3, epoch 157: -19893.74495080649\n","Reconstruction accuracy for fold 3, epoch 157: 0.5607777945697308\n","Training loss for fold 3, epoch 157: 152.97170085291708\n","Validation elbo for fold 3, epoch 158: -19921.493646032486\n","Reconstruction accuracy for fold 3, epoch 158: 0.5574624314904213\n","Training loss for fold 3, epoch 158: 153.01653634348224\n","Validation elbo for fold 3, epoch 159: -19901.283706467882\n","Reconstruction accuracy for fold 3, epoch 159: 0.5595523118972778\n","Training loss for fold 3, epoch 159: 152.67364378898375\n","Validation elbo for fold 3, epoch 160: -19906.158923348914\n","Reconstruction accuracy for fold 3, epoch 160: 0.560559444129467\n","Training loss for fold 3, epoch 160: 152.9208706271264\n","Validation elbo for fold 3, epoch 161: -19881.025134399348\n","Reconstruction accuracy for fold 3, epoch 161: 0.559965506196022\n","Training loss for fold 3, epoch 161: 152.7148705759356\n","Validation elbo for fold 3, epoch 162: -19851.81529026494\n","Reconstruction accuracy for fold 3, epoch 162: 0.5578720308840275\n","Training loss for fold 3, epoch 162: 153.07677582771547\n","Validation elbo for fold 3, epoch 163: -19879.26239294339\n","Reconstruction accuracy for fold 3, epoch 163: 0.5635310262441635\n","Training loss for fold 3, epoch 163: 152.25662034557712\n","Validation elbo for fold 3, epoch 164: -19913.816354376057\n","Reconstruction accuracy for fold 3, epoch 164: 0.5576069355010986\n","Training loss for fold 3, epoch 164: 153.01807428175402\n","Validation elbo for fold 3, epoch 165: -19865.104426235746\n","Reconstruction accuracy for fold 3, epoch 165: 0.558385469019413\n","Training loss for fold 3, epoch 165: 152.45508649272304\n","Validation elbo for fold 3, epoch 166: -19914.439589913996\n","Reconstruction accuracy for fold 3, epoch 166: 0.5597916878759861\n","Training loss for fold 3, epoch 166: 152.3899425383537\n","Validation elbo for fold 3, epoch 167: -19882.343371263727\n","Reconstruction accuracy for fold 3, epoch 167: 0.5584012381732464\n","Training loss for fold 3, epoch 167: 152.00441668110508\n","Validation elbo for fold 3, epoch 168: -19861.523938673938\n","Reconstruction accuracy for fold 3, epoch 168: 0.5605144985020161\n","Training loss for fold 3, epoch 168: 150.90724575904107\n","Validation elbo for fold 3, epoch 169: -19839.134839439168\n","Reconstruction accuracy for fold 3, epoch 169: 0.5627847090363503\n","Training loss for fold 3, epoch 169: 152.04148938578945\n","Validation elbo for fold 3, epoch 170: -19882.99608296046\n","Reconstruction accuracy for fold 3, epoch 170: 0.5603334866464138\n","Training loss for fold 3, epoch 170: 152.25010878039944\n","Validation elbo for fold 3, epoch 171: -19846.10555562829\n","Reconstruction accuracy for fold 3, epoch 171: 0.561612606048584\n","Training loss for fold 3, epoch 171: 152.1646574697187\n","Validation elbo for fold 3, epoch 172: -19845.899195643142\n","Reconstruction accuracy for fold 3, epoch 172: 0.5626847296953201\n","Training loss for fold 3, epoch 172: 152.0388439547631\n","Validation elbo for fold 3, epoch 173: -19869.36173121703\n","Reconstruction accuracy for fold 3, epoch 173: 0.5582234114408493\n","Training loss for fold 3, epoch 173: 152.18382140128844\n","Validation elbo for fold 3, epoch 174: -19859.82069814271\n","Reconstruction accuracy for fold 3, epoch 174: 0.5597130060195923\n","Training loss for fold 3, epoch 174: 151.74485163534843\n","Validation elbo for fold 3, epoch 175: -19848.215796120407\n","Reconstruction accuracy for fold 3, epoch 175: 0.5585843324661255\n","Training loss for fold 3, epoch 175: 151.01038065264302\n","Validation elbo for fold 3, epoch 176: -19858.54501027502\n","Reconstruction accuracy for fold 3, epoch 176: 0.5597625076770782\n","Training loss for fold 3, epoch 176: 151.06751177387852\n","Validation elbo for fold 3, epoch 177: -19808.8366154231\n","Reconstruction accuracy for fold 3, epoch 177: 0.5619854219257832\n","Training loss for fold 3, epoch 177: 152.54832433885144\n","Validation elbo for fold 3, epoch 178: -19920.71563264595\n","Reconstruction accuracy for fold 3, epoch 178: 0.5596156530082226\n","Training loss for fold 3, epoch 178: 152.2613279281124\n","Validation elbo for fold 3, epoch 179: -19884.02010896117\n","Reconstruction accuracy for fold 3, epoch 179: 0.5629890859127045\n","Training loss for fold 3, epoch 179: 151.0207477692635\n","Validation elbo for fold 3, epoch 180: -19864.34073220328\n","Reconstruction accuracy for fold 3, epoch 180: 0.5616776086390018\n","Training loss for fold 3, epoch 180: 151.5434353736139\n","Validation elbo for fold 3, epoch 181: -19871.652070573262\n","Reconstruction accuracy for fold 3, epoch 181: 0.5594115369021893\n","Training loss for fold 3, epoch 181: 151.02569407801474\n","Validation elbo for fold 3, epoch 182: -19808.193099913147\n","Reconstruction accuracy for fold 3, epoch 182: 0.5658020712435246\n","Training loss for fold 3, epoch 182: 150.84897958078693\n","Validation elbo for fold 3, epoch 183: -19843.346561582977\n","Reconstruction accuracy for fold 3, epoch 183: 0.5616057030856609\n","Training loss for fold 3, epoch 183: 151.6403094876197\n","Validation elbo for fold 3, epoch 184: -19874.585736775727\n","Reconstruction accuracy for fold 3, epoch 184: 0.5614546909928322\n","Training loss for fold 3, epoch 184: 150.76602911180066\n","Validation elbo for fold 3, epoch 185: -19826.391628954334\n","Reconstruction accuracy for fold 3, epoch 185: 0.5610883720219135\n","Training loss for fold 3, epoch 185: 150.86131286621094\n","Validation elbo for fold 3, epoch 186: -19824.55008257716\n","Reconstruction accuracy for fold 3, epoch 186: 0.560705192387104\n","Training loss for fold 3, epoch 186: 150.72773914952433\n","Validation elbo for fold 3, epoch 187: -19842.590836576717\n","Reconstruction accuracy for fold 3, epoch 187: 0.5616720765829086\n","Training loss for fold 3, epoch 187: 149.66205289286953\n","Validation elbo for fold 3, epoch 188: -19844.886013355605\n","Reconstruction accuracy for fold 3, epoch 188: 0.5623023808002472\n","Training loss for fold 3, epoch 188: 150.78385383852066\n","Validation elbo for fold 3, epoch 189: -19810.823328388487\n","Reconstruction accuracy for fold 3, epoch 189: 0.5647269114851952\n","Training loss for fold 3, epoch 189: 150.87180992864793\n","Validation elbo for fold 3, epoch 190: -19837.8749135529\n","Reconstruction accuracy for fold 3, epoch 190: 0.5613074116408825\n","Training loss for fold 3, epoch 190: 150.71547834334834\n","Validation elbo for fold 3, epoch 191: -19827.49163311733\n","Reconstruction accuracy for fold 3, epoch 191: 0.5615921467542648\n","Training loss for fold 3, epoch 191: 150.6364559050529\n","Validation elbo for fold 3, epoch 192: -19813.17392773709\n","Reconstruction accuracy for fold 3, epoch 192: 0.5623243637382984\n","Training loss for fold 3, epoch 192: 150.24451594198905\n","Validation elbo for fold 3, epoch 193: -19815.51271999567\n","Reconstruction accuracy for fold 3, epoch 193: 0.5645785294473171\n","Training loss for fold 3, epoch 193: 150.63853233091294\n","Validation elbo for fold 3, epoch 194: -19823.484065932138\n","Reconstruction accuracy for fold 3, epoch 194: 0.5642566010355949\n","Training loss for fold 3, epoch 194: 149.7761466733871\n","Validation elbo for fold 3, epoch 195: -19861.232538733493\n","Reconstruction accuracy for fold 3, epoch 195: 0.562098540365696\n","Training loss for fold 3, epoch 195: 150.7545653312437\n","Validation elbo for fold 3, epoch 196: -19841.05387497779\n","Reconstruction accuracy for fold 3, epoch 196: 0.5638835169374943\n","Training loss for fold 3, epoch 196: 150.2585737166866\n","Validation elbo for fold 3, epoch 197: -19845.264106235507\n","Reconstruction accuracy for fold 3, epoch 197: 0.5588115304708481\n","Training loss for fold 3, epoch 197: 150.4589699775942\n","Validation elbo for fold 3, epoch 198: -19827.05868319566\n","Reconstruction accuracy for fold 3, epoch 198: 0.5621036626398563\n","Training loss for fold 3, epoch 198: 150.57559597876764\n","Validation elbo for fold 3, epoch 199: -19823.072788098507\n","Reconstruction accuracy for fold 3, epoch 199: 0.5619296953082085\n","Training loss for fold 3, epoch 199: 149.66335530434884\n","Validation elbo for fold 3, epoch 200: -19822.446784746804\n","Reconstruction accuracy for fold 3, epoch 200: 0.5633262321352959\n","Training loss for fold 3, epoch 200: 149.51607882591986\n","Validation elbo for fold 3, epoch 201: -19818.323373653155\n","Reconstruction accuracy for fold 3, epoch 201: 0.5636825822293758\n","Training loss for fold 3, epoch 201: 149.87682539416897\n","Validation elbo for fold 3, epoch 202: -19833.218237503577\n","Reconstruction accuracy for fold 3, epoch 202: 0.5623653009533882\n","Training loss for fold 3, epoch 202: 149.56490916590536\n","Validation elbo for fold 3, epoch 203: -19823.074312737957\n","Reconstruction accuracy for fold 3, epoch 203: 0.5655224546790123\n","Training loss for fold 3, epoch 203: 149.08435624645603\n","Validation elbo for fold 3, epoch 204: -19825.296201086894\n","Reconstruction accuracy for fold 3, epoch 204: 0.5630799494683743\n","Training loss for fold 3, epoch 204: 149.55846724971647\n","Validation elbo for fold 3, epoch 205: -19862.092878261246\n","Reconstruction accuracy for fold 3, epoch 205: 0.5607262179255486\n","Training loss for fold 3, epoch 205: 148.5857810974121\n","Validation elbo for fold 3, epoch 206: -19856.705863754425\n","Reconstruction accuracy for fold 3, epoch 206: 0.5624055303633213\n","Training loss for fold 3, epoch 206: 149.87119883875692\n","Validation elbo for fold 3, epoch 207: -19921.067367822827\n","Reconstruction accuracy for fold 3, epoch 207: 0.559332724660635\n","Training loss for fold 3, epoch 207: 149.41878903296686\n","Validation elbo for fold 3, epoch 208: -19929.620646329284\n","Reconstruction accuracy for fold 3, epoch 208: 0.5624766126275063\n","Training loss for fold 3, epoch 208: 149.97452938941217\n","Validation elbo for fold 3, epoch 209: -19821.662726406055\n","Reconstruction accuracy for fold 3, epoch 209: 0.5609128959476948\n","Training loss for fold 3, epoch 209: 149.5920643960276\n","Validation elbo for fold 3, epoch 210: -19834.247379514938\n","Reconstruction accuracy for fold 3, epoch 210: 0.5632537715137005\n","Training loss for fold 3, epoch 210: 149.6842508623677\n","Validation elbo for fold 3, epoch 211: -19762.29660487717\n","Reconstruction accuracy for fold 3, epoch 211: 0.5631882213056087\n","Training loss for fold 3, epoch 211: 148.70890549690492\n","Validation elbo for fold 3, epoch 212: -19852.69589051298\n","Reconstruction accuracy for fold 3, epoch 212: 0.5619023106992245\n","Training loss for fold 3, epoch 212: 149.40419313984532\n","Validation elbo for fold 3, epoch 213: -19838.490997672918\n","Reconstruction accuracy for fold 3, epoch 213: 0.5649897903203964\n","Training loss for fold 3, epoch 213: 149.701664094002\n","Validation elbo for fold 3, epoch 214: -19862.62537635737\n","Reconstruction accuracy for fold 3, epoch 214: 0.5635951906442642\n","Training loss for fold 3, epoch 214: 149.13103928104525\n","Validation elbo for fold 3, epoch 215: -19787.506720458692\n","Reconstruction accuracy for fold 3, epoch 215: 0.5650293342769146\n","Training loss for fold 3, epoch 215: 148.76100577077557\n","Validation elbo for fold 3, epoch 216: -19793.018835691208\n","Reconstruction accuracy for fold 3, epoch 216: 0.5632725805044174\n","Training loss for fold 3, epoch 216: 149.61590428506173\n","Validation elbo for fold 3, epoch 217: -19805.68828152802\n","Reconstruction accuracy for fold 3, epoch 217: 0.5636763647198677\n","Training loss for fold 3, epoch 217: 149.10900940433626\n","Validation elbo for fold 3, epoch 218: -19851.510674366975\n","Reconstruction accuracy for fold 3, epoch 218: 0.5631006918847561\n","Training loss for fold 3, epoch 218: 149.30784077798165\n","Validation elbo for fold 3, epoch 219: -19843.747700690576\n","Reconstruction accuracy for fold 3, epoch 219: 0.5613241530954838\n","Training loss for fold 3, epoch 219: 148.80101357736896\n","Validation elbo for fold 3, epoch 220: -19773.328655353984\n","Reconstruction accuracy for fold 3, epoch 220: 0.5617174357175827\n","Training loss for fold 3, epoch 220: 148.35023473924207\n","Validation elbo for fold 3, epoch 221: -19802.52774881723\n","Reconstruction accuracy for fold 3, epoch 221: 0.5635058581829071\n","Training loss for fold 3, epoch 221: 148.41485546481223\n","Validation elbo for fold 3, epoch 222: -19835.347057091494\n","Reconstruction accuracy for fold 3, epoch 222: 0.5624052584171295\n","Training loss for fold 3, epoch 222: 149.1780715450164\n","Validation elbo for fold 3, epoch 223: -19818.724874456046\n","Reconstruction accuracy for fold 3, epoch 223: 0.5642644986510277\n","Training loss for fold 3, epoch 223: 149.30679038263136\n","Validation elbo for fold 3, epoch 224: -19846.401525198387\n","Reconstruction accuracy for fold 3, epoch 224: 0.5629101358354092\n","Training loss for fold 3, epoch 224: 149.29651592623802\n","Validation elbo for fold 3, epoch 225: -19851.70656813818\n","Reconstruction accuracy for fold 3, epoch 225: 0.5604423210024834\n","Training loss for fold 3, epoch 225: 147.977411823888\n","Validation elbo for fold 3, epoch 226: -19801.426653727747\n","Reconstruction accuracy for fold 3, epoch 226: 0.5654455758631229\n","Training loss for fold 3, epoch 226: 149.74260613226122\n","Validation elbo for fold 3, epoch 227: -19817.6377619092\n","Reconstruction accuracy for fold 3, epoch 227: 0.5650395676493645\n","Training loss for fold 3, epoch 227: 148.60347255583733\n","Validation elbo for fold 3, epoch 228: -19807.879187452392\n","Reconstruction accuracy for fold 3, epoch 228: 0.563753254711628\n","Training loss for fold 3, epoch 228: 148.2973445769279\n","Validation elbo for fold 3, epoch 229: -19859.0335379774\n","Reconstruction accuracy for fold 3, epoch 229: 0.5631583482027054\n","Training loss for fold 3, epoch 229: 148.12460684007215\n","Validation elbo for fold 3, epoch 230: -19852.03205556288\n","Reconstruction accuracy for fold 3, epoch 230: 0.5609962865710258\n","Training loss for fold 3, epoch 230: 147.9698138083181\n","Validation elbo for fold 3, epoch 231: -19804.702075515394\n","Reconstruction accuracy for fold 3, epoch 231: 0.5652602687478065\n","Training loss for fold 3, epoch 231: 148.0061492919922\n","Validation elbo for fold 3, epoch 232: -19820.038951845818\n","Reconstruction accuracy for fold 3, epoch 232: 0.5635297819972038\n","Training loss for fold 3, epoch 232: 147.93599356374432\n","Validation elbo for fold 3, epoch 233: -19803.98004916608\n","Reconstruction accuracy for fold 3, epoch 233: 0.5629821792244911\n","Training loss for fold 3, epoch 233: 148.0671098770634\n","Validation elbo for fold 3, epoch 234: -19796.6973899973\n","Reconstruction accuracy for fold 3, epoch 234: 0.5625221021473408\n","Training loss for fold 3, epoch 234: 147.81252128847183\n","Validation elbo for fold 3, epoch 235: -19834.022178905594\n","Reconstruction accuracy for fold 3, epoch 235: 0.5631770342588425\n","Training loss for fold 3, epoch 235: 148.38960327640658\n","Validation elbo for fold 3, epoch 236: -19833.48285839952\n","Reconstruction accuracy for fold 3, epoch 236: 0.5639410354197025\n","Training loss for fold 3, epoch 236: 147.92614155430948\n","Validation elbo for fold 3, epoch 237: -19783.64636019908\n","Reconstruction accuracy for fold 3, epoch 237: 0.5630628056824207\n","Training loss for fold 3, epoch 237: 147.90319578109248\n","Validation elbo for fold 3, epoch 238: -19792.059695734868\n","Reconstruction accuracy for fold 3, epoch 238: 0.5632020458579063\n","Training loss for fold 3, epoch 238: 147.56247981902092\n","Validation elbo for fold 3, epoch 239: -19768.816882799336\n","Reconstruction accuracy for fold 3, epoch 239: 0.5644515790045261\n","Training loss for fold 3, epoch 239: 146.92157326975178\n","Validation elbo for fold 3, epoch 240: -19829.053356968136\n","Reconstruction accuracy for fold 3, epoch 240: 0.5614777840673923\n","Training loss for fold 3, epoch 240: 148.33445579774917\n","Validation elbo for fold 3, epoch 241: -19829.151543530526\n","Reconstruction accuracy for fold 3, epoch 241: 0.5657221376895905\n","Training loss for fold 3, epoch 241: 148.04294032435263\n","Validation elbo for fold 3, epoch 242: -19800.758696661236\n","Reconstruction accuracy for fold 3, epoch 242: 0.563331488519907\n","Training loss for fold 3, epoch 242: 147.72843576246692\n","Validation elbo for fold 3, epoch 243: -19814.20371750733\n","Reconstruction accuracy for fold 3, epoch 243: 0.564089696854353\n","Training loss for fold 3, epoch 243: 147.75919711205268\n","Validation elbo for fold 3, epoch 244: -19857.65210928749\n","Reconstruction accuracy for fold 3, epoch 244: 0.5644609928131104\n","Training loss for fold 3, epoch 244: 148.1932716369629\n","Validation elbo for fold 3, epoch 245: -19770.566150816223\n","Reconstruction accuracy for fold 3, epoch 245: 0.5645573697984219\n","Training loss for fold 3, epoch 245: 148.37506866455078\n","Validation elbo for fold 3, epoch 246: -19843.904619831985\n","Reconstruction accuracy for fold 3, epoch 246: 0.5623565800487995\n","Training loss for fold 3, epoch 246: 146.5485434993621\n","Validation elbo for fold 3, epoch 247: -19790.15930393012\n","Reconstruction accuracy for fold 3, epoch 247: 0.5610687471926212\n","Training loss for fold 3, epoch 247: 147.26002871605658\n","Validation elbo for fold 3, epoch 248: -19872.04353964336\n","Reconstruction accuracy for fold 3, epoch 248: 0.5631855949759483\n","Training loss for fold 3, epoch 248: 147.7113872651131\n","Validation elbo for fold 3, epoch 249: -19786.637906532527\n","Reconstruction accuracy for fold 3, epoch 249: 0.5633627250790596\n","Training loss for fold 3, epoch 249: 147.41631194083922\n","Validation elbo for fold 3, epoch 250: -19769.829185405764\n","Reconstruction accuracy for fold 3, epoch 250: 0.5660412982106209\n","Training loss for fold 3, epoch 250: 147.05585159793978\n","Validation elbo for fold 3, epoch 251: -19827.56594359079\n","Reconstruction accuracy for fold 3, epoch 251: 0.5631113350391388\n","Training loss for fold 3, epoch 251: 147.99901433144845\n","Validation elbo for fold 3, epoch 252: -19797.352929425022\n","Reconstruction accuracy for fold 3, epoch 252: 0.5638134106993675\n","Training loss for fold 3, epoch 252: 146.53005723030336\n","Validation elbo for fold 3, epoch 253: -19845.582808763254\n","Reconstruction accuracy for fold 3, epoch 253: 0.5648988001048565\n","Training loss for fold 3, epoch 253: 145.61078545355028\n","Validation elbo for fold 3, epoch 254: -19820.476091842662\n","Reconstruction accuracy for fold 3, epoch 254: 0.563522320240736\n","Training loss for fold 3, epoch 254: 147.5855322807066\n","Validation elbo for fold 3, epoch 255: -19822.22464912561\n","Reconstruction accuracy for fold 3, epoch 255: 0.5624305605888367\n","Training loss for fold 3, epoch 255: 147.85743491880356\n","Validation elbo for fold 3, epoch 256: -19840.6029483847\n","Reconstruction accuracy for fold 3, epoch 256: 0.5633747689425945\n","Training loss for fold 3, epoch 256: 147.75094038440335\n","Validation elbo for fold 3, epoch 257: -19826.701685959582\n","Reconstruction accuracy for fold 3, epoch 257: 0.5632463023066521\n","Training loss for fold 3, epoch 257: 147.4348892704133\n","Validation elbo for fold 3, epoch 258: -19805.582041939713\n","Reconstruction accuracy for fold 3, epoch 258: 0.5644340254366398\n","Training loss for fold 3, epoch 258: 147.66642022901965\n","Validation elbo for fold 3, epoch 259: -19783.701185581464\n","Reconstruction accuracy for fold 3, epoch 259: 0.5654216520488262\n","Training loss for fold 3, epoch 259: 147.3208972561744\n","Validation elbo for fold 3, epoch 260: -19780.526073767214\n","Reconstruction accuracy for fold 3, epoch 260: 0.5653186328709126\n","Training loss for fold 3, epoch 260: 146.63963416314894\n","Validation elbo for fold 3, epoch 261: -19841.24396876694\n","Reconstruction accuracy for fold 3, epoch 261: 0.5642149895429611\n","Training loss for fold 3, epoch 261: 146.99420141404676\n","Validation elbo for fold 3, epoch 262: -19793.869344394883\n","Reconstruction accuracy for fold 3, epoch 262: 0.5642021261155605\n","Training loss for fold 3, epoch 262: 147.07257695351876\n","Validation elbo for fold 3, epoch 263: -19881.40303691647\n","Reconstruction accuracy for fold 3, epoch 263: 0.5626801624894142\n","Training loss for fold 3, epoch 263: 147.7888390325731\n","Validation elbo for fold 3, epoch 264: -19833.777469591874\n","Reconstruction accuracy for fold 3, epoch 264: 0.5629791356623173\n","Training loss for fold 3, epoch 264: 147.8868927494172\n","Validation elbo for fold 3, epoch 265: -19806.02764368339\n","Reconstruction accuracy for fold 3, epoch 265: 0.5653834827244282\n","Training loss for fold 3, epoch 265: 146.9174741929577\n","Validation elbo for fold 3, epoch 266: -19745.79886934559\n","Reconstruction accuracy for fold 3, epoch 266: 0.5652352385222912\n","Training loss for fold 3, epoch 266: 145.77422222014397\n","Validation elbo for fold 3, epoch 267: -19772.64488417866\n","Reconstruction accuracy for fold 3, epoch 267: 0.567138310521841\n","Training loss for fold 3, epoch 267: 146.3349350960024\n","Validation elbo for fold 3, epoch 268: -19834.044436729982\n","Reconstruction accuracy for fold 3, epoch 268: 0.5652736872434616\n","Training loss for fold 3, epoch 268: 147.02352671469413\n","Validation elbo for fold 3, epoch 269: -19760.056780897758\n","Reconstruction accuracy for fold 3, epoch 269: 0.564927700906992\n","Training loss for fold 3, epoch 269: 147.4746966208181\n","Validation elbo for fold 3, epoch 270: -19802.066824833244\n","Reconstruction accuracy for fold 3, epoch 270: 0.5645489357411861\n","Training loss for fold 3, epoch 270: 146.54853636218655\n","Validation elbo for fold 3, epoch 271: -19821.67789223054\n","Reconstruction accuracy for fold 3, epoch 271: 0.5631893314421177\n","Training loss for fold 3, epoch 271: 146.4140269371771\n","Validation elbo for fold 3, epoch 272: -19777.103132829187\n","Reconstruction accuracy for fold 3, epoch 272: 0.5641779229044914\n","Training loss for fold 3, epoch 272: 145.82603282313192\n","Validation elbo for fold 3, epoch 273: -19762.905940634446\n","Reconstruction accuracy for fold 3, epoch 273: 0.5638294443488121\n","Training loss for fold 3, epoch 273: 146.0827256479571\n","Validation elbo for fold 3, epoch 274: -19816.38178553246\n","Reconstruction accuracy for fold 3, epoch 274: 0.5659431181848049\n","Training loss for fold 3, epoch 274: 146.34265875047254\n","Validation elbo for fold 3, epoch 275: -19843.823680836125\n","Reconstruction accuracy for fold 3, epoch 275: 0.5649603344500065\n","Training loss for fold 3, epoch 275: 146.30790895031345\n","Validation elbo for fold 3, epoch 276: -19798.202113588966\n","Reconstruction accuracy for fold 3, epoch 276: 0.562851082533598\n","Training loss for fold 3, epoch 276: 146.39960036739225\n","Validation elbo for fold 3, epoch 277: -19802.92101163711\n","Reconstruction accuracy for fold 3, epoch 277: 0.5638259910047054\n","Training loss for fold 3, epoch 277: 146.81128594183153\n","Validation elbo for fold 3, epoch 278: -19826.711528369826\n","Reconstruction accuracy for fold 3, epoch 278: 0.5642626881599426\n","Training loss for fold 3, epoch 278: 146.5333687566942\n","Validation elbo for fold 3, epoch 279: -19785.812124102707\n","Reconstruction accuracy for fold 3, epoch 279: 0.5642361380159855\n","Training loss for fold 3, epoch 279: 146.12080764770508\n","Validation elbo for fold 3, epoch 280: -19791.452530309456\n","Reconstruction accuracy for fold 3, epoch 280: 0.565493144094944\n","Training loss for fold 3, epoch 280: 146.25836833830803\n","Validation elbo for fold 3, epoch 281: -19815.553956604752\n","Reconstruction accuracy for fold 3, epoch 281: 0.5635365545749664\n","Training loss for fold 3, epoch 281: 145.98200730354554\n","Validation elbo for fold 3, epoch 282: -19820.253075542787\n","Reconstruction accuracy for fold 3, epoch 282: 0.5661880150437355\n","Training loss for fold 3, epoch 282: 146.60865636025704\n","Validation elbo for fold 3, epoch 283: -19804.99542427179\n","Reconstruction accuracy for fold 3, epoch 283: 0.5648581385612488\n","Training loss for fold 3, epoch 283: 146.28498987997733\n","Validation elbo for fold 3, epoch 284: -19837.862469287462\n","Reconstruction accuracy for fold 3, epoch 284: 0.5664372034370899\n","Training loss for fold 3, epoch 284: 146.61067064346807\n","Validation elbo for fold 3, epoch 285: -19822.061870499252\n","Reconstruction accuracy for fold 3, epoch 285: 0.5632273554801941\n","Training loss for fold 3, epoch 285: 145.76030952699722\n","Validation elbo for fold 3, epoch 286: -19787.883944390785\n","Reconstruction accuracy for fold 3, epoch 286: 0.5653007850050926\n","Training loss for fold 3, epoch 286: 145.52923325569398\n","Validation elbo for fold 3, epoch 287: -19755.89180407689\n","Reconstruction accuracy for fold 3, epoch 287: 0.5676839798688889\n","Training loss for fold 3, epoch 287: 145.73461704869425\n","Validation elbo for fold 3, epoch 288: -19803.694457104444\n","Reconstruction accuracy for fold 3, epoch 288: 0.5654091946780682\n","Training loss for fold 3, epoch 288: 144.8602141103437\n","Validation elbo for fold 3, epoch 289: -19765.927995924743\n","Reconstruction accuracy for fold 3, epoch 289: 0.5659070275723934\n","Training loss for fold 3, epoch 289: 145.53615053238408\n","Validation elbo for fold 3, epoch 290: -19855.10432004019\n","Reconstruction accuracy for fold 3, epoch 290: 0.5623589307069778\n","Training loss for fold 3, epoch 290: 145.4079840875441\n","Validation elbo for fold 3, epoch 291: -19803.44037583381\n","Reconstruction accuracy for fold 3, epoch 291: 0.5664489604532719\n","Training loss for fold 3, epoch 291: 146.24314929592995\n","Validation elbo for fold 3, epoch 292: -19772.262931526115\n","Reconstruction accuracy for fold 3, epoch 292: 0.5648598000407219\n","Training loss for fold 3, epoch 292: 145.12162473124843\n","Validation elbo for fold 3, epoch 293: -19821.560462519643\n","Reconstruction accuracy for fold 3, epoch 293: 0.5663503631949425\n","Training loss for fold 3, epoch 293: 145.8190691548009\n","Validation elbo for fold 3, epoch 294: -19859.685516901285\n","Reconstruction accuracy for fold 3, epoch 294: 0.5647562257945538\n","Training loss for fold 3, epoch 294: 145.8722968562957\n","Validation elbo for fold 3, epoch 295: -19795.80189730948\n","Reconstruction accuracy for fold 3, epoch 295: 0.5644958354532719\n","Training loss for fold 3, epoch 295: 146.14084182247038\n","Validation elbo for fold 3, epoch 296: -19829.632934132733\n","Reconstruction accuracy for fold 3, epoch 296: 0.566332932561636\n","Training loss for fold 3, epoch 296: 146.42269860544513\n","Validation elbo for fold 3, epoch 297: -19786.305284516162\n","Reconstruction accuracy for fold 3, epoch 297: 0.5660176537930965\n","Training loss for fold 3, epoch 297: 146.52220326085245\n","Validation elbo for fold 3, epoch 298: -19827.904325051295\n","Reconstruction accuracy for fold 3, epoch 298: 0.5682086236774921\n","Training loss for fold 3, epoch 298: 146.38282628213204\n","Validation elbo for fold 3, epoch 299: -19810.396510486185\n","Reconstruction accuracy for fold 3, epoch 299: 0.5664874091744423\n","Training loss for fold 3, epoch 299: 146.34791269610005\n","Validation elbo for fold 3, epoch 300: -19819.27679126893\n","Reconstruction accuracy for fold 3, epoch 300: 0.5643991716206074\n","Training loss for fold 3, epoch 300: 146.02798043527912\n","Validation elbo for fold 3, epoch 301: -19771.1518977402\n","Reconstruction accuracy for fold 3, epoch 301: 0.567011084407568\n","Training loss for fold 3, epoch 301: 145.45638152091735\n","Validation elbo for fold 3, epoch 302: -19818.608063090338\n","Reconstruction accuracy for fold 3, epoch 302: 0.5664361044764519\n","Training loss for fold 3, epoch 302: 146.83481154903288\n","Validation elbo for fold 3, epoch 303: -19800.972051850677\n","Reconstruction accuracy for fold 3, epoch 303: 0.5635548122227192\n","Training loss for fold 3, epoch 303: 146.1189345082929\n","Validation elbo for fold 3, epoch 304: -19854.55784200727\n","Reconstruction accuracy for fold 3, epoch 304: 0.5675004757940769\n","Training loss for fold 3, epoch 304: 145.07535897531818\n","Validation elbo for fold 3, epoch 305: -19803.399240305007\n","Reconstruction accuracy for fold 3, epoch 305: 0.5618138164281845\n","Training loss for fold 3, epoch 305: 145.50395153414817\n","Validation elbo for fold 3, epoch 306: -19763.018930498245\n","Reconstruction accuracy for fold 3, epoch 306: 0.566347599029541\n","Training loss for fold 3, epoch 306: 145.6122196566674\n","Validation elbo for fold 3, epoch 307: -19757.26201848164\n","Reconstruction accuracy for fold 3, epoch 307: 0.5676022544503212\n","Training loss for fold 3, epoch 307: 145.19350864041238\n","Validation elbo for fold 3, epoch 308: -19809.229621893097\n","Reconstruction accuracy for fold 3, epoch 308: 0.5646482296288013\n","Training loss for fold 3, epoch 308: 145.49956610894972\n","Validation elbo for fold 3, epoch 309: -19830.798117849725\n","Reconstruction accuracy for fold 3, epoch 309: 0.5649523101747036\n","Training loss for fold 3, epoch 309: 145.62961135372038\n","Validation elbo for fold 3, epoch 310: -19819.991177787284\n","Reconstruction accuracy for fold 3, epoch 310: 0.5657558776438236\n","Training loss for fold 3, epoch 310: 145.14054821383567\n","Validation elbo for fold 3, epoch 311: -19798.036181403033\n","Reconstruction accuracy for fold 3, epoch 311: 0.5650413669645786\n","Training loss for fold 3, epoch 311: 145.16120701451456\n","Validation elbo for fold 3, epoch 312: -19824.47755894115\n","Reconstruction accuracy for fold 3, epoch 312: 0.564774751663208\n","Training loss for fold 3, epoch 312: 144.8798830586095\n","Validation elbo for fold 3, epoch 313: -19787.029236077375\n","Reconstruction accuracy for fold 3, epoch 313: 0.5657633505761623\n","Training loss for fold 3, epoch 313: 145.02252738706528\n","Validation elbo for fold 3, epoch 314: -19827.89724554204\n","Reconstruction accuracy for fold 3, epoch 314: 0.5645705088973045\n","Training loss for fold 3, epoch 314: 145.41062902635144\n","Validation elbo for fold 3, epoch 315: -19831.071362503255\n","Reconstruction accuracy for fold 3, epoch 315: 0.5646563842892647\n","Training loss for fold 3, epoch 315: 145.07418306412237\n","Validation elbo for fold 3, epoch 316: -19841.76070483453\n","Reconstruction accuracy for fold 3, epoch 316: 0.5650809183716774\n","Training loss for fold 3, epoch 316: 145.541868394421\n","Validation elbo for fold 3, epoch 317: -19773.76750749282\n","Reconstruction accuracy for fold 3, epoch 317: 0.568156223744154\n","Training loss for fold 3, epoch 317: 145.10366993565714\n","Validation elbo for fold 3, epoch 318: -19782.561166419917\n","Reconstruction accuracy for fold 3, epoch 318: 0.568202268332243\n","Training loss for fold 3, epoch 318: 144.7474616266066\n","Validation elbo for fold 3, epoch 319: -19818.013536272472\n","Reconstruction accuracy for fold 3, epoch 319: 0.5672306828200817\n","Training loss for fold 3, epoch 319: 145.0548580538842\n","Validation elbo for fold 3, epoch 320: -19833.677659270463\n","Reconstruction accuracy for fold 3, epoch 320: 0.5645674653351307\n","Training loss for fold 3, epoch 320: 145.01763423796623\n","Validation elbo for fold 3, epoch 321: -19823.92952951262\n","Reconstruction accuracy for fold 3, epoch 321: 0.5662788711488247\n","Training loss for fold 3, epoch 321: 144.7672715956165\n","Validation elbo for fold 3, epoch 322: -19833.924016501427\n","Reconstruction accuracy for fold 3, epoch 322: 0.5640703365206718\n","Training loss for fold 3, epoch 322: 144.56304833196825\n","Validation elbo for fold 3, epoch 323: -19797.808970047245\n","Reconstruction accuracy for fold 3, epoch 323: 0.5655152648687363\n","Training loss for fold 3, epoch 323: 145.01436787266886\n","Validation elbo for fold 3, epoch 324: -19855.136218603657\n","Reconstruction accuracy for fold 3, epoch 324: 0.5629099942743778\n","Training loss for fold 3, epoch 324: 144.46228261147775\n","Validation elbo for fold 3, epoch 325: -19843.768735923357\n","Reconstruction accuracy for fold 3, epoch 325: 0.565522588789463\n","Training loss for fold 3, epoch 325: 144.69009091777187\n","Validation elbo for fold 3, epoch 326: -19810.387127589885\n","Reconstruction accuracy for fold 3, epoch 326: 0.5659512765705585\n","Training loss for fold 3, epoch 326: 144.68329275808026\n","Validation elbo for fold 3, epoch 327: -19853.733009636366\n","Reconstruction accuracy for fold 3, epoch 327: 0.5656796917319298\n","Training loss for fold 3, epoch 327: 144.7754368935862\n","Validation elbo for fold 3, epoch 328: -19865.270901038908\n","Reconstruction accuracy for fold 3, epoch 328: 0.5640789084136486\n","Training loss for fold 3, epoch 328: 145.21928048902942\n","Validation elbo for fold 3, epoch 329: -19817.103364431925\n","Reconstruction accuracy for fold 3, epoch 329: 0.5628906339406967\n","Training loss for fold 3, epoch 329: 145.21716320899225\n","Validation elbo for fold 3, epoch 330: -19831.427846733335\n","Reconstruction accuracy for fold 3, epoch 330: 0.5641234368085861\n","Training loss for fold 3, epoch 330: 145.092595377276\n","Validation elbo for fold 3, epoch 331: -19744.319200454414\n","Reconstruction accuracy for fold 3, epoch 331: 0.5674405992031097\n","Training loss for fold 3, epoch 331: 145.26717253654235\n","Validation elbo for fold 3, epoch 332: -19818.567044063973\n","Reconstruction accuracy for fold 3, epoch 332: 0.5653371587395668\n","Training loss for fold 3, epoch 332: 145.45164182109218\n","Validation elbo for fold 3, epoch 333: -19814.151595889438\n","Reconstruction accuracy for fold 3, epoch 333: 0.562823161482811\n","Training loss for fold 3, epoch 333: 145.38707536266696\n","Validation elbo for fold 3, epoch 334: -19808.6284055948\n","Reconstruction accuracy for fold 3, epoch 334: 0.5661148652434349\n","Training loss for fold 3, epoch 334: 145.19404442079605\n","Validation elbo for fold 3, epoch 335: -19898.402336745676\n","Reconstruction accuracy for fold 3, epoch 335: 0.5625673197209835\n","Training loss for fold 3, epoch 335: 145.3581150424096\n","Validation elbo for fold 3, epoch 336: -19812.072710078995\n","Reconstruction accuracy for fold 3, epoch 336: 0.5641493014991283\n","Training loss for fold 3, epoch 336: 144.93221935149163\n","Validation elbo for fold 3, epoch 337: -19836.91959414735\n","Reconstruction accuracy for fold 3, epoch 337: 0.5646608099341393\n","Training loss for fold 3, epoch 337: 144.65645180979084\n","Validation elbo for fold 3, epoch 338: -19810.482601188116\n","Reconstruction accuracy for fold 3, epoch 338: 0.5643498077988625\n","Training loss for fold 3, epoch 338: 144.13262151902723\n","Validation elbo for fold 3, epoch 339: -19783.594266500324\n","Reconstruction accuracy for fold 3, epoch 339: 0.5666634403169155\n","Training loss for fold 3, epoch 339: 144.0951163999496\n","Validation elbo for fold 3, epoch 340: -19799.6348075585\n","Reconstruction accuracy for fold 3, epoch 340: 0.5638738349080086\n","Training loss for fold 3, epoch 340: 144.26404177758002\n","Validation elbo for fold 3, epoch 341: -19809.53759683759\n","Reconstruction accuracy for fold 3, epoch 341: 0.5655389130115509\n","Training loss for fold 3, epoch 341: 144.73746933475618\n","Validation elbo for fold 3, epoch 342: -19895.12586162695\n","Reconstruction accuracy for fold 3, epoch 342: 0.5626902617514133\n","Training loss for fold 3, epoch 342: 145.0677719116211\n","Validation elbo for fold 3, epoch 343: -19853.64485762272\n","Reconstruction accuracy for fold 3, epoch 343: 0.5648678205907345\n","Training loss for fold 3, epoch 343: 144.60637086437595\n","Validation elbo for fold 3, epoch 344: -19859.594832198833\n","Reconstruction accuracy for fold 3, epoch 344: 0.5634321644902229\n","Training loss for fold 3, epoch 344: 144.33249824277817\n","Validation elbo for fold 3, epoch 345: -19885.41465243137\n","Reconstruction accuracy for fold 3, epoch 345: 0.5651345737278461\n","Training loss for fold 3, epoch 345: 144.53677786550213\n","Validation elbo for fold 3, epoch 346: -19804.773163471567\n","Reconstruction accuracy for fold 3, epoch 346: 0.5667668730020523\n","Training loss for fold 3, epoch 346: 144.5052095228626\n","Validation elbo for fold 3, epoch 347: -19806.77079939784\n","Reconstruction accuracy for fold 3, epoch 347: 0.5656701400876045\n","Training loss for fold 3, epoch 347: 144.54430192516696\n","Validation elbo for fold 3, epoch 348: -19819.623982746692\n","Reconstruction accuracy for fold 3, epoch 348: 0.564336258918047\n","Training loss for fold 3, epoch 348: 143.72721062937092\n","Validation elbo for fold 3, epoch 349: -19851.59671496356\n","Reconstruction accuracy for fold 3, epoch 349: 0.5636426173150539\n","Training loss for fold 3, epoch 349: 144.5353141292449\n","Validation elbo for fold 3, epoch 350: -19850.083083968377\n","Reconstruction accuracy for fold 3, epoch 350: 0.5649221651256084\n","Training loss for fold 3, epoch 350: 144.62322358162172\n","Validation elbo for fold 3, epoch 351: -19859.81555328214\n","Reconstruction accuracy for fold 3, epoch 351: 0.5619833506643772\n","Training loss for fold 3, epoch 351: 145.24122102798955\n","Validation elbo for fold 3, epoch 352: -19765.854217598815\n","Reconstruction accuracy for fold 3, epoch 352: 0.5633140578866005\n","Training loss for fold 3, epoch 352: 144.85602052750127\n","Validation elbo for fold 3, epoch 353: -19863.94721183268\n","Reconstruction accuracy for fold 3, epoch 353: 0.5647558085620403\n","Training loss for fold 3, epoch 353: 144.00594920496786\n","Validation elbo for fold 3, epoch 354: -19845.725671928863\n","Reconstruction accuracy for fold 3, epoch 354: 0.5639408938586712\n","Training loss for fold 3, epoch 354: 144.86644818705898\n","Validation elbo for fold 3, epoch 355: -19821.58093653975\n","Reconstruction accuracy for fold 3, epoch 355: 0.5645272321999073\n","Training loss for fold 3, epoch 355: 144.4861821820659\n","Validation elbo for fold 3, epoch 356: -19894.35114397883\n","Reconstruction accuracy for fold 3, epoch 356: 0.5643742829561234\n","Training loss for fold 3, epoch 356: 144.01293133151145\n","Validation elbo for fold 3, epoch 357: -19850.722434295425\n","Reconstruction accuracy for fold 3, epoch 357: 0.5645877942442894\n","Training loss for fold 3, epoch 357: 145.23102668023878\n","Validation elbo for fold 3, epoch 358: -19780.20815874429\n","Reconstruction accuracy for fold 3, epoch 358: 0.5661057382822037\n","Training loss for fold 3, epoch 358: 143.9983924127394\n","Validation elbo for fold 3, epoch 359: -19863.226718224818\n","Reconstruction accuracy for fold 3, epoch 359: 0.5645028874278069\n","Training loss for fold 3, epoch 359: 143.96234450801725\n","Validation elbo for fold 3, epoch 360: -19809.63009853328\n","Reconstruction accuracy for fold 3, epoch 360: 0.5655586905777454\n","Training loss for fold 3, epoch 360: 144.09702990131993\n","Validation elbo for fold 3, epoch 361: -19891.20468933708\n","Reconstruction accuracy for fold 3, epoch 361: 0.5650657042860985\n","Training loss for fold 3, epoch 361: 144.6435904964324\n","Validation elbo for fold 3, epoch 362: -19821.09503499621\n","Reconstruction accuracy for fold 3, epoch 362: 0.565738458186388\n","Training loss for fold 3, epoch 362: 142.85845553490424\n","Validation elbo for fold 3, epoch 363: -19874.37118368289\n","Reconstruction accuracy for fold 3, epoch 363: 0.564178891479969\n","Training loss for fold 3, epoch 363: 144.3292275705645\n","Validation elbo for fold 3, epoch 364: -19817.618069613163\n","Reconstruction accuracy for fold 3, epoch 364: 0.5656733214855194\n","Training loss for fold 3, epoch 364: 144.10867186515563\n","Validation elbo for fold 3, epoch 365: -19852.51209191\n","Reconstruction accuracy for fold 3, epoch 365: 0.5619973167777061\n","Training loss for fold 3, epoch 365: 144.89471632434476\n","Validation elbo for fold 3, epoch 366: -19795.96543815093\n","Reconstruction accuracy for fold 3, epoch 366: 0.5631568320095539\n","Training loss for fold 3, epoch 366: 143.80716889904392\n","Validation elbo for fold 3, epoch 367: -19836.878440369044\n","Reconstruction accuracy for fold 3, epoch 367: 0.5652869530022144\n","Training loss for fold 3, epoch 367: 144.01481037755167\n","Validation elbo for fold 3, epoch 368: -19891.66160321037\n","Reconstruction accuracy for fold 3, epoch 368: 0.5642335154116154\n","Training loss for fold 3, epoch 368: 144.33808763565557\n","Validation elbo for fold 3, epoch 369: -19828.419766830833\n","Reconstruction accuracy for fold 3, epoch 369: 0.5656542405486107\n","Training loss for fold 3, epoch 369: 143.747925543016\n","Validation elbo for fold 3, epoch 370: -19863.883545204135\n","Reconstruction accuracy for fold 3, epoch 370: 0.5635221749544144\n","Training loss for fold 3, epoch 370: 144.06309410833543\n","Validation elbo for fold 3, epoch 371: -19802.09087084762\n","Reconstruction accuracy for fold 3, epoch 371: 0.5656998790800571\n","Training loss for fold 3, epoch 371: 143.82119824809413\n","Validation elbo for fold 3, epoch 372: -19818.30244739767\n","Reconstruction accuracy for fold 3, epoch 372: 0.5642729215323925\n","Training loss for fold 3, epoch 372: 143.7409901772776\n","Validation elbo for fold 3, epoch 373: -19793.125991000503\n","Reconstruction accuracy for fold 3, epoch 373: 0.562490027397871\n","Training loss for fold 3, epoch 373: 143.59876780356132\n","Validation elbo for fold 3, epoch 374: -19830.287993711183\n","Reconstruction accuracy for fold 3, epoch 374: 0.5655057281255722\n","Training loss for fold 3, epoch 374: 144.4207283758348\n","Validation elbo for fold 3, epoch 375: -19832.965946566677\n","Reconstruction accuracy for fold 3, epoch 375: 0.566199354827404\n","Training loss for fold 3, epoch 375: 143.4131068568076\n","Validation elbo for fold 3, epoch 376: -19781.147503808214\n","Reconstruction accuracy for fold 3, epoch 376: 0.5650740079581738\n","Training loss for fold 3, epoch 376: 144.27856309952276\n","Validation elbo for fold 3, epoch 377: -19847.280134570545\n","Reconstruction accuracy for fold 3, epoch 377: 0.5654422491788864\n","Training loss for fold 3, epoch 377: 143.62749998031123\n","Validation elbo for fold 3, epoch 378: -19810.33446965277\n","Reconstruction accuracy for fold 3, epoch 378: 0.5670746974647045\n","Training loss for fold 3, epoch 378: 144.21133816626764\n","Validation elbo for fold 3, epoch 379: -19850.99335879132\n","Reconstruction accuracy for fold 3, epoch 379: 0.5649960190057755\n","Training loss for fold 3, epoch 379: 144.63764510616178\n","Validation elbo for fold 3, epoch 380: -19897.614760862474\n","Reconstruction accuracy for fold 3, epoch 380: 0.5640505626797676\n","Training loss for fold 3, epoch 380: 144.11899320540888\n","Validation elbo for fold 3, epoch 381: -19822.43074827022\n","Reconstruction accuracy for fold 3, epoch 381: 0.5656759515404701\n","Training loss for fold 3, epoch 381: 143.36062400571763\n","Validation elbo for fold 3, epoch 382: -19806.496309581642\n","Reconstruction accuracy for fold 3, epoch 382: 0.5646585896611214\n","Training loss for fold 3, epoch 382: 143.38446943221552\n","Validation elbo for fold 3, epoch 383: -19831.055438395866\n","Reconstruction accuracy for fold 3, epoch 383: 0.569911178201437\n","Training loss for fold 3, epoch 383: 142.73469777261056\n","Validation elbo for fold 3, epoch 384: -19876.83451537318\n","Reconstruction accuracy for fold 3, epoch 384: 0.5671329163014889\n","Training loss for fold 3, epoch 384: 143.89711872223884\n","Validation elbo for fold 3, epoch 385: -19798.86603866535\n","Reconstruction accuracy for fold 3, epoch 385: 0.5635217614471912\n","Training loss for fold 3, epoch 385: 144.17394108926095\n","Validation elbo for fold 3, epoch 386: -19844.136519146792\n","Reconstruction accuracy for fold 3, epoch 386: 0.5645277835428715\n","Training loss for fold 3, epoch 386: 144.00704623806863\n","Validation elbo for fold 3, epoch 387: -19862.533833147972\n","Reconstruction accuracy for fold 3, epoch 387: 0.5666432529687881\n","Training loss for fold 3, epoch 387: 143.89908673686367\n","Validation elbo for fold 3, epoch 388: -19794.427139426687\n","Reconstruction accuracy for fold 3, epoch 388: 0.5649281181395054\n","Training loss for fold 3, epoch 388: 142.4516082271453\n","Validation elbo for fold 3, epoch 389: -19792.574133765884\n","Reconstruction accuracy for fold 3, epoch 389: 0.5644842199981213\n","Training loss for fold 3, epoch 389: 144.10635966639364\n","Validation elbo for fold 3, epoch 390: -19861.32904761431\n","Reconstruction accuracy for fold 3, epoch 390: 0.562681969255209\n","Training loss for fold 3, epoch 390: 144.56667795488912\n","Validation elbo for fold 3, epoch 391: -19853.336724333833\n","Reconstruction accuracy for fold 3, epoch 391: 0.5648527517914772\n","Training loss for fold 3, epoch 391: 144.34474255961757\n","Validation elbo for fold 3, epoch 392: -19829.321401421857\n","Reconstruction accuracy for fold 3, epoch 392: 0.5650632232427597\n","Training loss for fold 3, epoch 392: 142.92897427466607\n","Validation elbo for fold 3, epoch 393: -19828.33277509179\n","Reconstruction accuracy for fold 3, epoch 393: 0.5641126520931721\n","Training loss for fold 3, epoch 393: 143.22802156017673\n","Validation elbo for fold 3, epoch 394: -19826.964956963813\n","Reconstruction accuracy for fold 3, epoch 394: 0.5675152689218521\n","Training loss for fold 3, epoch 394: 143.50276823966735\n","Validation elbo for fold 3, epoch 395: -19807.982984682323\n","Reconstruction accuracy for fold 3, epoch 395: 0.5669481717050076\n","Training loss for fold 3, epoch 395: 142.98071498255575\n","Validation elbo for fold 3, epoch 396: -19845.818604599008\n","Reconstruction accuracy for fold 3, epoch 396: 0.5650666803121567\n","Training loss for fold 3, epoch 396: 143.57584639518493\n","Validation elbo for fold 3, epoch 397: -19842.51570103031\n","Reconstruction accuracy for fold 3, epoch 397: 0.564095500856638\n","Training loss for fold 3, epoch 397: 143.54442694879347\n","Validation elbo for fold 3, epoch 398: -19833.04670594054\n","Reconstruction accuracy for fold 3, epoch 398: 0.564780842512846\n","Training loss for fold 3, epoch 398: 143.48978645570816\n","Validation elbo for fold 3, epoch 399: -19871.183817133537\n","Reconstruction accuracy for fold 3, epoch 399: 0.5636570081114769\n","Training loss for fold 3, epoch 399: 143.54488028249432\n","Validation elbo for fold 3, epoch 400: -19865.62912045185\n","Reconstruction accuracy for fold 3, epoch 400: 0.5659511536359787\n","Training loss for fold 3, epoch 400: 143.68959365352507\n","Validation elbo for fold 3, epoch 401: -19885.49922585024\n","Reconstruction accuracy for fold 3, epoch 401: 0.5648607686161995\n","Training loss for fold 3, epoch 401: 143.55929626957064\n","Validation elbo for fold 3, epoch 402: -19773.680723844605\n","Reconstruction accuracy for fold 3, epoch 402: 0.566149715334177\n","Training loss for fold 3, epoch 402: 142.66016412550402\n","Validation elbo for fold 3, epoch 403: -19827.30354097677\n","Reconstruction accuracy for fold 3, epoch 403: 0.5650593414902687\n","Training loss for fold 3, epoch 403: 143.23416949856667\n","Validation elbo for fold 3, epoch 404: -19870.587892799416\n","Reconstruction accuracy for fold 3, epoch 404: 0.56351138651371\n","Training loss for fold 3, epoch 404: 143.98793718891758\n","Validation elbo for fold 3, epoch 405: -19820.258847729205\n","Reconstruction accuracy for fold 3, epoch 405: 0.5649467781186104\n","Training loss for fold 3, epoch 405: 143.12484728905463\n","Validation elbo for fold 3, epoch 406: -19838.445568790805\n","Reconstruction accuracy for fold 3, epoch 406: 0.5646613650023937\n","Training loss for fold 3, epoch 406: 142.9415772961032\n","Validation elbo for fold 3, epoch 407: -19854.754403527448\n","Reconstruction accuracy for fold 3, epoch 407: 0.5680166818201542\n","Training loss for fold 3, epoch 407: 143.28831801875944\n","Validation elbo for fold 3, epoch 408: -19829.723622672253\n","Reconstruction accuracy for fold 3, epoch 408: 0.5665981695055962\n","Training loss for fold 3, epoch 408: 143.44886829007058\n","Validation elbo for fold 3, epoch 409: -19816.42489921359\n","Reconstruction accuracy for fold 3, epoch 409: 0.566047940403223\n","Training loss for fold 3, epoch 409: 143.15267673615486\n","Validation elbo for fold 3, epoch 410: -19863.583803776804\n","Reconstruction accuracy for fold 3, epoch 410: 0.5670412331819534\n","Training loss for fold 3, epoch 410: 143.691524136451\n","Validation elbo for fold 3, epoch 411: -19855.48191431661\n","Reconstruction accuracy for fold 3, epoch 411: 0.5636339113116264\n","Training loss for fold 3, epoch 411: 143.3396973148469\n","Validation elbo for fold 3, epoch 412: -19846.119601620845\n","Reconstruction accuracy for fold 3, epoch 412: 0.5628140233457088\n","Training loss for fold 3, epoch 412: 142.82223609185988\n","Validation elbo for fold 3, epoch 413: -19865.375646235174\n","Reconstruction accuracy for fold 3, epoch 413: 0.5661704540252686\n","Training loss for fold 3, epoch 413: 143.9675551383726\n","Validation elbo for fold 3, epoch 414: -19827.9277638586\n","Reconstruction accuracy for fold 3, epoch 414: 0.56620904058218\n","Training loss for fold 3, epoch 414: 143.22988387077086\n","Validation elbo for fold 3, epoch 415: -19889.27128918586\n","Reconstruction accuracy for fold 3, epoch 415: 0.563566293567419\n","Training loss for fold 3, epoch 415: 143.26322789346017\n","Validation elbo for fold 3, epoch 416: -19843.536311328884\n","Reconstruction accuracy for fold 3, epoch 416: 0.5679689794778824\n","Training loss for fold 3, epoch 416: 143.0999994585591\n","Validation elbo for fold 3, epoch 417: -19852.013815613896\n","Reconstruction accuracy for fold 3, epoch 417: 0.5646642632782459\n","Training loss for fold 3, epoch 417: 143.26649401264805\n","Validation elbo for fold 3, epoch 418: -19865.99972837619\n","Reconstruction accuracy for fold 3, epoch 418: 0.5673276260495186\n","Training loss for fold 3, epoch 418: 143.10791064846902\n","Validation elbo for fold 3, epoch 419: -19835.30405976621\n","Reconstruction accuracy for fold 3, epoch 419: 0.5638342835009098\n","Training loss for fold 3, epoch 419: 143.84929976924772\n","Validation elbo for fold 3, epoch 420: -19849.197337973455\n","Reconstruction accuracy for fold 3, epoch 420: 0.5644327811896801\n","Training loss for fold 3, epoch 420: 143.08447843982327\n","Validation elbo for fold 3, epoch 421: -19799.326212655666\n","Reconstruction accuracy for fold 3, epoch 421: 0.5634527541697025\n","Training loss for fold 3, epoch 421: 142.24481816445626\n","Validation elbo for fold 3, epoch 422: -19830.996034043048\n","Reconstruction accuracy for fold 3, epoch 422: 0.5643191114068031\n","Training loss for fold 3, epoch 422: 143.35219130977507\n","Validation elbo for fold 3, epoch 423: -19836.117662262634\n","Reconstruction accuracy for fold 3, epoch 423: 0.5644331946969032\n","Training loss for fold 3, epoch 423: 142.1619770911432\n","Validation elbo for fold 3, epoch 424: -19869.739542265594\n","Reconstruction accuracy for fold 3, epoch 424: 0.5646794773638248\n","Training loss for fold 3, epoch 424: 144.07480855141915\n","Validation elbo for fold 3, epoch 425: -19841.595392180025\n","Reconstruction accuracy for fold 3, epoch 425: 0.5672615244984627\n","Training loss for fold 3, epoch 425: 143.07808230000157\n","Validation elbo for fold 3, epoch 426: -19836.57573327368\n","Reconstruction accuracy for fold 3, epoch 426: 0.5680372938513756\n","Training loss for fold 3, epoch 426: 142.5047712018413\n","Validation elbo for fold 3, epoch 427: -19849.27523469248\n","Reconstruction accuracy for fold 3, epoch 427: 0.5657775960862637\n","Training loss for fold 3, epoch 427: 142.74277668614542\n","Validation elbo for fold 3, epoch 428: -19873.804605408193\n","Reconstruction accuracy for fold 3, epoch 428: 0.5668874606490135\n","Training loss for fold 3, epoch 428: 143.3004627843057\n","Validation elbo for fold 3, epoch 429: -19862.331960390693\n","Reconstruction accuracy for fold 3, epoch 429: 0.5663574188947678\n","Training loss for fold 3, epoch 429: 142.82608992053616\n","Validation elbo for fold 3, epoch 430: -19807.519758056813\n","Reconstruction accuracy for fold 3, epoch 430: 0.5675147138535976\n","Training loss for fold 3, epoch 430: 142.52652740478516\n","Validation elbo for fold 3, epoch 431: -19841.310908839543\n","Reconstruction accuracy for fold 3, epoch 431: 0.5671141073107719\n","Training loss for fold 3, epoch 431: 143.44559872534967\n","Validation elbo for fold 3, epoch 432: -19880.16451529749\n","Reconstruction accuracy for fold 3, epoch 432: 0.5651154853403568\n","Training loss for fold 3, epoch 432: 142.70141761533677\n","Validation elbo for fold 3, epoch 433: -19854.52824921538\n","Reconstruction accuracy for fold 3, epoch 433: 0.5650047287344933\n","Training loss for fold 3, epoch 433: 143.04770217403288\n","Validation elbo for fold 3, epoch 434: -19806.162509204045\n","Reconstruction accuracy for fold 3, epoch 434: 0.5689516291022301\n","Training loss for fold 3, epoch 434: 143.03515391195975\n","Validation elbo for fold 3, epoch 435: -19863.724788146646\n","Reconstruction accuracy for fold 3, epoch 435: 0.5643462128937244\n","Training loss for fold 3, epoch 435: 141.53655735138923\n","Validation elbo for fold 3, epoch 436: -19881.806902834345\n","Reconstruction accuracy for fold 3, epoch 436: 0.5656487159430981\n","Training loss for fold 3, epoch 436: 141.65718337028258\n","Validation elbo for fold 3, epoch 437: -19902.106329590155\n","Reconstruction accuracy for fold 3, epoch 437: 0.5668527521193027\n","Training loss for fold 3, epoch 437: 143.96563769925027\n","Validation elbo for fold 3, epoch 438: -19858.270989771892\n","Reconstruction accuracy for fold 3, epoch 438: 0.5650889351963997\n","Training loss for fold 3, epoch 438: 142.9417466194399\n","Validation elbo for fold 3, epoch 439: -19846.095421995044\n","Reconstruction accuracy for fold 3, epoch 439: 0.5650759376585484\n","Training loss for fold 3, epoch 439: 143.441592677947\n","Validation elbo for fold 3, epoch 440: -19828.943133691268\n","Reconstruction accuracy for fold 3, epoch 440: 0.565626859664917\n","Training loss for fold 3, epoch 440: 142.94044925320534\n","Validation elbo for fold 3, epoch 441: -19820.28461775863\n","Reconstruction accuracy for fold 3, epoch 441: 0.5650650188326836\n","Training loss for fold 3, epoch 441: 143.32156913511216\n","Validation elbo for fold 3, epoch 442: -19838.02667138625\n","Reconstruction accuracy for fold 3, epoch 442: 0.5666089579463005\n","Training loss for fold 3, epoch 442: 143.00157436247795\n","Validation elbo for fold 3, epoch 443: -19817.2959279967\n","Reconstruction accuracy for fold 3, epoch 443: 0.5687117092311382\n","Training loss for fold 3, epoch 443: 142.74658769176853\n","Validation elbo for fold 3, epoch 444: -19855.17968592146\n","Reconstruction accuracy for fold 3, epoch 444: 0.5660190358757973\n","Training loss for fold 3, epoch 444: 142.70911136750252\n","Validation elbo for fold 3, epoch 445: -19846.22110469904\n","Reconstruction accuracy for fold 3, epoch 445: 0.5654688067734241\n","Training loss for fold 3, epoch 445: 142.51747906592584\n","Validation elbo for fold 3, epoch 446: -19838.58020593025\n","Reconstruction accuracy for fold 3, epoch 446: 0.5677181258797646\n","Training loss for fold 3, epoch 446: 142.15782903855848\n","Validation elbo for fold 3, epoch 447: -19845.97400101254\n","Reconstruction accuracy for fold 3, epoch 447: 0.5669469200074673\n","Training loss for fold 3, epoch 447: 142.53731044646233\n","Validation elbo for fold 3, epoch 448: -19854.705575616168\n","Reconstruction accuracy for fold 3, epoch 448: 0.5654715746641159\n","Training loss for fold 3, epoch 448: 143.39355136502175\n","Validation elbo for fold 3, epoch 449: -19900.018638529782\n","Reconstruction accuracy for fold 3, epoch 449: 0.5663961358368397\n","Training loss for fold 3, epoch 449: 142.88462128177767\n","Validation elbo for fold 3, epoch 450: -19779.504078656333\n","Reconstruction accuracy for fold 3, epoch 450: 0.5683164931833744\n","Training loss for fold 3, epoch 450: 142.41269646921467\n","Validation elbo for fold 3, epoch 451: -19849.200051788936\n","Reconstruction accuracy for fold 3, epoch 451: 0.56489422544837\n","Training loss for fold 3, epoch 451: 142.6518832791236\n","Validation elbo for fold 3, epoch 452: -19879.6739932224\n","Reconstruction accuracy for fold 3, epoch 452: 0.5671380236744881\n","Training loss for fold 3, epoch 452: 142.83304251393963\n","Validation elbo for fold 3, epoch 453: -19865.01610774204\n","Reconstruction accuracy for fold 3, epoch 453: 0.5641429387032986\n","Training loss for fold 3, epoch 453: 142.31193099483366\n","Validation elbo for fold 3, epoch 454: -19862.355648374927\n","Reconstruction accuracy for fold 3, epoch 454: 0.564665649086237\n","Training loss for fold 3, epoch 454: 144.84131462343277\n","Validation elbo for fold 3, epoch 455: -19872.21553925973\n","Reconstruction accuracy for fold 3, epoch 455: 0.5649001859128475\n","Training loss for fold 3, epoch 455: 143.87707064228672\n","Validation elbo for fold 3, epoch 456: -19916.62853327275\n","Reconstruction accuracy for fold 3, epoch 456: 0.5624887868762016\n","Training loss for fold 3, epoch 456: 144.02435721120526\n","Validation elbo for fold 3, epoch 457: -19894.690823130724\n","Reconstruction accuracy for fold 3, epoch 457: 0.5631533674895763\n","Training loss for fold 3, epoch 457: 144.06823016751198\n","Validation elbo for fold 3, epoch 458: -19832.742869959075\n","Reconstruction accuracy for fold 3, epoch 458: 0.5675367079675198\n","Training loss for fold 3, epoch 458: 143.0569354641822\n","Validation elbo for fold 3, epoch 459: -19833.446148028204\n","Reconstruction accuracy for fold 3, epoch 459: 0.5664072073996067\n","Training loss for fold 3, epoch 459: 142.64948358843404\n","Validation elbo for fold 3, epoch 460: -19826.48162929757\n","Reconstruction accuracy for fold 3, epoch 460: 0.5663399994373322\n","Training loss for fold 3, epoch 460: 143.10066235450006\n","Validation elbo for fold 3, epoch 461: -19812.825141695248\n","Reconstruction accuracy for fold 3, epoch 461: 0.5654776468873024\n","Training loss for fold 3, epoch 461: 142.89263054632372\n","Validation elbo for fold 3, epoch 462: -19806.64976587964\n","Reconstruction accuracy for fold 3, epoch 462: 0.5661331154406071\n","Training loss for fold 3, epoch 462: 142.93953335669732\n","Validation elbo for fold 3, epoch 463: -19833.237755088805\n","Reconstruction accuracy for fold 3, epoch 463: 0.5657368041574955\n","Training loss for fold 3, epoch 463: 142.73977956464213\n","Validation elbo for fold 3, epoch 464: -19883.026855278018\n","Reconstruction accuracy for fold 3, epoch 464: 0.5649568773806095\n","Training loss for fold 3, epoch 464: 144.04910745928365\n","Validation elbo for fold 3, epoch 465: -19817.640789257075\n","Reconstruction accuracy for fold 3, epoch 465: 0.5666981525719166\n","Training loss for fold 3, epoch 465: 141.814026001961\n","Validation elbo for fold 3, epoch 466: -19810.896955185322\n","Reconstruction accuracy for fold 3, epoch 466: 0.5671517141163349\n","Training loss for fold 3, epoch 466: 142.18756152737527\n","Validation elbo for fold 3, epoch 467: -19846.885081754146\n","Reconstruction accuracy for fold 3, epoch 467: 0.5665286108851433\n","Training loss for fold 3, epoch 467: 142.81768971104776\n","Validation elbo for fold 3, epoch 468: -19829.686733109138\n","Reconstruction accuracy for fold 3, epoch 468: 0.5664959773421288\n","Training loss for fold 3, epoch 468: 141.6293569995511\n","Validation elbo for fold 3, epoch 469: -19895.25211326273\n","Reconstruction accuracy for fold 3, epoch 469: 0.5686399303376675\n","Training loss for fold 3, epoch 469: 142.89564834102507\n","Validation elbo for fold 3, epoch 470: -19809.392573253797\n","Reconstruction accuracy for fold 3, epoch 470: 0.5671005547046661\n","Training loss for fold 3, epoch 470: 142.99433419012254\n","Validation elbo for fold 3, epoch 471: -19859.84581589827\n","Reconstruction accuracy for fold 3, epoch 471: 0.5668711438775063\n","Training loss for fold 3, epoch 471: 142.15081393334174\n","Validation elbo for fold 3, epoch 472: -19841.57114151937\n","Reconstruction accuracy for fold 3, epoch 472: 0.569074559956789\n","Training loss for fold 3, epoch 472: 143.91064182404548\n","Validation elbo for fold 3, epoch 473: -19940.619547453258\n","Reconstruction accuracy for fold 3, epoch 473: 0.5653505772352219\n","Training loss for fold 3, epoch 473: 141.81535997698384\n","Validation elbo for fold 3, epoch 474: -19827.58107406199\n","Reconstruction accuracy for fold 3, epoch 474: 0.5675733461976051\n","Training loss for fold 3, epoch 474: 143.33150260679184\n","Validation elbo for fold 3, epoch 475: -19818.254617687817\n","Reconstruction accuracy for fold 3, epoch 475: 0.5656438693404198\n","Training loss for fold 3, epoch 475: 141.95688198458762\n","Validation elbo for fold 3, epoch 476: -19809.837998017574\n","Reconstruction accuracy for fold 3, epoch 476: 0.5673966184258461\n","Training loss for fold 3, epoch 476: 141.12140150993102\n","Validation elbo for fold 3, epoch 477: -19794.116196088653\n","Reconstruction accuracy for fold 3, epoch 477: 0.5666662007570267\n","Training loss for fold 3, epoch 477: 142.6810322423135\n","Validation elbo for fold 3, epoch 478: -19843.13575508546\n","Reconstruction accuracy for fold 3, epoch 478: 0.5651607103645802\n","Training loss for fold 3, epoch 478: 142.23078487765403\n","Validation elbo for fold 3, epoch 479: -19850.845420996535\n","Reconstruction accuracy for fold 3, epoch 479: 0.5631421804428101\n","Training loss for fold 3, epoch 479: 142.23441585417717\n","Validation elbo for fold 3, epoch 480: -19829.932122575534\n","Reconstruction accuracy for fold 3, epoch 480: 0.5678272359073162\n","Training loss for fold 3, epoch 480: 142.29382016581874\n","Validation elbo for fold 3, epoch 481: -19850.795141852814\n","Reconstruction accuracy for fold 3, epoch 481: 0.5667418465018272\n","Training loss for fold 3, epoch 481: 142.1529260450794\n","Validation elbo for fold 3, epoch 482: -19879.41354919494\n","Reconstruction accuracy for fold 3, epoch 482: 0.564830482006073\n","Training loss for fold 3, epoch 482: 141.95852574994487\n","Validation elbo for fold 3, epoch 483: -19819.371398800402\n","Reconstruction accuracy for fold 3, epoch 483: 0.564711831510067\n","Training loss for fold 3, epoch 483: 142.48034421859248\n","Validation elbo for fold 3, epoch 484: -19825.053365385895\n","Reconstruction accuracy for fold 3, epoch 484: 0.5684684552252293\n","Training loss for fold 3, epoch 484: 142.37966106783958\n","Validation elbo for fold 3, epoch 485: -19855.058566730848\n","Reconstruction accuracy for fold 3, epoch 485: 0.5641884282231331\n","Training loss for fold 3, epoch 485: 142.69155883789062\n","Validation elbo for fold 3, epoch 486: -19866.154962216035\n","Reconstruction accuracy for fold 3, epoch 486: 0.5635108426213264\n","Training loss for fold 3, epoch 486: 141.82933056739068\n","Validation elbo for fold 3, epoch 487: -19812.920961289252\n","Reconstruction accuracy for fold 3, epoch 487: 0.5667834728956223\n","Training loss for fold 3, epoch 487: 141.76958133328347\n","Validation elbo for fold 3, epoch 488: -19792.804507005225\n","Reconstruction accuracy for fold 3, epoch 488: 0.5655405707657337\n","Training loss for fold 3, epoch 488: 141.6335675639491\n","Validation elbo for fold 3, epoch 489: -19899.80607444664\n","Reconstruction accuracy for fold 3, epoch 489: 0.5647206865251064\n","Training loss for fold 3, epoch 489: 142.59484703310073\n","Validation elbo for fold 3, epoch 490: -19790.212051092734\n","Reconstruction accuracy for fold 3, epoch 490: 0.5656039156019688\n","Training loss for fold 3, epoch 490: 141.70316585417717\n","Validation elbo for fold 3, epoch 491: -19802.08434433607\n","Reconstruction accuracy for fold 3, epoch 491: 0.5668918900191784\n","Training loss for fold 3, epoch 491: 141.92315070859848\n","Validation elbo for fold 3, epoch 492: -19844.90364296079\n","Reconstruction accuracy for fold 3, epoch 492: 0.5697546452283859\n","Training loss for fold 3, epoch 492: 141.70183981618572\n","Validation elbo for fold 3, epoch 493: -19839.38261164696\n","Reconstruction accuracy for fold 3, epoch 493: 0.5677190981805325\n","Training loss for fold 3, epoch 493: 141.46022648965157\n","Validation elbo for fold 3, epoch 494: -19852.911950956724\n","Reconstruction accuracy for fold 3, epoch 494: 0.5655837245285511\n","Training loss for fold 3, epoch 494: 141.00755605389995\n","Validation elbo for fold 3, epoch 495: -19862.319463445627\n","Reconstruction accuracy for fold 3, epoch 495: 0.5667678490281105\n","Training loss for fold 3, epoch 495: 141.86455868136497\n","Validation elbo for fold 3, epoch 496: -19833.19728101364\n","Reconstruction accuracy for fold 3, epoch 496: 0.5685309618711472\n","Training loss for fold 3, epoch 496: 142.6532852418961\n","Validation elbo for fold 3, epoch 497: -19827.582874876483\n","Reconstruction accuracy for fold 3, epoch 497: 0.5665391162037849\n","Training loss for fold 3, epoch 497: 142.31462946245748\n","Validation elbo for fold 3, epoch 498: -19849.82569486526\n","Reconstruction accuracy for fold 3, epoch 498: 0.5651443861424923\n","Training loss for fold 3, epoch 498: 142.03841720088835\n","Validation elbo for fold 3, epoch 499: -19910.903186907555\n","Reconstruction accuracy for fold 3, epoch 499: 0.5645688511431217\n","Training loss for fold 3, epoch 499: 142.4939954203944\n","Fold 4\n","-------\n","Validation elbo for fold 4, epoch 0: -39738.63524931426\n","Reconstruction accuracy for fold 4, epoch 0: 0.051082569640129805\n","Training loss for fold 4, epoch 0: 239.50551236060357\n","Validation elbo for fold 4, epoch 1: -26538.91777782197\n","Reconstruction accuracy for fold 4, epoch 1: 0.3723106365650892\n","Training loss for fold 4, epoch 1: 225.83047362296813\n","Validation elbo for fold 4, epoch 2: -26503.064083778496\n","Reconstruction accuracy for fold 4, epoch 2: 0.3726888429373503\n","Training loss for fold 4, epoch 2: 225.44352746778918\n","Validation elbo for fold 4, epoch 3: -26470.280774525476\n","Reconstruction accuracy for fold 4, epoch 3: 0.37564798817038536\n","Training loss for fold 4, epoch 3: 225.27523311491936\n","Validation elbo for fold 4, epoch 4: -26205.739505838308\n","Reconstruction accuracy for fold 4, epoch 4: 0.3861996177583933\n","Training loss for fold 4, epoch 4: 222.35797635970576\n","Validation elbo for fold 4, epoch 5: -25821.167591857462\n","Reconstruction accuracy for fold 4, epoch 5: 0.3821387682110071\n","Training loss for fold 4, epoch 5: 221.32017837032194\n","Validation elbo for fold 4, epoch 6: -25762.59834664163\n","Reconstruction accuracy for fold 4, epoch 6: 0.38653495721518993\n","Training loss for fold 4, epoch 6: 220.3782730102539\n","Validation elbo for fold 4, epoch 7: -25628.00707713317\n","Reconstruction accuracy for fold 4, epoch 7: 0.38697926327586174\n","Training loss for fold 4, epoch 7: 218.59886390932144\n","Validation elbo for fold 4, epoch 8: -25443.600762395814\n","Reconstruction accuracy for fold 4, epoch 8: 0.38551054894924164\n","Training loss for fold 4, epoch 8: 216.9215358611076\n","Validation elbo for fold 4, epoch 9: -25322.734519225898\n","Reconstruction accuracy for fold 4, epoch 9: 0.3754158094525337\n","Training loss for fold 4, epoch 9: 216.22928643995715\n","Validation elbo for fold 4, epoch 10: -25182.980604548833\n","Reconstruction accuracy for fold 4, epoch 10: 0.3817615285515785\n","Training loss for fold 4, epoch 10: 214.87520205590033\n","Validation elbo for fold 4, epoch 11: -24991.61646861964\n","Reconstruction accuracy for fold 4, epoch 11: 0.38558605313301086\n","Training loss for fold 4, epoch 11: 213.62308428364415\n","Validation elbo for fold 4, epoch 12: -24761.13352865559\n","Reconstruction accuracy for fold 4, epoch 12: 0.388407738879323\n","Training loss for fold 4, epoch 12: 212.1839311661259\n","Validation elbo for fold 4, epoch 13: -24611.62832945906\n","Reconstruction accuracy for fold 4, epoch 13: 0.39277378655970097\n","Training loss for fold 4, epoch 13: 211.73380205708165\n","Validation elbo for fold 4, epoch 14: -24531.148093798554\n","Reconstruction accuracy for fold 4, epoch 14: 0.39783526211977005\n","Training loss for fold 4, epoch 14: 210.262813198951\n","Validation elbo for fold 4, epoch 15: -24386.180868814045\n","Reconstruction accuracy for fold 4, epoch 15: 0.4038265570998192\n","Training loss for fold 4, epoch 15: 209.4634089316091\n","Validation elbo for fold 4, epoch 16: -24201.23550117642\n","Reconstruction accuracy for fold 4, epoch 16: 0.4163450039923191\n","Training loss for fold 4, epoch 16: 208.2756556849326\n","Validation elbo for fold 4, epoch 17: -24086.56170825298\n","Reconstruction accuracy for fold 4, epoch 17: 0.41503545455634594\n","Training loss for fold 4, epoch 17: 207.27500324864542\n","Validation elbo for fold 4, epoch 18: -23921.625070742994\n","Reconstruction accuracy for fold 4, epoch 18: 0.4242249857634306\n","Training loss for fold 4, epoch 18: 205.2279352987966\n","Validation elbo for fold 4, epoch 19: -23766.032503193135\n","Reconstruction accuracy for fold 4, epoch 19: 0.42912397533655167\n","Training loss for fold 4, epoch 19: 204.12982940673828\n","Validation elbo for fold 4, epoch 20: -23603.6077023366\n","Reconstruction accuracy for fold 4, epoch 20: 0.4344866368919611\n","Training loss for fold 4, epoch 20: 202.74982378559727\n","Validation elbo for fold 4, epoch 21: -23496.249497104487\n","Reconstruction accuracy for fold 4, epoch 21: 0.4414539448916912\n","Training loss for fold 4, epoch 21: 201.68797646799396\n","Validation elbo for fold 4, epoch 22: -23416.388824243175\n","Reconstruction accuracy for fold 4, epoch 22: 0.43699165247380733\n","Training loss for fold 4, epoch 22: 200.81606760332662\n","Validation elbo for fold 4, epoch 23: -23312.96744104947\n","Reconstruction accuracy for fold 4, epoch 23: 0.44177545607089996\n","Training loss for fold 4, epoch 23: 199.97801257717995\n","Validation elbo for fold 4, epoch 24: -23235.913090976246\n","Reconstruction accuracy for fold 4, epoch 24: 0.4474051408469677\n","Training loss for fold 4, epoch 24: 198.87013121574157\n","Validation elbo for fold 4, epoch 25: -23123.54925140695\n","Reconstruction accuracy for fold 4, epoch 25: 0.447864243760705\n","Training loss for fold 4, epoch 25: 198.28447600333922\n","Validation elbo for fold 4, epoch 26: -23020.60295982763\n","Reconstruction accuracy for fold 4, epoch 26: 0.45703068003058434\n","Training loss for fold 4, epoch 26: 197.55116764191658\n","Validation elbo for fold 4, epoch 27: -22925.581310538324\n","Reconstruction accuracy for fold 4, epoch 27: 0.45879062823951244\n","Training loss for fold 4, epoch 27: 196.16803470734627\n","Validation elbo for fold 4, epoch 28: -22815.680387757122\n","Reconstruction accuracy for fold 4, epoch 28: 0.460769884288311\n","Training loss for fold 4, epoch 28: 195.1280286235194\n","Validation elbo for fold 4, epoch 29: -22684.474169953843\n","Reconstruction accuracy for fold 4, epoch 29: 0.4703148100525141\n","Training loss for fold 4, epoch 29: 194.98689343852382\n","Validation elbo for fold 4, epoch 30: -22646.656498583332\n","Reconstruction accuracy for fold 4, epoch 30: 0.4719479437917471\n","Training loss for fold 4, epoch 30: 194.04877176592427\n","Validation elbo for fold 4, epoch 31: -22540.38193954587\n","Reconstruction accuracy for fold 4, epoch 31: 0.4752682838588953\n","Training loss for fold 4, epoch 31: 193.06212492912047\n","Validation elbo for fold 4, epoch 32: -22448.535205790995\n","Reconstruction accuracy for fold 4, epoch 32: 0.47837953455746174\n","Training loss for fold 4, epoch 32: 192.84237301734186\n","Validation elbo for fold 4, epoch 33: -22373.048344789226\n","Reconstruction accuracy for fold 4, epoch 33: 0.4797872733324766\n","Training loss for fold 4, epoch 33: 191.98158510269658\n","Validation elbo for fold 4, epoch 34: -22330.906832250974\n","Reconstruction accuracy for fold 4, epoch 34: 0.48306917026638985\n","Training loss for fold 4, epoch 34: 191.00689820320375\n","Validation elbo for fold 4, epoch 35: -22252.478795159514\n","Reconstruction accuracy for fold 4, epoch 35: 0.48451714031398296\n","Training loss for fold 4, epoch 35: 190.29903190366684\n","Validation elbo for fold 4, epoch 36: -22189.87716789761\n","Reconstruction accuracy for fold 4, epoch 36: 0.4867059011012316\n","Training loss for fold 4, epoch 36: 189.67515736241495\n","Validation elbo for fold 4, epoch 37: -22114.267157545888\n","Reconstruction accuracy for fold 4, epoch 37: 0.4909202493727207\n","Training loss for fold 4, epoch 37: 188.72883975121283\n","Validation elbo for fold 4, epoch 38: -22079.38155655538\n","Reconstruction accuracy for fold 4, epoch 38: 0.48950753919780254\n","Training loss for fold 4, epoch 38: 188.89335312381868\n","Validation elbo for fold 4, epoch 39: -22005.77177145324\n","Reconstruction accuracy for fold 4, epoch 39: 0.49259915575385094\n","Training loss for fold 4, epoch 39: 187.86887408841042\n","Validation elbo for fold 4, epoch 40: -21974.899707671168\n","Reconstruction accuracy for fold 4, epoch 40: 0.4932051133364439\n","Training loss for fold 4, epoch 40: 187.88970307380922\n","Validation elbo for fold 4, epoch 41: -21900.684408756024\n","Reconstruction accuracy for fold 4, epoch 41: 0.4960539098829031\n","Training loss for fold 4, epoch 41: 187.6834478070659\n","Validation elbo for fold 4, epoch 42: -21824.001214276228\n","Reconstruction accuracy for fold 4, epoch 42: 0.4982317443937063\n","Training loss for fold 4, epoch 42: 186.15437489171183\n","Validation elbo for fold 4, epoch 43: -21822.860222572475\n","Reconstruction accuracy for fold 4, epoch 43: 0.5016858037561178\n","Training loss for fold 4, epoch 43: 185.06502360682333\n","Validation elbo for fold 4, epoch 44: -21696.331056705665\n","Reconstruction accuracy for fold 4, epoch 44: 0.503340931609273\n","Training loss for fold 4, epoch 44: 184.4704134541173\n","Validation elbo for fold 4, epoch 45: -21687.085527558145\n","Reconstruction accuracy for fold 4, epoch 45: 0.5009263511747122\n","Training loss for fold 4, epoch 45: 183.81019764561808\n","Validation elbo for fold 4, epoch 46: -21635.670592683295\n","Reconstruction accuracy for fold 4, epoch 46: 0.5058684851974249\n","Training loss for fold 4, epoch 46: 182.1687292283581\n","Validation elbo for fold 4, epoch 47: -21537.42481298503\n","Reconstruction accuracy for fold 4, epoch 47: 0.5060943029820919\n","Training loss for fold 4, epoch 47: 182.08917113273375\n","Validation elbo for fold 4, epoch 48: -21507.0700312493\n","Reconstruction accuracy for fold 4, epoch 48: 0.5082002319395542\n","Training loss for fold 4, epoch 48: 181.5698210193265\n","Validation elbo for fold 4, epoch 49: -21490.55365871096\n","Reconstruction accuracy for fold 4, epoch 49: 0.5117768030613661\n","Training loss for fold 4, epoch 49: 181.36322513703377\n","Validation elbo for fold 4, epoch 50: -21411.943003205113\n","Reconstruction accuracy for fold 4, epoch 50: 0.510827362537384\n","Training loss for fold 4, epoch 50: 179.80248038999497\n","Validation elbo for fold 4, epoch 51: -21364.469135207597\n","Reconstruction accuracy for fold 4, epoch 51: 0.5136952288448811\n","Training loss for fold 4, epoch 51: 179.9146479945029\n","Validation elbo for fold 4, epoch 52: -21362.371719754774\n","Reconstruction accuracy for fold 4, epoch 52: 0.5134540665894747\n","Training loss for fold 4, epoch 52: 179.62212864045173\n","Validation elbo for fold 4, epoch 53: -21290.248184487624\n","Reconstruction accuracy for fold 4, epoch 53: 0.5170338191092014\n","Training loss for fold 4, epoch 53: 178.76813162526776\n","Validation elbo for fold 4, epoch 54: -21263.198751680262\n","Reconstruction accuracy for fold 4, epoch 54: 0.518715213984251\n","Training loss for fold 4, epoch 54: 178.43544720065208\n","Validation elbo for fold 4, epoch 55: -21187.406844958914\n","Reconstruction accuracy for fold 4, epoch 55: 0.518780630081892\n","Training loss for fold 4, epoch 55: 178.13196440665953\n","Validation elbo for fold 4, epoch 56: -21195.422182001443\n","Reconstruction accuracy for fold 4, epoch 56: 0.5208947211503983\n","Training loss for fold 4, epoch 56: 178.06390750023627\n","Validation elbo for fold 4, epoch 57: -21210.65304344538\n","Reconstruction accuracy for fold 4, epoch 57: 0.5196125488728285\n","Training loss for fold 4, epoch 57: 177.4266564153856\n","Validation elbo for fold 4, epoch 58: -21121.699706109976\n","Reconstruction accuracy for fold 4, epoch 58: 0.5213055536150932\n","Training loss for fold 4, epoch 58: 176.56617416874056\n","Validation elbo for fold 4, epoch 59: -21094.97675117548\n","Reconstruction accuracy for fold 4, epoch 59: 0.5228345617651939\n","Training loss for fold 4, epoch 59: 176.80729158463018\n","Validation elbo for fold 4, epoch 60: -21053.014325229542\n","Reconstruction accuracy for fold 4, epoch 60: 0.5262375995516777\n","Training loss for fold 4, epoch 60: 176.0480676466419\n","Validation elbo for fold 4, epoch 61: -21019.992590819213\n","Reconstruction accuracy for fold 4, epoch 61: 0.5263892933726311\n","Training loss for fold 4, epoch 61: 175.83388986895162\n","Validation elbo for fold 4, epoch 62: -20983.760570650215\n","Reconstruction accuracy for fold 4, epoch 62: 0.5273347459733486\n","Training loss for fold 4, epoch 62: 175.15853020452684\n","Validation elbo for fold 4, epoch 63: -20957.767006151367\n","Reconstruction accuracy for fold 4, epoch 63: 0.5272696167230606\n","Training loss for fold 4, epoch 63: 174.84881296465474\n","Validation elbo for fold 4, epoch 64: -20978.641656823725\n","Reconstruction accuracy for fold 4, epoch 64: 0.5255613885819912\n","Training loss for fold 4, epoch 64: 174.0818860453944\n","Validation elbo for fold 4, epoch 65: -20900.71975531517\n","Reconstruction accuracy for fold 4, epoch 65: 0.5266470611095428\n","Training loss for fold 4, epoch 65: 174.22810437602382\n","Validation elbo for fold 4, epoch 66: -20909.743166012722\n","Reconstruction accuracy for fold 4, epoch 66: 0.5284252539277077\n","Training loss for fold 4, epoch 66: 173.27262829196067\n","Validation elbo for fold 4, epoch 67: -20879.436707228608\n","Reconstruction accuracy for fold 4, epoch 67: 0.5279866084456444\n","Training loss for fold 4, epoch 67: 173.39514726208103\n","Validation elbo for fold 4, epoch 68: -20852.11171530591\n","Reconstruction accuracy for fold 4, epoch 68: 0.5284656323492527\n","Training loss for fold 4, epoch 68: 173.05360511041457\n","Validation elbo for fold 4, epoch 69: -20824.168094237055\n","Reconstruction accuracy for fold 4, epoch 69: 0.532024659216404\n","Training loss for fold 4, epoch 69: 172.81822204589844\n","Validation elbo for fold 4, epoch 70: -20805.543883415885\n","Reconstruction accuracy for fold 4, epoch 70: 0.5320474654436111\n","Training loss for fold 4, epoch 70: 171.8291256812311\n","Validation elbo for fold 4, epoch 71: -20792.988216377955\n","Reconstruction accuracy for fold 4, epoch 71: 0.5334033481776714\n","Training loss for fold 4, epoch 71: 171.91167942170173\n","Validation elbo for fold 4, epoch 72: -20819.94937861594\n","Reconstruction accuracy for fold 4, epoch 72: 0.5317661948502064\n","Training loss for fold 4, epoch 72: 171.20049925773375\n","Validation elbo for fold 4, epoch 73: -20759.73532712818\n","Reconstruction accuracy for fold 4, epoch 73: 0.5326267406344414\n","Training loss for fold 4, epoch 73: 171.37603439823275\n","Validation elbo for fold 4, epoch 74: -20745.02963465567\n","Reconstruction accuracy for fold 4, epoch 74: 0.532682191580534\n","Training loss for fold 4, epoch 74: 170.69483873921055\n","Validation elbo for fold 4, epoch 75: -20689.39978556906\n","Reconstruction accuracy for fold 4, epoch 75: 0.5337045304477215\n","Training loss for fold 4, epoch 75: 170.78211950486707\n","Validation elbo for fold 4, epoch 76: -20703.64031165132\n","Reconstruction accuracy for fold 4, epoch 76: 0.533394206315279\n","Training loss for fold 4, epoch 76: 170.0411138226909\n","Validation elbo for fold 4, epoch 77: -20697.5303384922\n","Reconstruction accuracy for fold 4, epoch 77: 0.5326248072087765\n","Training loss for fold 4, epoch 77: 169.8104774721207\n","Validation elbo for fold 4, epoch 78: -20688.70021578826\n","Reconstruction accuracy for fold 4, epoch 78: 0.5324682667851448\n","Training loss for fold 4, epoch 78: 168.79668524957472\n","Validation elbo for fold 4, epoch 79: -20632.77133216941\n","Reconstruction accuracy for fold 4, epoch 79: 0.5337847322225571\n","Training loss for fold 4, epoch 79: 168.59016590733683\n","Validation elbo for fold 4, epoch 80: -20633.816587841477\n","Reconstruction accuracy for fold 4, epoch 80: 0.5364419966936111\n","Training loss for fold 4, epoch 80: 168.00777484524636\n","Validation elbo for fold 4, epoch 81: -20642.581865218388\n","Reconstruction accuracy for fold 4, epoch 81: 0.5359506793320179\n","Training loss for fold 4, epoch 81: 168.8219510970577\n","Validation elbo for fold 4, epoch 82: -20620.345152540373\n","Reconstruction accuracy for fold 4, epoch 82: 0.5349308289587498\n","Training loss for fold 4, epoch 82: 167.7268282982611\n","Validation elbo for fold 4, epoch 83: -20591.47024581897\n","Reconstruction accuracy for fold 4, epoch 83: 0.5369435586035252\n","Training loss for fold 4, epoch 83: 167.7851798765121\n","Validation elbo for fold 4, epoch 84: -20589.939430448394\n","Reconstruction accuracy for fold 4, epoch 84: 0.5357775427401066\n","Training loss for fold 4, epoch 84: 167.57318090623426\n","Validation elbo for fold 4, epoch 85: -20574.689431439056\n","Reconstruction accuracy for fold 4, epoch 85: 0.5372008979320526\n","Training loss for fold 4, epoch 85: 166.8252452727287\n","Validation elbo for fold 4, epoch 86: -20578.483627019465\n","Reconstruction accuracy for fold 4, epoch 86: 0.5366826243698597\n","Training loss for fold 4, epoch 86: 167.23406440980972\n","Validation elbo for fold 4, epoch 87: -20509.747462348983\n","Reconstruction accuracy for fold 4, epoch 87: 0.5380672477185726\n","Training loss for fold 4, epoch 87: 166.41385527580016\n","Validation elbo for fold 4, epoch 88: -20494.86609322405\n","Reconstruction accuracy for fold 4, epoch 88: 0.539739515632391\n","Training loss for fold 4, epoch 88: 165.76431422079764\n","Validation elbo for fold 4, epoch 89: -20512.826908484723\n","Reconstruction accuracy for fold 4, epoch 89: 0.538079559803009\n","Training loss for fold 4, epoch 89: 165.82632741620463\n","Validation elbo for fold 4, epoch 90: -20516.60437162182\n","Reconstruction accuracy for fold 4, epoch 90: 0.5368864424526691\n","Training loss for fold 4, epoch 90: 165.5114723943895\n","Validation elbo for fold 4, epoch 91: -20493.90125193534\n","Reconstruction accuracy for fold 4, epoch 91: 0.5374170392751694\n","Training loss for fold 4, epoch 91: 166.0686773484753\n","Validation elbo for fold 4, epoch 92: -20491.261746683165\n","Reconstruction accuracy for fold 4, epoch 92: 0.5393279939889908\n","Training loss for fold 4, epoch 92: 164.95994247928743\n","Validation elbo for fold 4, epoch 93: -20507.052462728123\n","Reconstruction accuracy for fold 4, epoch 93: 0.5388072058558464\n","Training loss for fold 4, epoch 93: 165.0395465973885\n","Validation elbo for fold 4, epoch 94: -20454.224062837027\n","Reconstruction accuracy for fold 4, epoch 94: 0.5407483018934727\n","Training loss for fold 4, epoch 94: 164.73468878961378\n","Validation elbo for fold 4, epoch 95: -20425.025944265337\n","Reconstruction accuracy for fold 4, epoch 95: 0.5393228717148304\n","Training loss for fold 4, epoch 95: 164.36348699754285\n","Validation elbo for fold 4, epoch 96: -20423.1213650137\n","Reconstruction accuracy for fold 4, epoch 96: 0.5419732257723808\n","Training loss for fold 4, epoch 96: 164.17494226271106\n","Validation elbo for fold 4, epoch 97: -20426.792635679456\n","Reconstruction accuracy for fold 4, epoch 97: 0.5411439351737499\n","Training loss for fold 4, epoch 97: 164.48331303750314\n","Validation elbo for fold 4, epoch 98: -20451.558540436206\n","Reconstruction accuracy for fold 4, epoch 98: 0.5396948531270027\n","Training loss for fold 4, epoch 98: 163.65256869408393\n","Validation elbo for fold 4, epoch 99: -20397.286741241885\n","Reconstruction accuracy for fold 4, epoch 99: 0.5417158789932728\n","Training loss for fold 4, epoch 99: 162.9314897598759\n","Validation elbo for fold 4, epoch 100: -20327.114798285715\n","Reconstruction accuracy for fold 4, epoch 100: 0.5434973984956741\n","Training loss for fold 4, epoch 100: 162.79825124432963\n","Validation elbo for fold 4, epoch 101: -20403.337987441424\n","Reconstruction accuracy for fold 4, epoch 101: 0.5403142273426056\n","Training loss for fold 4, epoch 101: 163.17720794677734\n","Validation elbo for fold 4, epoch 102: -20458.63842189972\n","Reconstruction accuracy for fold 4, epoch 102: 0.5399632677435875\n","Training loss for fold 4, epoch 102: 163.01439642137098\n","Validation elbo for fold 4, epoch 103: -20350.988330923607\n","Reconstruction accuracy for fold 4, epoch 103: 0.5418229103088379\n","Training loss for fold 4, epoch 103: 162.09996549544795\n","Validation elbo for fold 4, epoch 104: -20409.935753830054\n","Reconstruction accuracy for fold 4, epoch 104: 0.5407636538147926\n","Training loss for fold 4, epoch 104: 162.69680983020413\n","Validation elbo for fold 4, epoch 105: -20317.3060764466\n","Reconstruction accuracy for fold 4, epoch 105: 0.5461831502616405\n","Training loss for fold 4, epoch 105: 161.98644871865548\n","Validation elbo for fold 4, epoch 106: -20345.426130282496\n","Reconstruction accuracy for fold 4, epoch 106: 0.5419674180448055\n","Training loss for fold 4, epoch 106: 161.7033669256395\n","Validation elbo for fold 4, epoch 107: -20340.010097188107\n","Reconstruction accuracy for fold 4, epoch 107: 0.5440307594835758\n","Training loss for fold 4, epoch 107: 161.85732195454258\n","Validation elbo for fold 4, epoch 108: -20359.39492544976\n","Reconstruction accuracy for fold 4, epoch 108: 0.5433057323098183\n","Training loss for fold 4, epoch 108: 161.93325879496913\n","Validation elbo for fold 4, epoch 109: -20348.11753759535\n","Reconstruction accuracy for fold 4, epoch 109: 0.5429621040821075\n","Training loss for fold 4, epoch 109: 161.92782912715788\n","Validation elbo for fold 4, epoch 110: -20337.223434502306\n","Reconstruction accuracy for fold 4, epoch 110: 0.5429745465517044\n","Training loss for fold 4, epoch 110: 161.19891012868572\n","Validation elbo for fold 4, epoch 111: -20264.361215939723\n","Reconstruction accuracy for fold 4, epoch 111: 0.5457476861774921\n","Training loss for fold 4, epoch 111: 160.55318057152533\n","Validation elbo for fold 4, epoch 112: -20293.509186735835\n","Reconstruction accuracy for fold 4, epoch 112: 0.5440765246748924\n","Training loss for fold 4, epoch 112: 161.10955441382623\n","Validation elbo for fold 4, epoch 113: -20285.999838613232\n","Reconstruction accuracy for fold 4, epoch 113: 0.5441505052149296\n","Training loss for fold 4, epoch 113: 160.76082020421183\n","Validation elbo for fold 4, epoch 114: -20254.20265180763\n","Reconstruction accuracy for fold 4, epoch 114: 0.5474703051149845\n","Training loss for fold 4, epoch 114: 159.59462196596206\n","Validation elbo for fold 4, epoch 115: -20270.05298523417\n","Reconstruction accuracy for fold 4, epoch 115: 0.5445162653923035\n","Training loss for fold 4, epoch 115: 160.01411708708733\n","Validation elbo for fold 4, epoch 116: -20288.81501512031\n","Reconstruction accuracy for fold 4, epoch 116: 0.5458612181246281\n","Training loss for fold 4, epoch 116: 160.4753221081149\n","Validation elbo for fold 4, epoch 117: -20272.109448387982\n","Reconstruction accuracy for fold 4, epoch 117: 0.5419347882270813\n","Training loss for fold 4, epoch 117: 160.01764678955078\n","Validation elbo for fold 4, epoch 118: -20240.446515313415\n","Reconstruction accuracy for fold 4, epoch 118: 0.5449255965650082\n","Training loss for fold 4, epoch 118: 159.84491729736328\n","Validation elbo for fold 4, epoch 119: -20278.17884530018\n","Reconstruction accuracy for fold 4, epoch 119: 0.5455666743218899\n","Training loss for fold 4, epoch 119: 159.15545063634073\n","Validation elbo for fold 4, epoch 120: -20266.1868648659\n","Reconstruction accuracy for fold 4, epoch 120: 0.5458453185856342\n","Training loss for fold 4, epoch 120: 158.84474612820534\n","Validation elbo for fold 4, epoch 121: -20232.671951215612\n","Reconstruction accuracy for fold 4, epoch 121: 0.5473888516426086\n","Training loss for fold 4, epoch 121: 159.1013439547631\n","Validation elbo for fold 4, epoch 122: -20248.813663936955\n","Reconstruction accuracy for fold 4, epoch 122: 0.5454152598977089\n","Training loss for fold 4, epoch 122: 158.6161673761183\n","Validation elbo for fold 4, epoch 123: -20244.696105150826\n","Reconstruction accuracy for fold 4, epoch 123: 0.5477812960743904\n","Training loss for fold 4, epoch 123: 158.5968721451298\n","Validation elbo for fold 4, epoch 124: -20196.347048805175\n","Reconstruction accuracy for fold 4, epoch 124: 0.5468939244747162\n","Training loss for fold 4, epoch 124: 158.6293996995495\n","Validation elbo for fold 4, epoch 125: -20213.126608835344\n","Reconstruction accuracy for fold 4, epoch 125: 0.5475510582327843\n","Training loss for fold 4, epoch 125: 158.36370751165575\n","Validation elbo for fold 4, epoch 126: -20172.0670215398\n","Reconstruction accuracy for fold 4, epoch 126: 0.5486065708100796\n","Training loss for fold 4, epoch 126: 158.38341620660597\n","Validation elbo for fold 4, epoch 127: -20177.177382073372\n","Reconstruction accuracy for fold 4, epoch 127: 0.5484471283853054\n","Training loss for fold 4, epoch 127: 157.2532016384986\n","Validation elbo for fold 4, epoch 128: -20206.575440019198\n","Reconstruction accuracy for fold 4, epoch 128: 0.5447662957012653\n","Training loss for fold 4, epoch 128: 158.60980372275077\n","Validation elbo for fold 4, epoch 129: -20200.85125046946\n","Reconstruction accuracy for fold 4, epoch 129: 0.5501910299062729\n","Training loss for fold 4, epoch 129: 158.09008518342048\n","Validation elbo for fold 4, epoch 130: -20173.193310548493\n","Reconstruction accuracy for fold 4, epoch 130: 0.5473071299493313\n","Training loss for fold 4, epoch 130: 157.88472058696132\n","Validation elbo for fold 4, epoch 131: -20166.49060529485\n","Reconstruction accuracy for fold 4, epoch 131: 0.5482138507068157\n","Training loss for fold 4, epoch 131: 157.50867043772053\n","Validation elbo for fold 4, epoch 132: -20188.60330226585\n","Reconstruction accuracy for fold 4, epoch 132: 0.5483673512935638\n","Training loss for fold 4, epoch 132: 157.55248875771798\n","Validation elbo for fold 4, epoch 133: -20142.23899658066\n","Reconstruction accuracy for fold 4, epoch 133: 0.5486407317221165\n","Training loss for fold 4, epoch 133: 157.21437589583857\n","Validation elbo for fold 4, epoch 134: -20210.651144223844\n","Reconstruction accuracy for fold 4, epoch 134: 0.5481275655329227\n","Training loss for fold 4, epoch 134: 157.91223710583103\n","Validation elbo for fold 4, epoch 135: -20198.181744579237\n","Reconstruction accuracy for fold 4, epoch 135: 0.5476854629814625\n","Training loss for fold 4, epoch 135: 156.91254351215977\n","Validation elbo for fold 4, epoch 136: -20164.693609744587\n","Reconstruction accuracy for fold 4, epoch 136: 0.548982709646225\n","Training loss for fold 4, epoch 136: 157.52407763081212\n","Validation elbo for fold 4, epoch 137: -20198.48858187429\n","Reconstruction accuracy for fold 4, epoch 137: 0.5466611906886101\n","Training loss for fold 4, epoch 137: 156.6040782313193\n","Validation elbo for fold 4, epoch 138: -20153.39492715239\n","Reconstruction accuracy for fold 4, epoch 138: 0.5480231493711472\n","Training loss for fold 4, epoch 138: 156.9947728803081\n","Validation elbo for fold 4, epoch 139: -20157.753357488917\n","Reconstruction accuracy for fold 4, epoch 139: 0.5493392124772072\n","Training loss for fold 4, epoch 139: 156.40022966938633\n","Validation elbo for fold 4, epoch 140: -20172.619223352973\n","Reconstruction accuracy for fold 4, epoch 140: 0.5463861506432295\n","Training loss for fold 4, epoch 140: 156.6734375492219\n","Validation elbo for fold 4, epoch 141: -20169.709784824146\n","Reconstruction accuracy for fold 4, epoch 141: 0.5495116487145424\n","Training loss for fold 4, epoch 141: 155.63330816453504\n","Validation elbo for fold 4, epoch 142: -20157.46975040996\n","Reconstruction accuracy for fold 4, epoch 142: 0.550487793982029\n","Training loss for fold 4, epoch 142: 155.77177035424018\n","Validation elbo for fold 4, epoch 143: -20168.09286785023\n","Reconstruction accuracy for fold 4, epoch 143: 0.5516164638102055\n","Training loss for fold 4, epoch 143: 156.0290524882655\n","Validation elbo for fold 4, epoch 144: -20157.896021925742\n","Reconstruction accuracy for fold 4, epoch 144: 0.5495655797421932\n","Training loss for fold 4, epoch 144: 155.86031489218436\n","Validation elbo for fold 4, epoch 145: -20127.93567304659\n","Reconstruction accuracy for fold 4, epoch 145: 0.5481334999203682\n","Training loss for fold 4, epoch 145: 155.11520016577936\n","Validation elbo for fold 4, epoch 146: -20128.322775598404\n","Reconstruction accuracy for fold 4, epoch 146: 0.550902783870697\n","Training loss for fold 4, epoch 146: 155.5796149469191\n","Validation elbo for fold 4, epoch 147: -20164.879311392215\n","Reconstruction accuracy for fold 4, epoch 147: 0.546878170222044\n","Training loss for fold 4, epoch 147: 155.15547672394783\n","Validation elbo for fold 4, epoch 148: -20106.415115833275\n","Reconstruction accuracy for fold 4, epoch 148: 0.5487440265715122\n","Training loss for fold 4, epoch 148: 156.36773583196825\n","Validation elbo for fold 4, epoch 149: -20170.562878455392\n","Reconstruction accuracy for fold 4, epoch 149: 0.5482769124209881\n","Training loss for fold 4, epoch 149: 155.0336448915543\n","Validation elbo for fold 4, epoch 150: -20104.220355942973\n","Reconstruction accuracy for fold 4, epoch 150: 0.5504081472754478\n","Training loss for fold 4, epoch 150: 154.52578759962512\n","Validation elbo for fold 4, epoch 151: -20096.487286678206\n","Reconstruction accuracy for fold 4, epoch 151: 0.5507579930126667\n","Training loss for fold 4, epoch 151: 154.6235797020697\n","Validation elbo for fold 4, epoch 152: -20154.605701708835\n","Reconstruction accuracy for fold 4, epoch 152: 0.5498178079724312\n","Training loss for fold 4, epoch 152: 154.51939613588394\n","Validation elbo for fold 4, epoch 153: -20123.366280412913\n","Reconstruction accuracy for fold 4, epoch 153: 0.5496723279356956\n","Training loss for fold 4, epoch 153: 155.39556663267075\n","Validation elbo for fold 4, epoch 154: -20107.948643925367\n","Reconstruction accuracy for fold 4, epoch 154: 0.55236029997468\n","Training loss for fold 4, epoch 154: 154.97761830975932\n","Validation elbo for fold 4, epoch 155: -20146.26594963127\n","Reconstruction accuracy for fold 4, epoch 155: 0.5503540709614754\n","Training loss for fold 4, epoch 155: 154.71886173371345\n","Validation elbo for fold 4, epoch 156: -20120.355537943004\n","Reconstruction accuracy for fold 4, epoch 156: 0.5466665923595428\n","Training loss for fold 4, epoch 156: 153.98568504087388\n","Validation elbo for fold 4, epoch 157: -20128.08764567687\n","Reconstruction accuracy for fold 4, epoch 157: 0.5506117008626461\n","Training loss for fold 4, epoch 157: 154.54287793559413\n","Validation elbo for fold 4, epoch 158: -20122.822782894174\n","Reconstruction accuracy for fold 4, epoch 158: 0.5504512898623943\n","Training loss for fold 4, epoch 158: 155.09427888931768\n","Validation elbo for fold 4, epoch 159: -20103.253752076867\n","Reconstruction accuracy for fold 4, epoch 159: 0.551125843077898\n","Training loss for fold 4, epoch 159: 153.26648712158203\n","Validation elbo for fold 4, epoch 160: -20118.154297887286\n","Reconstruction accuracy for fold 4, epoch 160: 0.5496893413364887\n","Training loss for fold 4, epoch 160: 155.1995198649745\n","Validation elbo for fold 4, epoch 161: -20119.721054774524\n","Reconstruction accuracy for fold 4, epoch 161: 0.5483872517943382\n","Training loss for fold 4, epoch 161: 154.346796589513\n","Validation elbo for fold 4, epoch 162: -20186.121603189873\n","Reconstruction accuracy for fold 4, epoch 162: 0.5484944209456444\n","Training loss for fold 4, epoch 162: 154.1055878669985\n","Validation elbo for fold 4, epoch 163: -20146.43916489197\n","Reconstruction accuracy for fold 4, epoch 163: 0.5489916913211346\n","Training loss for fold 4, epoch 163: 153.8528060913086\n","Validation elbo for fold 4, epoch 164: -20104.50172250962\n","Reconstruction accuracy for fold 4, epoch 164: 0.5520638152956963\n","Training loss for fold 4, epoch 164: 153.86778210055442\n","Validation elbo for fold 4, epoch 165: -20080.16699319268\n","Reconstruction accuracy for fold 4, epoch 165: 0.5478966254740953\n","Training loss for fold 4, epoch 165: 153.63106020035283\n","Validation elbo for fold 4, epoch 166: -20049.30508510954\n","Reconstruction accuracy for fold 4, epoch 166: 0.550862405449152\n","Training loss for fold 4, epoch 166: 153.40666961669922\n","Validation elbo for fold 4, epoch 167: -20149.595102101288\n","Reconstruction accuracy for fold 4, epoch 167: 0.5499049238860607\n","Training loss for fold 4, epoch 167: 153.1678235453944\n","Validation elbo for fold 4, epoch 168: -20082.5671957601\n","Reconstruction accuracy for fold 4, epoch 168: 0.5521339252591133\n","Training loss for fold 4, epoch 168: 152.8084953061996\n","Validation elbo for fold 4, epoch 169: -20053.893178510072\n","Reconstruction accuracy for fold 4, epoch 169: 0.5499136373400688\n","Training loss for fold 4, epoch 169: 153.02958162369268\n","Validation elbo for fold 4, epoch 170: -20092.560299341007\n","Reconstruction accuracy for fold 4, epoch 170: 0.5503627844154835\n","Training loss for fold 4, epoch 170: 152.58850368376702\n","Validation elbo for fold 4, epoch 171: -20050.170008593137\n","Reconstruction accuracy for fold 4, epoch 171: 0.5511900037527084\n","Training loss for fold 4, epoch 171: 152.91167499173073\n","Validation elbo for fold 4, epoch 172: -20090.443987557148\n","Reconstruction accuracy for fold 4, epoch 172: 0.5543694235384464\n","Training loss for fold 4, epoch 172: 153.00788067233177\n","Validation elbo for fold 4, epoch 173: -20080.293791388864\n","Reconstruction accuracy for fold 4, epoch 173: 0.5519399084150791\n","Training loss for fold 4, epoch 173: 152.56609713646674\n","Validation elbo for fold 4, epoch 174: -20070.93925912504\n","Reconstruction accuracy for fold 4, epoch 174: 0.5493895448744297\n","Training loss for fold 4, epoch 174: 152.80246882284843\n","Validation elbo for fold 4, epoch 175: -20128.989613187485\n","Reconstruction accuracy for fold 4, epoch 175: 0.5481011420488358\n","Training loss for fold 4, epoch 175: 153.13894973262663\n","Validation elbo for fold 4, epoch 176: -20090.3739905677\n","Reconstruction accuracy for fold 4, epoch 176: 0.5514962933957577\n","Training loss for fold 4, epoch 176: 153.05019083330708\n","Validation elbo for fold 4, epoch 177: -20073.069420174055\n","Reconstruction accuracy for fold 4, epoch 177: 0.5505587346851826\n","Training loss for fold 4, epoch 177: 152.5086224463678\n","Validation elbo for fold 4, epoch 178: -20060.446913329302\n","Reconstruction accuracy for fold 4, epoch 178: 0.5547068379819393\n","Training loss for fold 4, epoch 178: 151.9236580633348\n","Validation elbo for fold 4, epoch 179: -20082.671482469963\n","Reconstruction accuracy for fold 4, epoch 179: 0.5502430200576782\n","Training loss for fold 4, epoch 179: 152.3584230484501\n","Validation elbo for fold 4, epoch 180: -20054.14934002638\n","Reconstruction accuracy for fold 4, epoch 180: 0.5514206551015377\n","Training loss for fold 4, epoch 180: 151.96952844435168\n","Validation elbo for fold 4, epoch 181: -20068.97153254073\n","Reconstruction accuracy for fold 4, epoch 181: 0.5520072504878044\n","Training loss for fold 4, epoch 181: 151.71129534321446\n","Validation elbo for fold 4, epoch 182: -20063.27587370991\n","Reconstruction accuracy for fold 4, epoch 182: 0.5510436967015266\n","Training loss for fold 4, epoch 182: 151.72384766609437\n","Validation elbo for fold 4, epoch 183: -20095.44615487531\n","Reconstruction accuracy for fold 4, epoch 183: 0.5534272976219654\n","Training loss for fold 4, epoch 183: 152.06610562724453\n","Validation elbo for fold 4, epoch 184: -20113.734217047328\n","Reconstruction accuracy for fold 4, epoch 184: 0.5534466542303562\n","Training loss for fold 4, epoch 184: 151.96110263947517\n","Validation elbo for fold 4, epoch 185: -20027.781653689082\n","Reconstruction accuracy for fold 4, epoch 185: 0.550764087587595\n","Training loss for fold 4, epoch 185: 151.61168892152847\n","Validation elbo for fold 4, epoch 186: -20075.327748386557\n","Reconstruction accuracy for fold 4, epoch 186: 0.5509247705340385\n","Training loss for fold 4, epoch 186: 151.40693713772683\n","Validation elbo for fold 4, epoch 187: -20074.200653168555\n","Reconstruction accuracy for fold 4, epoch 187: 0.5519538819789886\n","Training loss for fold 4, epoch 187: 151.67020834645916\n","Validation elbo for fold 4, epoch 188: -20061.255479539326\n","Reconstruction accuracy for fold 4, epoch 188: 0.5533161237835884\n","Training loss for fold 4, epoch 188: 151.1945089524792\n","Validation elbo for fold 4, epoch 189: -20095.921306281685\n","Reconstruction accuracy for fold 4, epoch 189: 0.5527564845979214\n","Training loss for fold 4, epoch 189: 151.68441661711663\n","Validation elbo for fold 4, epoch 190: -20042.79652895296\n","Reconstruction accuracy for fold 4, epoch 190: 0.5535079129040241\n","Training loss for fold 4, epoch 190: 151.3974865328881\n","Validation elbo for fold 4, epoch 191: -20097.409881963897\n","Reconstruction accuracy for fold 4, epoch 191: 0.5517259947955608\n","Training loss for fold 4, epoch 191: 150.64997199273878\n","Validation elbo for fold 4, epoch 192: -20057.76047258865\n","Reconstruction accuracy for fold 4, epoch 192: 0.5513555221259594\n","Training loss for fold 4, epoch 192: 151.28668360556327\n","Validation elbo for fold 4, epoch 193: -20031.18719786551\n","Reconstruction accuracy for fold 4, epoch 193: 0.5532805770635605\n","Training loss for fold 4, epoch 193: 151.14944605673514\n","Validation elbo for fold 4, epoch 194: -20099.766507805452\n","Reconstruction accuracy for fold 4, epoch 194: 0.5496640354394913\n","Training loss for fold 4, epoch 194: 151.47154309672695\n","Validation elbo for fold 4, epoch 195: -19992.35742106322\n","Reconstruction accuracy for fold 4, epoch 195: 0.5524947121739388\n","Training loss for fold 4, epoch 195: 150.35879393546813\n","Validation elbo for fold 4, epoch 196: -20082.708341638816\n","Reconstruction accuracy for fold 4, epoch 196: 0.552796583622694\n","Training loss for fold 4, epoch 196: 151.0199161652596\n","Validation elbo for fold 4, epoch 197: -20077.45694444322\n","Reconstruction accuracy for fold 4, epoch 197: 0.5509307160973549\n","Training loss for fold 4, epoch 197: 150.8100459191107\n","Validation elbo for fold 4, epoch 198: -20089.869484070005\n","Reconstruction accuracy for fold 4, epoch 198: 0.5510224103927612\n","Training loss for fold 4, epoch 198: 151.68573760986328\n","Validation elbo for fold 4, epoch 199: -20041.607467085712\n","Reconstruction accuracy for fold 4, epoch 199: 0.5534382276237011\n","Training loss for fold 4, epoch 199: 150.7715606689453\n","Validation elbo for fold 4, epoch 200: -20082.358123344482\n","Reconstruction accuracy for fold 4, epoch 200: 0.5505047999322414\n","Training loss for fold 4, epoch 200: 150.94903318343623\n","Validation elbo for fold 4, epoch 201: -20081.268300462936\n","Reconstruction accuracy for fold 4, epoch 201: 0.553235363215208\n","Training loss for fold 4, epoch 201: 150.5041265180034\n","Validation elbo for fold 4, epoch 202: -20100.760608084624\n","Reconstruction accuracy for fold 4, epoch 202: 0.5495737381279469\n","Training loss for fold 4, epoch 202: 150.12913537794543\n","Validation elbo for fold 4, epoch 203: -20018.449083721025\n","Reconstruction accuracy for fold 4, epoch 203: 0.5530005507171154\n","Training loss for fold 4, epoch 203: 150.52452899563698\n","Validation elbo for fold 4, epoch 204: -20014.46761179179\n","Reconstruction accuracy for fold 4, epoch 204: 0.5527180396020412\n","Training loss for fold 4, epoch 204: 150.29713243053806\n","Validation elbo for fold 4, epoch 205: -20112.745283897188\n","Reconstruction accuracy for fold 4, epoch 205: 0.5512007810175419\n","Training loss for fold 4, epoch 205: 150.61909977082283\n","Validation elbo for fold 4, epoch 206: -20114.29123884885\n","Reconstruction accuracy for fold 4, epoch 206: 0.5487232878804207\n","Training loss for fold 4, epoch 206: 150.60565505489225\n","Validation elbo for fold 4, epoch 207: -20098.324787736037\n","Reconstruction accuracy for fold 4, epoch 207: 0.5533013232052326\n","Training loss for fold 4, epoch 207: 150.41676601286858\n","Validation elbo for fold 4, epoch 208: -20061.858526030315\n","Reconstruction accuracy for fold 4, epoch 208: 0.5520638152956963\n","Training loss for fold 4, epoch 208: 149.67411410424018\n","Validation elbo for fold 4, epoch 209: -20046.894670696653\n","Reconstruction accuracy for fold 4, epoch 209: 0.5529604516923428\n","Training loss for fold 4, epoch 209: 150.38130680207283\n","Validation elbo for fold 4, epoch 210: -20080.348428539066\n","Reconstruction accuracy for fold 4, epoch 210: 0.5517790950834751\n","Training loss for fold 4, epoch 210: 149.91743555376607\n","Validation elbo for fold 4, epoch 211: -20061.638173143325\n","Reconstruction accuracy for fold 4, epoch 211: 0.552892416715622\n","Training loss for fold 4, epoch 211: 149.5758337205456\n","Validation elbo for fold 4, epoch 212: -19979.222343328234\n","Reconstruction accuracy for fold 4, epoch 212: 0.5538088269531727\n","Training loss for fold 4, epoch 212: 149.5429490612399\n","Validation elbo for fold 4, epoch 213: -20030.377964630017\n","Reconstruction accuracy for fold 4, epoch 213: 0.5547817908227444\n","Training loss for fold 4, epoch 213: 149.45097732543945\n","Validation elbo for fold 4, epoch 214: -20043.106058533165\n","Reconstruction accuracy for fold 4, epoch 214: 0.554806400090456\n","Training loss for fold 4, epoch 214: 149.72098935034967\n","Validation elbo for fold 4, epoch 215: -20067.066637760603\n","Reconstruction accuracy for fold 4, epoch 215: 0.5531559772789478\n","Training loss for fold 4, epoch 215: 149.62070711197393\n","Validation elbo for fold 4, epoch 216: -20052.1269735292\n","Reconstruction accuracy for fold 4, epoch 216: 0.5510084256529808\n","Training loss for fold 4, epoch 216: 149.20069762199157\n","Validation elbo for fold 4, epoch 217: -19954.096156002004\n","Reconstruction accuracy for fold 4, epoch 217: 0.556006845086813\n","Training loss for fold 4, epoch 217: 148.6697686718356\n","Validation elbo for fold 4, epoch 218: -20022.281566239573\n","Reconstruction accuracy for fold 4, epoch 218: 0.5553764142096043\n","Training loss for fold 4, epoch 218: 148.90763276623142\n","Validation elbo for fold 4, epoch 219: -20025.467739484542\n","Reconstruction accuracy for fold 4, epoch 219: 0.5516670756042004\n","Training loss for fold 4, epoch 219: 148.87562339536606\n","Validation elbo for fold 4, epoch 220: -20095.41980198017\n","Reconstruction accuracy for fold 4, epoch 220: 0.5527126416563988\n","Training loss for fold 4, epoch 220: 149.31682660502773\n","Validation elbo for fold 4, epoch 221: -20065.316549675634\n","Reconstruction accuracy for fold 4, epoch 221: 0.5533323027193546\n","Training loss for fold 4, epoch 221: 149.12667748235887\n","Validation elbo for fold 4, epoch 222: -20052.245139195715\n","Reconstruction accuracy for fold 4, epoch 222: 0.5533457137644291\n","Training loss for fold 4, epoch 222: 148.63965028332126\n","Validation elbo for fold 4, epoch 223: -20042.089946806333\n","Reconstruction accuracy for fold 4, epoch 223: 0.5550063736736774\n","Training loss for fold 4, epoch 223: 148.71668489517705\n","Validation elbo for fold 4, epoch 224: -20021.736385500917\n","Reconstruction accuracy for fold 4, epoch 224: 0.5553520768880844\n","Training loss for fold 4, epoch 224: 148.93811502764302\n","Validation elbo for fold 4, epoch 225: -20056.884452563867\n","Reconstruction accuracy for fold 4, epoch 225: 0.5529538132250309\n","Training loss for fold 4, epoch 225: 148.83470769082345\n","Validation elbo for fold 4, epoch 226: -20056.51607992265\n","Reconstruction accuracy for fold 4, epoch 226: 0.5551612414419651\n","Training loss for fold 4, epoch 226: 148.6294452298072\n","Validation elbo for fold 4, epoch 227: -19994.640880030383\n","Reconstruction accuracy for fold 4, epoch 227: 0.5525662042200565\n","Training loss for fold 4, epoch 227: 148.99290220199092\n","Validation elbo for fold 4, epoch 228: -20055.87925329462\n","Reconstruction accuracy for fold 4, epoch 228: 0.5530532449483871\n","Training loss for fold 4, epoch 228: 149.92267411754978\n","Validation elbo for fold 4, epoch 229: -20092.250956230084\n","Reconstruction accuracy for fold 4, epoch 229: 0.549596693366766\n","Training loss for fold 4, epoch 229: 148.48701944658833\n","Validation elbo for fold 4, epoch 230: -20039.111521100334\n","Reconstruction accuracy for fold 4, epoch 230: 0.5521503798663616\n","Training loss for fold 4, epoch 230: 148.07010724467617\n","Validation elbo for fold 4, epoch 231: -19997.023896061204\n","Reconstruction accuracy for fold 4, epoch 231: 0.5545590184628963\n","Training loss for fold 4, epoch 231: 147.7315912554341\n","Validation elbo for fold 4, epoch 232: -20037.211983718735\n","Reconstruction accuracy for fold 4, epoch 232: 0.5513701885938644\n","Training loss for fold 4, epoch 232: 148.8655021421371\n","Validation elbo for fold 4, epoch 233: -20044.461705021582\n","Reconstruction accuracy for fold 4, epoch 233: 0.5515683554112911\n","Training loss for fold 4, epoch 233: 148.03887988675027\n","Validation elbo for fold 4, epoch 234: -20033.536955896445\n","Reconstruction accuracy for fold 4, epoch 234: 0.553693912923336\n","Training loss for fold 4, epoch 234: 147.11321959957\n","Validation elbo for fold 4, epoch 235: -20011.489739488425\n","Reconstruction accuracy for fold 4, epoch 235: 0.5541625544428825\n","Training loss for fold 4, epoch 235: 147.77733587449598\n","Validation elbo for fold 4, epoch 236: -20070.185760328684\n","Reconstruction accuracy for fold 4, epoch 236: 0.5536334775388241\n","Training loss for fold 4, epoch 236: 148.68632630378968\n","Validation elbo for fold 4, epoch 237: -20031.55296603222\n","Reconstruction accuracy for fold 4, epoch 237: 0.5536990314722061\n","Training loss for fold 4, epoch 237: 147.91832893125473\n","Validation elbo for fold 4, epoch 238: -20092.55333948216\n","Reconstruction accuracy for fold 4, epoch 238: 0.5538446381688118\n","Training loss for fold 4, epoch 238: 147.93815145184917\n","Validation elbo for fold 4, epoch 239: -20049.2407894855\n","Reconstruction accuracy for fold 4, epoch 239: 0.5542698688805103\n","Training loss for fold 4, epoch 239: 148.73816631686302\n","Validation elbo for fold 4, epoch 240: -20014.648367635982\n","Reconstruction accuracy for fold 4, epoch 240: 0.5532558262348175\n","Training loss for fold 4, epoch 240: 148.37758882584112\n","Validation elbo for fold 4, epoch 241: -20035.542119608654\n","Reconstruction accuracy for fold 4, epoch 241: 0.5553046502172947\n","Training loss for fold 4, epoch 241: 147.56618561283236\n","Validation elbo for fold 4, epoch 242: -20028.464001609434\n","Reconstruction accuracy for fold 4, epoch 242: 0.5541554987430573\n","Training loss for fold 4, epoch 242: 148.56002930671937\n","Validation elbo for fold 4, epoch 243: -20065.074046995967\n","Reconstruction accuracy for fold 4, epoch 243: 0.5563128776848316\n","Training loss for fold 4, epoch 243: 147.99537781746156\n","Validation elbo for fold 4, epoch 244: -20068.49427361078\n","Reconstruction accuracy for fold 4, epoch 244: 0.5552805811166763\n","Training loss for fold 4, epoch 244: 147.65584502681608\n","Validation elbo for fold 4, epoch 245: -20032.95934211698\n","Reconstruction accuracy for fold 4, epoch 245: 0.5557127185165882\n","Training loss for fold 4, epoch 245: 147.45433856594948\n","Validation elbo for fold 4, epoch 246: -20063.254386026976\n","Reconstruction accuracy for fold 4, epoch 246: 0.554644200950861\n","Training loss for fold 4, epoch 246: 147.06008886521863\n","Validation elbo for fold 4, epoch 247: -20106.010881298847\n","Reconstruction accuracy for fold 4, epoch 247: 0.5527927055954933\n","Training loss for fold 4, epoch 247: 147.9509642816359\n","Validation elbo for fold 4, epoch 248: -20073.28263612351\n","Reconstruction accuracy for fold 4, epoch 248: 0.5539088025689125\n","Training loss for fold 4, epoch 248: 147.56761821623772\n","Validation elbo for fold 4, epoch 249: -20057.872464271044\n","Reconstruction accuracy for fold 4, epoch 249: 0.5544736944139004\n","Training loss for fold 4, epoch 249: 148.18710056427986\n","Validation elbo for fold 4, epoch 250: -19981.342706985994\n","Reconstruction accuracy for fold 4, epoch 250: 0.5557822734117508\n","Training loss for fold 4, epoch 250: 146.88113674040764\n","Validation elbo for fold 4, epoch 251: -20013.8506781341\n","Reconstruction accuracy for fold 4, epoch 251: 0.5528124906122684\n","Training loss for fold 4, epoch 251: 147.57568826983052\n","Validation elbo for fold 4, epoch 252: -20013.637277298847\n","Reconstruction accuracy for fold 4, epoch 252: 0.5555167719721794\n","Training loss for fold 4, epoch 252: 147.50582910353137\n","Validation elbo for fold 4, epoch 253: -20059.532035612312\n","Reconstruction accuracy for fold 4, epoch 253: 0.5526133589446545\n","Training loss for fold 4, epoch 253: 147.91871298513104\n","Validation elbo for fold 4, epoch 254: -20075.75618207576\n","Reconstruction accuracy for fold 4, epoch 254: 0.5543571226298809\n","Training loss for fold 4, epoch 254: 147.75339975664693\n","Validation elbo for fold 4, epoch 255: -20040.278106946454\n","Reconstruction accuracy for fold 4, epoch 255: 0.5536525622010231\n","Training loss for fold 4, epoch 255: 147.9665444897067\n","Validation elbo for fold 4, epoch 256: -19993.918061372045\n","Reconstruction accuracy for fold 4, epoch 256: 0.5548221729695797\n","Training loss for fold 4, epoch 256: 147.4109849006899\n","Validation elbo for fold 4, epoch 257: -19996.653823838038\n","Reconstruction accuracy for fold 4, epoch 257: 0.555993989109993\n","Training loss for fold 4, epoch 257: 146.75207642586\n","Validation elbo for fold 4, epoch 258: -20074.80602213293\n","Reconstruction accuracy for fold 4, epoch 258: 0.5524497777223587\n","Training loss for fold 4, epoch 258: 147.05361926171088\n","Validation elbo for fold 4, epoch 259: -20055.564071604065\n","Reconstruction accuracy for fold 4, epoch 259: 0.5552753321826458\n","Training loss for fold 4, epoch 259: 146.67671991163684\n","Validation elbo for fold 4, epoch 260: -20054.85098994824\n","Reconstruction accuracy for fold 4, epoch 260: 0.553739819675684\n","Training loss for fold 4, epoch 260: 146.9416294713174\n","Validation elbo for fold 4, epoch 261: -20100.58256641159\n","Reconstruction accuracy for fold 4, epoch 261: 0.5529502220451832\n","Training loss for fold 4, epoch 261: 147.36745206771357\n","Validation elbo for fold 4, epoch 262: -20035.461663420232\n","Reconstruction accuracy for fold 4, epoch 262: 0.5572826601564884\n","Training loss for fold 4, epoch 262: 146.52043041106194\n","Validation elbo for fold 4, epoch 263: -20071.05495845252\n","Reconstruction accuracy for fold 4, epoch 263: 0.5541499778628349\n","Training loss for fold 4, epoch 263: 147.05478422103388\n","Validation elbo for fold 4, epoch 264: -20048.473515047895\n","Reconstruction accuracy for fold 4, epoch 264: 0.5531533658504486\n","Training loss for fold 4, epoch 264: 147.0580788889239\n","Validation elbo for fold 4, epoch 265: -20114.767281053795\n","Reconstruction accuracy for fold 4, epoch 265: 0.5534942299127579\n","Training loss for fold 4, epoch 265: 146.85253143310547\n","Validation elbo for fold 4, epoch 266: -20016.14734548402\n","Reconstruction accuracy for fold 4, epoch 266: 0.5538460239768028\n","Training loss for fold 4, epoch 266: 147.68403022520005\n","Validation elbo for fold 4, epoch 267: -20103.78497243979\n","Reconstruction accuracy for fold 4, epoch 267: 0.5512849986553192\n","Training loss for fold 4, epoch 267: 147.1876941803963\n","Validation elbo for fold 4, epoch 268: -20038.903775625335\n","Reconstruction accuracy for fold 4, epoch 268: 0.5540463924407959\n","Training loss for fold 4, epoch 268: 146.4032397116384\n","Validation elbo for fold 4, epoch 269: -20058.948119390545\n","Reconstruction accuracy for fold 4, epoch 269: 0.5509390234947205\n","Training loss for fold 4, epoch 269: 146.64212183798514\n","Validation elbo for fold 4, epoch 270: -20075.3727111946\n","Reconstruction accuracy for fold 4, epoch 270: 0.5554226078093052\n","Training loss for fold 4, epoch 270: 146.54840776997227\n","Validation elbo for fold 4, epoch 271: -20021.607044575787\n","Reconstruction accuracy for fold 4, epoch 271: 0.5538818351924419\n","Training loss for fold 4, epoch 271: 146.78347261490362\n","Validation elbo for fold 4, epoch 272: -20084.25652958245\n","Reconstruction accuracy for fold 4, epoch 272: 0.5557239167392254\n","Training loss for fold 4, epoch 272: 146.9761674942509\n","Validation elbo for fold 4, epoch 273: -20059.20908975731\n","Reconstruction accuracy for fold 4, epoch 273: 0.5547380894422531\n","Training loss for fold 4, epoch 273: 145.88657625259893\n","Validation elbo for fold 4, epoch 274: -20032.049953492507\n","Reconstruction accuracy for fold 4, epoch 274: 0.5547104366123676\n","Training loss for fold 4, epoch 274: 145.96963796307963\n","Validation elbo for fold 4, epoch 275: -20052.26762019567\n","Reconstruction accuracy for fold 4, epoch 275: 0.5527628399431705\n","Training loss for fold 4, epoch 275: 145.27139171477288\n","Validation elbo for fold 4, epoch 276: -20098.488508406685\n","Reconstruction accuracy for fold 4, epoch 276: 0.5521344840526581\n","Training loss for fold 4, epoch 276: 146.47454218710624\n","Validation elbo for fold 4, epoch 277: -20065.38643476906\n","Reconstruction accuracy for fold 4, epoch 277: 0.5551941581070423\n","Training loss for fold 4, epoch 277: 148.68821667086692\n","Validation elbo for fold 4, epoch 278: -20007.763772594146\n","Reconstruction accuracy for fold 4, epoch 278: 0.5541267395019531\n","Training loss for fold 4, epoch 278: 147.45988488966418\n","Validation elbo for fold 4, epoch 279: -20093.84917789141\n","Reconstruction accuracy for fold 4, epoch 279: 0.5527626983821392\n","Training loss for fold 4, epoch 279: 146.94200700329196\n","Validation elbo for fold 4, epoch 280: -20065.61249538977\n","Reconstruction accuracy for fold 4, epoch 280: 0.5536893494427204\n","Training loss for fold 4, epoch 280: 147.08479788995558\n","Validation elbo for fold 4, epoch 281: -20060.533135226022\n","Reconstruction accuracy for fold 4, epoch 281: 0.5543323718011379\n","Training loss for fold 4, epoch 281: 145.8670778582173\n","Validation elbo for fold 4, epoch 282: -19995.944372724975\n","Reconstruction accuracy for fold 4, epoch 282: 0.5563351400196552\n","Training loss for fold 4, epoch 282: 145.98974424792874\n","Validation elbo for fold 4, epoch 283: -20046.603261447257\n","Reconstruction accuracy for fold 4, epoch 283: 0.553530178964138\n","Training loss for fold 4, epoch 283: 146.0423852243731\n","Validation elbo for fold 4, epoch 284: -20041.474373005633\n","Reconstruction accuracy for fold 4, epoch 284: 0.5543567053973675\n","Training loss for fold 4, epoch 284: 147.0236075616652\n","Validation elbo for fold 4, epoch 285: -20073.882635859034\n","Reconstruction accuracy for fold 4, epoch 285: 0.5542706921696663\n","Training loss for fold 4, epoch 285: 146.61066190658076\n","Validation elbo for fold 4, epoch 286: -20034.073676329543\n","Reconstruction accuracy for fold 4, epoch 286: 0.5550253093242645\n","Training loss for fold 4, epoch 286: 146.01991321194558\n","Validation elbo for fold 4, epoch 287: -20010.469666778554\n","Reconstruction accuracy for fold 4, epoch 287: 0.553665280342102\n","Training loss for fold 4, epoch 287: 145.44492856917842\n","Validation elbo for fold 4, epoch 288: -20013.88996079588\n","Reconstruction accuracy for fold 4, epoch 288: 0.5557165928184986\n","Training loss for fold 4, epoch 288: 146.19727017802578\n","Validation elbo for fold 4, epoch 289: -20046.19214101867\n","Reconstruction accuracy for fold 4, epoch 289: 0.5532377138733864\n","Training loss for fold 4, epoch 289: 145.8530266054215\n","Validation elbo for fold 4, epoch 290: -20052.51233070822\n","Reconstruction accuracy for fold 4, epoch 290: 0.5550514496862888\n","Training loss for fold 4, epoch 290: 146.10430834370274\n","Validation elbo for fold 4, epoch 291: -20044.82251615991\n","Reconstruction accuracy for fold 4, epoch 291: 0.55327283218503\n","Training loss for fold 4, epoch 291: 146.36826878209268\n","Validation elbo for fold 4, epoch 292: -20007.600929523505\n","Reconstruction accuracy for fold 4, epoch 292: 0.5539298206567764\n","Training loss for fold 4, epoch 292: 144.5470945296749\n","Validation elbo for fold 4, epoch 293: -20077.5774522824\n","Reconstruction accuracy for fold 4, epoch 293: 0.5547181852161884\n","Training loss for fold 4, epoch 293: 146.10202924666865\n","Validation elbo for fold 4, epoch 294: -20069.218088792833\n","Reconstruction accuracy for fold 4, epoch 294: 0.5557884983718395\n","Training loss for fold 4, epoch 294: 146.63513872700352\n","Validation elbo for fold 4, epoch 295: -20143.870419124545\n","Reconstruction accuracy for fold 4, epoch 295: 0.551310308277607\n","Training loss for fold 4, epoch 295: 146.26830587079448\n","Validation elbo for fold 4, epoch 296: -20115.251982027465\n","Reconstruction accuracy for fold 4, epoch 296: 0.5513448752462864\n","Training loss for fold 4, epoch 296: 146.3147832808956\n","Validation elbo for fold 4, epoch 297: -20015.46683820317\n","Reconstruction accuracy for fold 4, epoch 297: 0.5556240864098072\n","Training loss for fold 4, epoch 297: 145.3542463241085\n","Validation elbo for fold 4, epoch 298: -20104.105595026725\n","Reconstruction accuracy for fold 4, epoch 298: 0.5547953508794308\n","Training loss for fold 4, epoch 298: 145.19112396240234\n","Validation elbo for fold 4, epoch 299: -20055.804182922184\n","Reconstruction accuracy for fold 4, epoch 299: 0.5566477887332439\n","Training loss for fold 4, epoch 299: 145.27358504264586\n","Validation elbo for fold 4, epoch 300: -20009.78091736252\n","Reconstruction accuracy for fold 4, epoch 300: 0.5553307719528675\n","Training loss for fold 4, epoch 300: 145.50751224640877\n","Validation elbo for fold 4, epoch 301: -20025.352946873078\n","Reconstruction accuracy for fold 4, epoch 301: 0.5533994995057583\n","Training loss for fold 4, epoch 301: 145.5258664777202\n","Validation elbo for fold 4, epoch 302: -20056.941256330643\n","Reconstruction accuracy for fold 4, epoch 302: 0.55466203764081\n","Training loss for fold 4, epoch 302: 146.59551657399822\n","Validation elbo for fold 4, epoch 303: -20060.184601522124\n","Reconstruction accuracy for fold 4, epoch 303: 0.5564620867371559\n","Training loss for fold 4, epoch 303: 145.89155652446132\n","Validation elbo for fold 4, epoch 304: -20075.318038044385\n","Reconstruction accuracy for fold 4, epoch 304: 0.5536763519048691\n","Training loss for fold 4, epoch 304: 145.67500711256457\n","Validation elbo for fold 4, epoch 305: -20060.178093477003\n","Reconstruction accuracy for fold 4, epoch 305: 0.5554609075188637\n","Training loss for fold 4, epoch 305: 145.8371196869881\n","Validation elbo for fold 4, epoch 306: -20063.980174748383\n","Reconstruction accuracy for fold 4, epoch 306: 0.5563933551311493\n","Training loss for fold 4, epoch 306: 146.1435154330346\n","Validation elbo for fold 4, epoch 307: -20040.532514298\n","Reconstruction accuracy for fold 4, epoch 307: 0.5551074594259262\n","Training loss for fold 4, epoch 307: 145.6755373554845\n","Validation elbo for fold 4, epoch 308: -20059.51753275012\n","Reconstruction accuracy for fold 4, epoch 308: 0.5558810159564018\n","Training loss for fold 4, epoch 308: 144.89849558184224\n","Validation elbo for fold 4, epoch 309: -20012.606890462364\n","Reconstruction accuracy for fold 4, epoch 309: 0.5561812222003937\n","Training loss for fold 4, epoch 309: 144.53491457047002\n","Validation elbo for fold 4, epoch 310: -20038.636930648732\n","Reconstruction accuracy for fold 4, epoch 310: 0.5561118014156818\n","Training loss for fold 4, epoch 310: 145.32881853657383\n","Validation elbo for fold 4, epoch 311: -20019.81061506423\n","Reconstruction accuracy for fold 4, epoch 311: 0.5535347424447536\n","Training loss for fold 4, epoch 311: 145.1369701508553\n","Validation elbo for fold 4, epoch 312: -20065.132201207878\n","Reconstruction accuracy for fold 4, epoch 312: 0.5541487224400043\n","Training loss for fold 4, epoch 312: 146.1465952473302\n","Validation elbo for fold 4, epoch 313: -20064.403827426224\n","Reconstruction accuracy for fold 4, epoch 313: 0.5523008443415165\n","Training loss for fold 4, epoch 313: 146.29360580444336\n","Validation elbo for fold 4, epoch 314: -20060.66729905332\n","Reconstruction accuracy for fold 4, epoch 314: 0.5503868460655212\n","Training loss for fold 4, epoch 314: 144.89445877075195\n","Validation elbo for fold 4, epoch 315: -20086.481281563276\n","Reconstruction accuracy for fold 4, epoch 315: 0.5559140667319298\n","Training loss for fold 4, epoch 315: 146.40492223924207\n","Validation elbo for fold 4, epoch 316: -20062.735414822204\n","Reconstruction accuracy for fold 4, epoch 316: 0.5558456145226955\n","Training loss for fold 4, epoch 316: 145.24383286506898\n","Validation elbo for fold 4, epoch 317: -20058.832831669308\n","Reconstruction accuracy for fold 4, epoch 317: 0.5564846284687519\n","Training loss for fold 4, epoch 317: 144.96154674406975\n","Validation elbo for fold 4, epoch 318: -20063.00415915582\n","Reconstruction accuracy for fold 4, epoch 318: 0.5567306280136108\n","Training loss for fold 4, epoch 318: 145.09313078849547\n","Validation elbo for fold 4, epoch 319: -20059.97798488817\n","Reconstruction accuracy for fold 4, epoch 319: 0.5564197711646557\n","Training loss for fold 4, epoch 319: 145.53815484816027\n","Validation elbo for fold 4, epoch 320: -20056.206478243643\n","Reconstruction accuracy for fold 4, epoch 320: 0.5575974024832249\n","Training loss for fold 4, epoch 320: 145.7962887671686\n","Validation elbo for fold 4, epoch 321: -20072.98557891574\n","Reconstruction accuracy for fold 4, epoch 321: 0.5550768785178661\n","Training loss for fold 4, epoch 321: 144.83519301875944\n","Validation elbo for fold 4, epoch 322: -20055.65556413588\n","Reconstruction accuracy for fold 4, epoch 322: 0.5554783307015896\n","Training loss for fold 4, epoch 322: 145.40615217147334\n","Validation elbo for fold 4, epoch 323: -20094.41645171106\n","Reconstruction accuracy for fold 4, epoch 323: 0.5550705268979073\n","Training loss for fold 4, epoch 323: 145.08201525288243\n","Validation elbo for fold 4, epoch 324: -20043.096947815946\n","Reconstruction accuracy for fold 4, epoch 324: 0.5547456964850426\n","Training loss for fold 4, epoch 324: 144.2519095636183\n","Validation elbo for fold 4, epoch 325: -20064.77240560203\n","Reconstruction accuracy for fold 4, epoch 325: 0.5571530796587467\n","Training loss for fold 4, epoch 325: 144.6375466623614\n","Validation elbo for fold 4, epoch 326: -20064.128449290383\n","Reconstruction accuracy for fold 4, epoch 326: 0.5559339821338654\n","Training loss for fold 4, epoch 326: 144.93340646066974\n","Validation elbo for fold 4, epoch 327: -20032.93605161273\n","Reconstruction accuracy for fold 4, epoch 327: 0.5541333742439747\n","Training loss for fold 4, epoch 327: 143.8926278391192\n","Validation elbo for fold 4, epoch 328: -20061.07148345183\n","Reconstruction accuracy for fold 4, epoch 328: 0.5562166310846806\n","Training loss for fold 4, epoch 328: 144.8894323533581\n","Validation elbo for fold 4, epoch 329: -20096.068055784894\n","Reconstruction accuracy for fold 4, epoch 329: 0.5570813193917274\n","Training loss for fold 4, epoch 329: 145.01836678289598\n","Validation elbo for fold 4, epoch 330: -20059.06703892406\n","Reconstruction accuracy for fold 4, epoch 330: 0.5542081855237484\n","Training loss for fold 4, epoch 330: 144.80599458755987\n","Validation elbo for fold 4, epoch 331: -20110.899949817343\n","Reconstruction accuracy for fold 4, epoch 331: 0.5542012751102448\n","Training loss for fold 4, epoch 331: 144.49856382800687\n","Validation elbo for fold 4, epoch 332: -20093.359589131465\n","Reconstruction accuracy for fold 4, epoch 332: 0.5547835901379585\n","Training loss for fold 4, epoch 332: 144.6772068392846\n","Validation elbo for fold 4, epoch 333: -20109.491667295548\n","Reconstruction accuracy for fold 4, epoch 333: 0.5527423731982708\n","Training loss for fold 4, epoch 333: 146.5511608739053\n","Validation elbo for fold 4, epoch 334: -20050.300526471263\n","Reconstruction accuracy for fold 4, epoch 334: 0.5546657741069794\n","Training loss for fold 4, epoch 334: 144.27034328829856\n","Validation elbo for fold 4, epoch 335: -20041.86952185419\n","Reconstruction accuracy for fold 4, epoch 335: 0.5550522692501545\n","Training loss for fold 4, epoch 335: 145.73905772547567\n","Validation elbo for fold 4, epoch 336: -20065.34271835192\n","Reconstruction accuracy for fold 4, epoch 336: 0.5532213933765888\n","Training loss for fold 4, epoch 336: 145.27518524662142\n","Validation elbo for fold 4, epoch 337: -20078.57065612208\n","Reconstruction accuracy for fold 4, epoch 337: 0.5538237653672695\n","Training loss for fold 4, epoch 337: 144.81323882072203\n","Validation elbo for fold 4, epoch 338: -20064.91787452845\n","Reconstruction accuracy for fold 4, epoch 338: 0.5564099438488483\n","Training loss for fold 4, epoch 338: 145.2380627047631\n","Validation elbo for fold 4, epoch 339: -20053.663693271483\n","Reconstruction accuracy for fold 4, epoch 339: 0.5514990650117397\n","Training loss for fold 4, epoch 339: 144.59782766526746\n","Validation elbo for fold 4, epoch 340: -20014.349923683953\n","Reconstruction accuracy for fold 4, epoch 340: 0.5544645637273788\n","Training loss for fold 4, epoch 340: 144.38477473105155\n","Validation elbo for fold 4, epoch 341: -20020.14434202508\n","Reconstruction accuracy for fold 4, epoch 341: 0.5548937991261482\n","Training loss for fold 4, epoch 341: 144.604371347735\n","Validation elbo for fold 4, epoch 342: -20046.39774499974\n","Reconstruction accuracy for fold 4, epoch 342: 0.5573233179748058\n","Training loss for fold 4, epoch 342: 144.24933082826675\n","Validation elbo for fold 4, epoch 343: -20040.757916045073\n","Reconstruction accuracy for fold 4, epoch 343: 0.5563768967986107\n","Training loss for fold 4, epoch 343: 145.01806948261876\n","Validation elbo for fold 4, epoch 344: -20071.457043976454\n","Reconstruction accuracy for fold 4, epoch 344: 0.5542601905763149\n","Training loss for fold 4, epoch 344: 145.6056602231918\n","Validation elbo for fold 4, epoch 345: -20059.649221786378\n","Reconstruction accuracy for fold 4, epoch 345: 0.5536361113190651\n","Training loss for fold 4, epoch 345: 144.54137740596647\n","Validation elbo for fold 4, epoch 346: -20048.062403867807\n","Reconstruction accuracy for fold 4, epoch 346: 0.5553798712790012\n","Training loss for fold 4, epoch 346: 144.47665602161038\n","Validation elbo for fold 4, epoch 347: -20025.86643791267\n","Reconstruction accuracy for fold 4, epoch 347: 0.5549950189888477\n","Training loss for fold 4, epoch 347: 144.28507355720765\n","Validation elbo for fold 4, epoch 348: -20052.949008438467\n","Reconstruction accuracy for fold 4, epoch 348: 0.5559695214033127\n","Training loss for fold 4, epoch 348: 144.11702137608683\n","Validation elbo for fold 4, epoch 349: -20047.883818327322\n","Reconstruction accuracy for fold 4, epoch 349: 0.5557468794286251\n","Training loss for fold 4, epoch 349: 144.10663813929403\n","Validation elbo for fold 4, epoch 350: -20044.83664548667\n","Reconstruction accuracy for fold 4, epoch 350: 0.5559074319899082\n","Training loss for fold 4, epoch 350: 143.80590328093498\n","Validation elbo for fold 4, epoch 351: -20055.618855190303\n","Reconstruction accuracy for fold 4, epoch 351: 0.5558317825198174\n","Training loss for fold 4, epoch 351: 143.87396510954827\n","Validation elbo for fold 4, epoch 352: -20033.606393059912\n","Reconstruction accuracy for fold 4, epoch 352: 0.5544362179934978\n","Training loss for fold 4, epoch 352: 143.59432958787488\n","Validation elbo for fold 4, epoch 353: -20046.36229843969\n","Reconstruction accuracy for fold 4, epoch 353: 0.5562224350869656\n","Training loss for fold 4, epoch 353: 143.07383014309792\n","Validation elbo for fold 4, epoch 354: -20092.34844533344\n","Reconstruction accuracy for fold 4, epoch 354: 0.5576807856559753\n","Training loss for fold 4, epoch 354: 143.68511113812846\n","Validation elbo for fold 4, epoch 355: -20025.07642446582\n","Reconstruction accuracy for fold 4, epoch 355: 0.555630024522543\n","Training loss for fold 4, epoch 355: 142.48370976601876\n","Validation elbo for fold 4, epoch 356: -20093.164613021247\n","Reconstruction accuracy for fold 4, epoch 356: 0.5561138801276684\n","Training loss for fold 4, epoch 356: 144.39520780501826\n","Validation elbo for fold 4, epoch 357: -20100.636779296226\n","Reconstruction accuracy for fold 4, epoch 357: 0.5556199289858341\n","Training loss for fold 4, epoch 357: 144.48921375889933\n","Validation elbo for fold 4, epoch 358: -20061.97339623353\n","Reconstruction accuracy for fold 4, epoch 358: 0.5547701790928841\n","Training loss for fold 4, epoch 358: 143.06239269625755\n","Validation elbo for fold 4, epoch 359: -20034.635292926767\n","Reconstruction accuracy for fold 4, epoch 359: 0.5573262199759483\n","Training loss for fold 4, epoch 359: 144.3053083112163\n","Validation elbo for fold 4, epoch 360: -20081.358917217316\n","Reconstruction accuracy for fold 4, epoch 360: 0.5528881214559078\n","Training loss for fold 4, epoch 360: 143.97450760872132\n","Validation elbo for fold 4, epoch 361: -20048.88128815422\n","Reconstruction accuracy for fold 4, epoch 361: 0.5568690523505211\n","Training loss for fold 4, epoch 361: 144.23424210086947\n","Validation elbo for fold 4, epoch 362: -20053.23215089315\n","Reconstruction accuracy for fold 4, epoch 362: 0.5546838901937008\n","Training loss for fold 4, epoch 362: 143.76733312299174\n","Validation elbo for fold 4, epoch 363: -20085.754677746438\n","Reconstruction accuracy for fold 4, epoch 363: 0.5524721704423428\n","Training loss for fold 4, epoch 363: 143.446223966537\n","Validation elbo for fold 4, epoch 364: -20057.63304950084\n","Reconstruction accuracy for fold 4, epoch 364: 0.5555813610553741\n","Training loss for fold 4, epoch 364: 144.34833981913906\n","Validation elbo for fold 4, epoch 365: -20013.97634513052\n","Reconstruction accuracy for fold 4, epoch 365: 0.5550725981593132\n","Training loss for fold 4, epoch 365: 143.77623502669795\n","Validation elbo for fold 4, epoch 366: -20043.864673352513\n","Reconstruction accuracy for fold 4, epoch 366: 0.555535301566124\n","Training loss for fold 4, epoch 366: 143.56054047615297\n","Validation elbo for fold 4, epoch 367: -20045.045240799445\n","Reconstruction accuracy for fold 4, epoch 367: 0.555524930357933\n","Training loss for fold 4, epoch 367: 143.71310658608712\n","Validation elbo for fold 4, epoch 368: -20035.783584829675\n","Reconstruction accuracy for fold 4, epoch 368: 0.5548687763512135\n","Training loss for fold 4, epoch 368: 143.19146113241874\n","Validation elbo for fold 4, epoch 369: -20018.113259305428\n","Reconstruction accuracy for fold 4, epoch 369: 0.5554772242903709\n","Training loss for fold 4, epoch 369: 143.67968405446697\n","Validation elbo for fold 4, epoch 370: -20032.52293712439\n","Reconstruction accuracy for fold 4, epoch 370: 0.5567408613860607\n","Training loss for fold 4, epoch 370: 143.4757199441233\n","Validation elbo for fold 4, epoch 371: -20088.62528396556\n","Reconstruction accuracy for fold 4, epoch 371: 0.5544608347117901\n","Training loss for fold 4, epoch 371: 143.87811574628276\n","Validation elbo for fold 4, epoch 372: -20136.311169968707\n","Reconstruction accuracy for fold 4, epoch 372: 0.5531958155333996\n","Training loss for fold 4, epoch 372: 143.98341997208135\n","Validation elbo for fold 4, epoch 373: -20065.327533803793\n","Reconstruction accuracy for fold 4, epoch 373: 0.5552047975361347\n","Training loss for fold 4, epoch 373: 143.74058138939643\n","Validation elbo for fold 4, epoch 374: -20076.29481263754\n","Reconstruction accuracy for fold 4, epoch 374: 0.5548158138990402\n","Training loss for fold 4, epoch 374: 143.6774624240014\n","Validation elbo for fold 4, epoch 375: -20052.35028601184\n","Reconstruction accuracy for fold 4, epoch 375: 0.553046464920044\n","Training loss for fold 4, epoch 375: 143.90447382773124\n","Validation elbo for fold 4, epoch 376: -20030.851516104223\n","Reconstruction accuracy for fold 4, epoch 376: 0.5569977909326553\n","Training loss for fold 4, epoch 376: 143.31083962225145\n","Validation elbo for fold 4, epoch 377: -20060.065725263652\n","Reconstruction accuracy for fold 4, epoch 377: 0.5552879013121128\n","Training loss for fold 4, epoch 377: 143.1993763831354\n","Validation elbo for fold 4, epoch 378: -20073.707849951115\n","Reconstruction accuracy for fold 4, epoch 378: 0.5582552216947079\n","Training loss for fold 4, epoch 378: 143.1855936358052\n","Validation elbo for fold 4, epoch 379: -20056.918516408135\n","Reconstruction accuracy for fold 4, epoch 379: 0.556719284504652\n","Training loss for fold 4, epoch 379: 142.9462873397335\n","Validation elbo for fold 4, epoch 380: -20070.30930148444\n","Reconstruction accuracy for fold 4, epoch 380: 0.5562399961054325\n","Training loss for fold 4, epoch 380: 143.95296650548136\n","Validation elbo for fold 4, epoch 381: -20055.980414008605\n","Reconstruction accuracy for fold 4, epoch 381: 0.5564987324178219\n","Training loss for fold 4, epoch 381: 143.88543553506173\n","Validation elbo for fold 4, epoch 382: -20089.818773599698\n","Reconstruction accuracy for fold 4, epoch 382: 0.5533780679106712\n","Training loss for fold 4, epoch 382: 144.43875245125062\n","Validation elbo for fold 4, epoch 383: -20120.70320517772\n","Reconstruction accuracy for fold 4, epoch 383: 0.5564174205064774\n","Training loss for fold 4, epoch 383: 144.53788991128243\n","Validation elbo for fold 4, epoch 384: -20093.75461768174\n","Reconstruction accuracy for fold 4, epoch 384: 0.5556213185191154\n","Training loss for fold 4, epoch 384: 143.18279930853075\n","Validation elbo for fold 4, epoch 385: -20040.0670866636\n","Reconstruction accuracy for fold 4, epoch 385: 0.557243250310421\n","Training loss for fold 4, epoch 385: 143.14991341867756\n","Validation elbo for fold 4, epoch 386: -20080.25094589955\n","Reconstruction accuracy for fold 4, epoch 386: 0.5558197535574436\n","Training loss for fold 4, epoch 386: 142.57269557829827\n","Validation elbo for fold 4, epoch 387: -20015.945119676944\n","Reconstruction accuracy for fold 4, epoch 387: 0.5590936355292797\n","Training loss for fold 4, epoch 387: 143.4357632052514\n","Validation elbo for fold 4, epoch 388: -20084.199042351494\n","Reconstruction accuracy for fold 4, epoch 388: 0.5540985316038132\n","Training loss for fold 4, epoch 388: 142.8906608089324\n","Validation elbo for fold 4, epoch 389: -20066.833047748696\n","Reconstruction accuracy for fold 4, epoch 389: 0.5544269569218159\n","Training loss for fold 4, epoch 389: 143.60612696986044\n","Validation elbo for fold 4, epoch 390: -20025.82689493472\n","Reconstruction accuracy for fold 4, epoch 390: 0.5564580745995045\n","Training loss for fold 4, epoch 390: 142.69465686428933\n","Validation elbo for fold 4, epoch 391: -20007.288838391316\n","Reconstruction accuracy for fold 4, epoch 391: 0.5577873885631561\n","Training loss for fold 4, epoch 391: 142.57271132930632\n","Validation elbo for fold 4, epoch 392: -20099.147817957168\n","Reconstruction accuracy for fold 4, epoch 392: 0.5544721707701683\n","Training loss for fold 4, epoch 392: 143.46920604090536\n","Validation elbo for fold 4, epoch 393: -20036.16403853636\n","Reconstruction accuracy for fold 4, epoch 393: 0.5557908527553082\n","Training loss for fold 4, epoch 393: 143.05382820867723\n","Validation elbo for fold 4, epoch 394: -20110.837562336885\n","Reconstruction accuracy for fold 4, epoch 394: 0.5549740046262741\n","Training loss for fold 4, epoch 394: 142.90947563417495\n","Validation elbo for fold 4, epoch 395: -20045.384192274225\n","Reconstruction accuracy for fold 4, epoch 395: 0.5556117706000805\n","Training loss for fold 4, epoch 395: 143.38234206168883\n","Validation elbo for fold 4, epoch 396: -20047.578612199337\n","Reconstruction accuracy for fold 4, epoch 396: 0.5543438419699669\n","Training loss for fold 4, epoch 396: 142.480349879111\n","Validation elbo for fold 4, epoch 397: -20127.03945388712\n","Reconstruction accuracy for fold 4, epoch 397: 0.5535958632826805\n","Training loss for fold 4, epoch 397: 142.8348247158912\n","Validation elbo for fold 4, epoch 398: -20058.54269304064\n","Reconstruction accuracy for fold 4, epoch 398: 0.555908802896738\n","Training loss for fold 4, epoch 398: 142.76936377248455\n","Validation elbo for fold 4, epoch 399: -20078.7954843302\n","Reconstruction accuracy for fold 4, epoch 399: 0.5545418597757816\n","Training loss for fold 4, epoch 399: 144.24366858697707\n","Validation elbo for fold 4, epoch 400: -20051.861280095283\n","Reconstruction accuracy for fold 4, epoch 400: 0.5570125915110111\n","Training loss for fold 4, epoch 400: 144.11742671843498\n","Validation elbo for fold 4, epoch 401: -20075.68916901498\n","Reconstruction accuracy for fold 4, epoch 401: 0.5537380203604698\n","Training loss for fold 4, epoch 401: 144.15491190264302\n","Validation elbo for fold 4, epoch 402: -20023.38059294223\n","Reconstruction accuracy for fold 4, epoch 402: 0.5554148554801941\n","Training loss for fold 4, epoch 402: 144.0872541858304\n","Validation elbo for fold 4, epoch 403: -20045.41775607944\n","Reconstruction accuracy for fold 4, epoch 403: 0.5571497678756714\n","Training loss for fold 4, epoch 403: 143.30734289846112\n","Validation elbo for fold 4, epoch 404: -20051.051390059725\n","Reconstruction accuracy for fold 4, epoch 404: 0.5545397996902466\n","Training loss for fold 4, epoch 404: 143.3790860329905\n","Validation elbo for fold 4, epoch 405: -20115.471082013624\n","Reconstruction accuracy for fold 4, epoch 405: 0.5537996962666512\n","Training loss for fold 4, epoch 405: 143.2242336888467\n","Validation elbo for fold 4, epoch 406: -20034.143342811425\n","Reconstruction accuracy for fold 4, epoch 406: 0.5575384870171547\n","Training loss for fold 4, epoch 406: 142.58503513951456\n","Validation elbo for fold 4, epoch 407: -20047.313709961483\n","Reconstruction accuracy for fold 4, epoch 407: 0.5556249059736729\n","Training loss for fold 4, epoch 407: 143.16057328254945\n","Validation elbo for fold 4, epoch 408: -20014.920493005393\n","Reconstruction accuracy for fold 4, epoch 408: 0.5563338883221149\n","Training loss for fold 4, epoch 408: 143.45760320848035\n","Validation elbo for fold 4, epoch 409: -20053.704788416147\n","Reconstruction accuracy for fold 4, epoch 409: 0.5554513707756996\n","Training loss for fold 4, epoch 409: 143.44368054789882\n","Validation elbo for fold 4, epoch 410: -20054.416750461074\n","Reconstruction accuracy for fold 4, epoch 410: 0.555939506739378\n","Training loss for fold 4, epoch 410: 142.17434692382812\n","Validation elbo for fold 4, epoch 411: -20040.49466791801\n","Reconstruction accuracy for fold 4, epoch 411: 0.5560325719416142\n","Training loss for fold 4, epoch 411: 143.11290408718972\n","Validation elbo for fold 4, epoch 412: -20101.17219355114\n","Reconstruction accuracy for fold 4, epoch 412: 0.5526096150279045\n","Training loss for fold 4, epoch 412: 143.13648014683878\n","Validation elbo for fold 4, epoch 413: -20055.687574806063\n","Reconstruction accuracy for fold 4, epoch 413: 0.5552164204418659\n","Training loss for fold 4, epoch 413: 142.71124292189074\n","Validation elbo for fold 4, epoch 414: -20082.302394964856\n","Reconstruction accuracy for fold 4, epoch 414: 0.5573296770453453\n","Training loss for fold 4, epoch 414: 143.1310219303254\n","Validation elbo for fold 4, epoch 415: -20049.66152199066\n","Reconstruction accuracy for fold 4, epoch 415: 0.5589198097586632\n","Training loss for fold 4, epoch 415: 142.90644725676506\n","Validation elbo for fold 4, epoch 416: -20068.759764029022\n","Reconstruction accuracy for fold 4, epoch 416: 0.5575849525630474\n","Training loss for fold 4, epoch 416: 142.18003020748014\n","Validation elbo for fold 4, epoch 417: -20043.910096873653\n","Reconstruction accuracy for fold 4, epoch 417: 0.5577819980680943\n","Training loss for fold 4, epoch 417: 143.2042694091797\n","Validation elbo for fold 4, epoch 418: -20063.483346024106\n","Reconstruction accuracy for fold 4, epoch 418: 0.5578038617968559\n","Training loss for fold 4, epoch 418: 142.18210589501166\n","Validation elbo for fold 4, epoch 419: -20028.822559140477\n","Reconstruction accuracy for fold 4, epoch 419: 0.5573376975953579\n","Training loss for fold 4, epoch 419: 143.50249161258822\n","Validation elbo for fold 4, epoch 420: -20069.58915435173\n","Reconstruction accuracy for fold 4, epoch 420: 0.5563355498015881\n","Training loss for fold 4, epoch 420: 143.08602240777785\n","Validation elbo for fold 4, epoch 421: -20088.34797200134\n","Reconstruction accuracy for fold 4, epoch 421: 0.5557387135922909\n","Training loss for fold 4, epoch 421: 143.2679711618731\n","Validation elbo for fold 4, epoch 422: -20015.12141844717\n","Reconstruction accuracy for fold 4, epoch 422: 0.5552559681236744\n","Training loss for fold 4, epoch 422: 143.13397733626826\n","Validation elbo for fold 4, epoch 423: -20056.919936186983\n","Reconstruction accuracy for fold 4, epoch 423: 0.5560018718242645\n","Training loss for fold 4, epoch 423: 142.69751333421277\n","Validation elbo for fold 4, epoch 424: -20044.747031644634\n","Reconstruction accuracy for fold 4, epoch 424: 0.5573047809302807\n","Training loss for fold 4, epoch 424: 143.08778012183404\n","Validation elbo for fold 4, epoch 425: -20078.253185096615\n","Reconstruction accuracy for fold 4, epoch 425: 0.5542280972003937\n","Training loss for fold 4, epoch 425: 142.77356363111926\n","Validation elbo for fold 4, epoch 426: -20026.410461108866\n","Reconstruction accuracy for fold 4, epoch 426: 0.5563329234719276\n","Training loss for fold 4, epoch 426: 142.11469071911228\n","Validation elbo for fold 4, epoch 427: -20064.74148665015\n","Reconstruction accuracy for fold 4, epoch 427: 0.555353183299303\n","Training loss for fold 4, epoch 427: 141.90473285798103\n","Validation elbo for fold 4, epoch 428: -20044.956955840236\n","Reconstruction accuracy for fold 4, epoch 428: 0.5570674873888493\n","Training loss for fold 4, epoch 428: 142.9712279535109\n","Validation elbo for fold 4, epoch 429: -20078.995736137935\n","Reconstruction accuracy for fold 4, epoch 429: 0.5557755045592785\n","Training loss for fold 4, epoch 429: 142.38201153662897\n","Validation elbo for fold 4, epoch 430: -20021.997148992457\n","Reconstruction accuracy for fold 4, epoch 430: 0.5587694942951202\n","Training loss for fold 4, epoch 430: 142.44732370684224\n","Validation elbo for fold 4, epoch 431: -20058.89588830416\n","Reconstruction accuracy for fold 4, epoch 431: 0.5569814741611481\n","Training loss for fold 4, epoch 431: 142.67310370168377\n","Validation elbo for fold 4, epoch 432: -20029.838196840734\n","Reconstruction accuracy for fold 4, epoch 432: 0.5568156763911247\n","Training loss for fold 4, epoch 432: 142.440245720648\n","Validation elbo for fold 4, epoch 433: -20117.515958304044\n","Reconstruction accuracy for fold 4, epoch 433: 0.5544719025492668\n","Training loss for fold 4, epoch 433: 142.68696914180632\n","Validation elbo for fold 4, epoch 434: -20092.143645771266\n","Reconstruction accuracy for fold 4, epoch 434: 0.5551947057247162\n","Training loss for fold 4, epoch 434: 142.5255589638987\n","Validation elbo for fold 4, epoch 435: -20054.209147803074\n","Reconstruction accuracy for fold 4, epoch 435: 0.5562480241060257\n","Training loss for fold 4, epoch 435: 142.2714895432995\n","Validation elbo for fold 4, epoch 436: -20152.283141197237\n","Reconstruction accuracy for fold 4, epoch 436: 0.5543601512908936\n","Training loss for fold 4, epoch 436: 144.97439353696763\n","Validation elbo for fold 4, epoch 437: -20045.914025082173\n","Reconstruction accuracy for fold 4, epoch 437: 0.5564995594322681\n","Training loss for fold 4, epoch 437: 143.55407370290447\n","Validation elbo for fold 4, epoch 438: -20058.688447246677\n","Reconstruction accuracy for fold 4, epoch 438: 0.5553050488233566\n","Training loss for fold 4, epoch 438: 143.1052865059145\n","Validation elbo for fold 4, epoch 439: -20099.314416071218\n","Reconstruction accuracy for fold 4, epoch 439: 0.5530561432242393\n","Training loss for fold 4, epoch 439: 143.21976938555318\n","Validation elbo for fold 4, epoch 440: -20070.09475692591\n","Reconstruction accuracy for fold 4, epoch 440: 0.5552122630178928\n","Training loss for fold 4, epoch 440: 142.68513771795458\n","Validation elbo for fold 4, epoch 441: -20012.778320820253\n","Reconstruction accuracy for fold 4, epoch 441: 0.5572410337626934\n","Training loss for fold 4, epoch 441: 142.8727072438886\n","Validation elbo for fold 4, epoch 442: -20038.071071955877\n","Reconstruction accuracy for fold 4, epoch 442: 0.556597176939249\n","Training loss for fold 4, epoch 442: 141.21731604299237\n","Validation elbo for fold 4, epoch 443: -20067.86190750061\n","Reconstruction accuracy for fold 4, epoch 443: 0.5546065866947174\n","Training loss for fold 4, epoch 443: 142.2564779712308\n","Validation elbo for fold 4, epoch 444: -20095.65850837394\n","Reconstruction accuracy for fold 4, epoch 444: 0.5552986972033978\n","Training loss for fold 4, epoch 444: 141.7119978627851\n","Validation elbo for fold 4, epoch 445: -20030.61031043777\n","Reconstruction accuracy for fold 4, epoch 445: 0.5599996671080589\n","Training loss for fold 4, epoch 445: 143.31023456204323\n","Validation elbo for fold 4, epoch 446: -20029.569527420826\n","Reconstruction accuracy for fold 4, epoch 446: 0.5564381629228592\n","Training loss for fold 4, epoch 446: 142.6130152056294\n","Validation elbo for fold 4, epoch 447: -20095.226394006288\n","Reconstruction accuracy for fold 4, epoch 447: 0.5553249791264534\n","Training loss for fold 4, epoch 447: 142.48380857898343\n","Validation elbo for fold 4, epoch 448: -20042.91003862921\n","Reconstruction accuracy for fold 4, epoch 448: 0.5567686595022678\n","Training loss for fold 4, epoch 448: 142.0106432514806\n","Validation elbo for fold 4, epoch 449: -20075.446118409942\n","Reconstruction accuracy for fold 4, epoch 449: 0.5541198272258043\n","Training loss for fold 4, epoch 449: 142.27407332389586\n","Validation elbo for fold 4, epoch 450: -20012.714088369383\n","Reconstruction accuracy for fold 4, epoch 450: 0.558581281453371\n","Training loss for fold 4, epoch 450: 141.5924062421245\n","Validation elbo for fold 4, epoch 451: -20051.533371518446\n","Reconstruction accuracy for fold 4, epoch 451: 0.5592704899609089\n","Training loss for fold 4, epoch 451: 142.12995012344854\n","Validation elbo for fold 4, epoch 452: -20052.83214155792\n","Reconstruction accuracy for fold 4, epoch 452: 0.5569499507546425\n","Training loss for fold 4, epoch 452: 141.9965109056042\n","Validation elbo for fold 4, epoch 453: -20040.348501490127\n","Reconstruction accuracy for fold 4, epoch 453: 0.5567244030535221\n","Training loss for fold 4, epoch 453: 141.68238018405052\n","Validation elbo for fold 4, epoch 454: -20052.4162313871\n","Reconstruction accuracy for fold 4, epoch 454: 0.5549814775586128\n","Training loss for fold 4, epoch 454: 142.76484421760804\n","Validation elbo for fold 4, epoch 455: -20038.7121676312\n","Reconstruction accuracy for fold 4, epoch 455: 0.5578494854271412\n","Training loss for fold 4, epoch 455: 142.61408172115202\n","Validation elbo for fold 4, epoch 456: -20040.62647313885\n","Reconstruction accuracy for fold 4, epoch 456: 0.556589163839817\n","Training loss for fold 4, epoch 456: 142.3755869711599\n","Validation elbo for fold 4, epoch 457: -20035.90810181664\n","Reconstruction accuracy for fold 4, epoch 457: 0.5565841905772686\n","Training loss for fold 4, epoch 457: 142.2527710699266\n","Validation elbo for fold 4, epoch 458: -20025.29102805483\n","Reconstruction accuracy for fold 4, epoch 458: 0.556506335735321\n","Training loss for fold 4, epoch 458: 142.14641435684698\n","Validation elbo for fold 4, epoch 459: -20070.198250121946\n","Reconstruction accuracy for fold 4, epoch 459: 0.5587372668087482\n","Training loss for fold 4, epoch 459: 141.9199382412818\n","Validation elbo for fold 4, epoch 460: -20108.668097565496\n","Reconstruction accuracy for fold 4, epoch 460: 0.5562231279909611\n","Training loss for fold 4, epoch 460: 142.23075583673292\n","Validation elbo for fold 4, epoch 461: -20064.534878369523\n","Reconstruction accuracy for fold 4, epoch 461: 0.556735459715128\n","Training loss for fold 4, epoch 461: 141.98688507080078\n","Validation elbo for fold 4, epoch 462: -20013.613014625076\n","Reconstruction accuracy for fold 4, epoch 462: 0.5556430220603943\n","Training loss for fold 4, epoch 462: 142.1863555908203\n","Validation elbo for fold 4, epoch 463: -20038.26811942199\n","Reconstruction accuracy for fold 4, epoch 463: 0.5586259476840496\n","Training loss for fold 4, epoch 463: 141.70778520645635\n","Validation elbo for fold 4, epoch 464: -20034.905242843368\n","Reconstruction accuracy for fold 4, epoch 464: 0.5561419576406479\n","Training loss for fold 4, epoch 464: 141.93564101188414\n","Validation elbo for fold 4, epoch 465: -20061.038167861072\n","Reconstruction accuracy for fold 4, epoch 465: 0.555399090051651\n","Training loss for fold 4, epoch 465: 143.74400231146043\n","Validation elbo for fold 4, epoch 466: -20091.79637248833\n","Reconstruction accuracy for fold 4, epoch 466: 0.5566972978413105\n","Training loss for fold 4, epoch 466: 142.54864157399822\n","Validation elbo for fold 4, epoch 467: -20047.76810679936\n","Reconstruction accuracy for fold 4, epoch 467: 0.5577742606401443\n","Training loss for fold 4, epoch 467: 142.06569056357108\n","Validation elbo for fold 4, epoch 468: -20144.938875239648\n","Reconstruction accuracy for fold 4, epoch 468: 0.5542799532413483\n","Training loss for fold 4, epoch 468: 143.03186416625977\n","Validation elbo for fold 4, epoch 469: -20093.56004747381\n","Reconstruction accuracy for fold 4, epoch 469: 0.5565881952643394\n","Training loss for fold 4, epoch 469: 142.69180347073464\n","Validation elbo for fold 4, epoch 470: -20091.00487949855\n","Reconstruction accuracy for fold 4, epoch 470: 0.5549099780619144\n","Training loss for fold 4, epoch 470: 141.0165386815225\n","Validation elbo for fold 4, epoch 471: -20027.09027789071\n","Reconstruction accuracy for fold 4, epoch 471: 0.5587646551430225\n","Training loss for fold 4, epoch 471: 141.81901451849168\n","Validation elbo for fold 4, epoch 472: -20020.24253348035\n","Reconstruction accuracy for fold 4, epoch 472: 0.5581308975815773\n","Training loss for fold 4, epoch 472: 141.75028893255418\n","Validation elbo for fold 4, epoch 473: -20040.827892495756\n","Reconstruction accuracy for fold 4, epoch 473: 0.5560769625008106\n","Training loss for fold 4, epoch 473: 141.7976790397398\n","Validation elbo for fold 4, epoch 474: -20114.008545060165\n","Reconstruction accuracy for fold 4, epoch 474: 0.5541537068784237\n","Training loss for fold 4, epoch 474: 142.03468298142957\n","Validation elbo for fold 4, epoch 475: -20077.488848808858\n","Reconstruction accuracy for fold 4, epoch 475: 0.5597254410386086\n","Training loss for fold 4, epoch 475: 142.14676493983114\n","Validation elbo for fold 4, epoch 476: -20033.52331364646\n","Reconstruction accuracy for fold 4, epoch 476: 0.5576065219938755\n","Training loss for fold 4, epoch 476: 142.99530004685926\n","Validation elbo for fold 4, epoch 477: -20007.500757830014\n","Reconstruction accuracy for fold 4, epoch 477: 0.5575117915868759\n","Training loss for fold 4, epoch 477: 143.64144454463835\n","Validation elbo for fold 4, epoch 478: -20062.113900386517\n","Reconstruction accuracy for fold 4, epoch 478: 0.5546876154839993\n","Training loss for fold 4, epoch 478: 142.63503991403888\n","Validation elbo for fold 4, epoch 479: -20073.77944265677\n","Reconstruction accuracy for fold 4, epoch 479: 0.554182467982173\n","Training loss for fold 4, epoch 479: 142.1203157978673\n","Validation elbo for fold 4, epoch 480: -20029.657336480275\n","Reconstruction accuracy for fold 4, epoch 480: 0.5578124225139618\n","Training loss for fold 4, epoch 480: 142.21530126756238\n","Validation elbo for fold 4, epoch 481: -20041.885454161406\n","Reconstruction accuracy for fold 4, epoch 481: 0.5559780858457088\n","Training loss for fold 4, epoch 481: 141.3440647740518\n","Validation elbo for fold 4, epoch 482: -20033.054032902506\n","Reconstruction accuracy for fold 4, epoch 482: 0.5561891086399555\n","Training loss for fold 4, epoch 482: 142.09787516440116\n","Validation elbo for fold 4, epoch 483: -20045.647240528906\n","Reconstruction accuracy for fold 4, epoch 483: 0.5555371008813381\n","Training loss for fold 4, epoch 483: 141.79932022094727\n","Validation elbo for fold 4, epoch 484: -20021.472091432057\n","Reconstruction accuracy for fold 4, epoch 484: 0.5554481744766235\n","Training loss for fold 4, epoch 484: 141.1097926478232\n","Validation elbo for fold 4, epoch 485: -20032.47982295762\n","Reconstruction accuracy for fold 4, epoch 485: 0.5550919696688652\n","Training loss for fold 4, epoch 485: 141.8290881495322\n","Validation elbo for fold 4, epoch 486: -20029.3257521006\n","Reconstruction accuracy for fold 4, epoch 486: 0.5576794035732746\n","Training loss for fold 4, epoch 486: 141.41151932747132\n","Validation elbo for fold 4, epoch 487: -20047.147573735234\n","Reconstruction accuracy for fold 4, epoch 487: 0.5574260577559471\n","Training loss for fold 4, epoch 487: 142.17824209890057\n","Validation elbo for fold 4, epoch 488: -20027.616585003427\n","Reconstruction accuracy for fold 4, epoch 488: 0.5582000352442265\n","Training loss for fold 4, epoch 488: 141.5300571072486\n","Validation elbo for fold 4, epoch 489: -20074.835562544336\n","Reconstruction accuracy for fold 4, epoch 489: 0.5550936162471771\n","Training loss for fold 4, epoch 489: 142.34985794559603\n","Validation elbo for fold 4, epoch 490: -20072.090015512636\n","Reconstruction accuracy for fold 4, epoch 490: 0.5555669590830803\n","Training loss for fold 4, epoch 490: 142.23400891211725\n","Validation elbo for fold 4, epoch 491: -20073.85688476981\n","Reconstruction accuracy for fold 4, epoch 491: 0.554665632545948\n","Training loss for fold 4, epoch 491: 141.94312089489353\n","Validation elbo for fold 4, epoch 492: -20093.8474122988\n","Reconstruction accuracy for fold 4, epoch 492: 0.5544673316180706\n","Training loss for fold 4, epoch 492: 142.22275075604838\n","Validation elbo for fold 4, epoch 493: -20054.052177915575\n","Reconstruction accuracy for fold 4, epoch 493: 0.5562297627329826\n","Training loss for fold 4, epoch 493: 140.87654101464057\n","Validation elbo for fold 4, epoch 494: -20040.541297710148\n","Reconstruction accuracy for fold 4, epoch 494: 0.5577885024249554\n","Training loss for fold 4, epoch 494: 141.9182718338505\n","Validation elbo for fold 4, epoch 495: -20080.115651251803\n","Reconstruction accuracy for fold 4, epoch 495: 0.5559726990759373\n","Training loss for fold 4, epoch 495: 142.20017390097343\n","Validation elbo for fold 4, epoch 496: -20036.60022523249\n","Reconstruction accuracy for fold 4, epoch 496: 0.5570737160742283\n","Training loss for fold 4, epoch 496: 142.14392520535378\n","Validation elbo for fold 4, epoch 497: -20103.019386285705\n","Reconstruction accuracy for fold 4, epoch 497: 0.5587629862129688\n","Training loss for fold 4, epoch 497: 141.5809460301553\n","Validation elbo for fold 4, epoch 498: -20014.024164903174\n","Reconstruction accuracy for fold 4, epoch 498: 0.5582314282655716\n","Training loss for fold 4, epoch 498: 141.26234300674932\n","Validation elbo for fold 4, epoch 499: -20012.655515496448\n","Reconstruction accuracy for fold 4, epoch 499: 0.558750543743372\n","Training loss for fold 4, epoch 499: 140.825988400367\n","Fold 5\n","-------\n","Validation elbo for fold 5, epoch 0: -39724.82083315482\n","Reconstruction accuracy for fold 5, epoch 0: 0.05205719522200525\n","Training loss for fold 5, epoch 0: 239.65496776949973\n","Validation elbo for fold 5, epoch 1: -26512.87142308682\n","Reconstruction accuracy for fold 5, epoch 1: 0.3722692932933569\n","Training loss for fold 5, epoch 1: 225.650270277454\n","Validation elbo for fold 5, epoch 2: -26506.295816270125\n","Reconstruction accuracy for fold 5, epoch 2: 0.3726650606840849\n","Training loss for fold 5, epoch 2: 225.1881827077558\n","Validation elbo for fold 5, epoch 3: -26437.136901660822\n","Reconstruction accuracy for fold 5, epoch 3: 0.37306747026741505\n","Training loss for fold 5, epoch 3: 224.14472321541078\n","Validation elbo for fold 5, epoch 4: -25874.009192295147\n","Reconstruction accuracy for fold 5, epoch 4: 0.3868842665106058\n","Training loss for fold 5, epoch 4: 221.50984684113533\n","Validation elbo for fold 5, epoch 5: -25738.660422150748\n","Reconstruction accuracy for fold 5, epoch 5: 0.38568768836557865\n","Training loss for fold 5, epoch 5: 221.12101450274068\n","Validation elbo for fold 5, epoch 6: -25689.877578566924\n","Reconstruction accuracy for fold 5, epoch 6: 0.382864760234952\n","Training loss for fold 5, epoch 6: 220.46478714481478\n","Validation elbo for fold 5, epoch 7: -25631.90633618468\n","Reconstruction accuracy for fold 5, epoch 7: 0.38279036059975624\n","Training loss for fold 5, epoch 7: 218.77524837370842\n","Validation elbo for fold 5, epoch 8: -25458.790499715054\n","Reconstruction accuracy for fold 5, epoch 8: 0.3817244693636894\n","Training loss for fold 5, epoch 8: 217.70625600507182\n","Validation elbo for fold 5, epoch 9: -25317.177023016957\n","Reconstruction accuracy for fold 5, epoch 9: 0.38099460676312447\n","Training loss for fold 5, epoch 9: 216.4812311972341\n","Validation elbo for fold 5, epoch 10: -25118.3707287909\n","Reconstruction accuracy for fold 5, epoch 10: 0.39242143742740154\n","Training loss for fold 5, epoch 10: 214.23985856579196\n","Validation elbo for fold 5, epoch 11: -24831.111251232043\n","Reconstruction accuracy for fold 5, epoch 11: 0.3943054210394621\n","Training loss for fold 5, epoch 11: 212.70697735201927\n","Validation elbo for fold 5, epoch 12: -24622.034426541424\n","Reconstruction accuracy for fold 5, epoch 12: 0.4044818878173828\n","Training loss for fold 5, epoch 12: 211.41578969647807\n","Validation elbo for fold 5, epoch 13: -24440.492216428567\n","Reconstruction accuracy for fold 5, epoch 13: 0.40960102528333664\n","Training loss for fold 5, epoch 13: 209.967410425986\n","Validation elbo for fold 5, epoch 14: -24260.322980567755\n","Reconstruction accuracy for fold 5, epoch 14: 0.41679511964321136\n","Training loss for fold 5, epoch 14: 208.51890170189643\n","Validation elbo for fold 5, epoch 15: -24076.507211062155\n","Reconstruction accuracy for fold 5, epoch 15: 0.42185175605118275\n","Training loss for fold 5, epoch 15: 206.38780581566596\n","Validation elbo for fold 5, epoch 16: -23838.759567518224\n","Reconstruction accuracy for fold 5, epoch 16: 0.4296536073088646\n","Training loss for fold 5, epoch 16: 204.8146251555412\n","Validation elbo for fold 5, epoch 17: -23645.96016981049\n","Reconstruction accuracy for fold 5, epoch 17: 0.43570173904299736\n","Training loss for fold 5, epoch 17: 203.0060328821982\n","Validation elbo for fold 5, epoch 18: -23433.011484744384\n","Reconstruction accuracy for fold 5, epoch 18: 0.44370244443416595\n","Training loss for fold 5, epoch 18: 201.03207471293788\n","Validation elbo for fold 5, epoch 19: -23245.40146576956\n","Reconstruction accuracy for fold 5, epoch 19: 0.4506448581814766\n","Training loss for fold 5, epoch 19: 199.73655454574092\n","Validation elbo for fold 5, epoch 20: -23149.259030785943\n","Reconstruction accuracy for fold 5, epoch 20: 0.4520639330148697\n","Training loss for fold 5, epoch 20: 198.57655236028856\n","Validation elbo for fold 5, epoch 21: -22968.27370237113\n","Reconstruction accuracy for fold 5, epoch 21: 0.46208773367106915\n","Training loss for fold 5, epoch 21: 197.01231138167842\n","Validation elbo for fold 5, epoch 22: -22830.40910998728\n","Reconstruction accuracy for fold 5, epoch 22: 0.46507453359663486\n","Training loss for fold 5, epoch 22: 196.08099463678175\n","Validation elbo for fold 5, epoch 23: -22695.342756875296\n","Reconstruction accuracy for fold 5, epoch 23: 0.4699664730578661\n","Training loss for fold 5, epoch 23: 194.64454823155558\n","Validation elbo for fold 5, epoch 24: -22565.618693582623\n","Reconstruction accuracy for fold 5, epoch 24: 0.4700186047703028\n","Training loss for fold 5, epoch 24: 193.35428053332913\n","Validation elbo for fold 5, epoch 25: -22467.82073534598\n","Reconstruction accuracy for fold 5, epoch 25: 0.47443194314837456\n","Training loss for fold 5, epoch 25: 192.41094699982673\n","Validation elbo for fold 5, epoch 26: -22363.941955760944\n","Reconstruction accuracy for fold 5, epoch 26: 0.47831772454082966\n","Training loss for fold 5, epoch 26: 191.63347896452873\n","Validation elbo for fold 5, epoch 27: -22313.7435926112\n","Reconstruction accuracy for fold 5, epoch 27: 0.4771248884499073\n","Training loss for fold 5, epoch 27: 191.0380603421119\n","Validation elbo for fold 5, epoch 28: -22212.736656106612\n","Reconstruction accuracy for fold 5, epoch 28: 0.4840563777834177\n","Training loss for fold 5, epoch 28: 190.86566605106478\n","Validation elbo for fold 5, epoch 29: -22111.783089223576\n","Reconstruction accuracy for fold 5, epoch 29: 0.4865667913109064\n","Training loss for fold 5, epoch 29: 189.19954016900832\n","Validation elbo for fold 5, epoch 30: -22054.01360427838\n","Reconstruction accuracy for fold 5, epoch 30: 0.4895324297249317\n","Training loss for fold 5, epoch 30: 189.2270766227476\n","Validation elbo for fold 5, epoch 31: -21948.13384519877\n","Reconstruction accuracy for fold 5, epoch 31: 0.49276178516447544\n","Training loss for fold 5, epoch 31: 188.01163285778415\n","Validation elbo for fold 5, epoch 32: -21891.54014618723\n","Reconstruction accuracy for fold 5, epoch 32: 0.4948070030659437\n","Training loss for fold 5, epoch 32: 187.10823871243386\n","Validation elbo for fold 5, epoch 33: -21787.930988418488\n","Reconstruction accuracy for fold 5, epoch 33: 0.5001796092838049\n","Training loss for fold 5, epoch 33: 185.98196288078063\n","Validation elbo for fold 5, epoch 34: -21744.035020782612\n","Reconstruction accuracy for fold 5, epoch 34: 0.49931783229112625\n","Training loss for fold 5, epoch 34: 185.2791516703944\n","Validation elbo for fold 5, epoch 35: -21630.19865993776\n","Reconstruction accuracy for fold 5, epoch 35: 0.5061606802046299\n","Training loss for fold 5, epoch 35: 184.7691938338741\n","Validation elbo for fold 5, epoch 36: -21554.598297397883\n","Reconstruction accuracy for fold 5, epoch 36: 0.5091647636145353\n","Training loss for fold 5, epoch 36: 184.2181615521831\n","Validation elbo for fold 5, epoch 37: -21470.171009086673\n","Reconstruction accuracy for fold 5, epoch 37: 0.510305467993021\n","Training loss for fold 5, epoch 37: 183.04248809814453\n","Validation elbo for fold 5, epoch 38: -21366.47555444651\n","Reconstruction accuracy for fold 5, epoch 38: 0.5144490115344524\n","Training loss for fold 5, epoch 38: 181.68731935562627\n","Validation elbo for fold 5, epoch 39: -21322.181491541905\n","Reconstruction accuracy for fold 5, epoch 39: 0.5157599411904812\n","Training loss for fold 5, epoch 39: 181.82732612855972\n","Validation elbo for fold 5, epoch 40: -21250.945729106883\n","Reconstruction accuracy for fold 5, epoch 40: 0.518730565905571\n","Training loss for fold 5, epoch 40: 180.2715555006458\n","Validation elbo for fold 5, epoch 41: -21164.347926146987\n","Reconstruction accuracy for fold 5, epoch 41: 0.5234645903110504\n","Training loss for fold 5, epoch 41: 179.33863978232108\n","Validation elbo for fold 5, epoch 42: -21083.688863447118\n","Reconstruction accuracy for fold 5, epoch 42: 0.5241437032818794\n","Training loss for fold 5, epoch 42: 178.78427197856288\n","Validation elbo for fold 5, epoch 43: -21034.683126235126\n","Reconstruction accuracy for fold 5, epoch 43: 0.5259626917541027\n","Training loss for fold 5, epoch 43: 178.41497630457724\n","Validation elbo for fold 5, epoch 44: -21013.524638035007\n","Reconstruction accuracy for fold 5, epoch 44: 0.5264472365379333\n","Training loss for fold 5, epoch 44: 177.9369639735068\n","Validation elbo for fold 5, epoch 45: -20944.786214730495\n","Reconstruction accuracy for fold 5, epoch 45: 0.5285732187330723\n","Training loss for fold 5, epoch 45: 176.83033383277154\n","Validation elbo for fold 5, epoch 46: -20894.09582727114\n","Reconstruction accuracy for fold 5, epoch 46: 0.5311050713062286\n","Training loss for fold 5, epoch 46: 175.58167660620904\n","Validation elbo for fold 5, epoch 47: -20777.665199265684\n","Reconstruction accuracy for fold 5, epoch 47: 0.5344977304339409\n","Training loss for fold 5, epoch 47: 174.86726920835434\n","Validation elbo for fold 5, epoch 48: -20720.3068856595\n","Reconstruction accuracy for fold 5, epoch 48: 0.5366419516503811\n","Training loss for fold 5, epoch 48: 173.98504810948526\n","Validation elbo for fold 5, epoch 49: -20663.53163112923\n","Reconstruction accuracy for fold 5, epoch 49: 0.5381939262151718\n","Training loss for fold 5, epoch 49: 173.57025810980028\n","Validation elbo for fold 5, epoch 50: -20615.242920178913\n","Reconstruction accuracy for fold 5, epoch 50: 0.5385771058499813\n","Training loss for fold 5, epoch 50: 173.2251946233934\n","Validation elbo for fold 5, epoch 51: -20581.639540075084\n","Reconstruction accuracy for fold 5, epoch 51: 0.5381567254662514\n","Training loss for fold 5, epoch 51: 172.48799182522683\n","Validation elbo for fold 5, epoch 52: -20549.913590050826\n","Reconstruction accuracy for fold 5, epoch 52: 0.5425198599696159\n","Training loss for fold 5, epoch 52: 171.87896654682774\n","Validation elbo for fold 5, epoch 53: -20496.5649808407\n","Reconstruction accuracy for fold 5, epoch 53: 0.5429214388132095\n","Training loss for fold 5, epoch 53: 171.33621412707913\n","Validation elbo for fold 5, epoch 54: -20465.945524688126\n","Reconstruction accuracy for fold 5, epoch 54: 0.5445652157068253\n","Training loss for fold 5, epoch 54: 170.39168843915385\n","Validation elbo for fold 5, epoch 55: -20428.77031792902\n","Reconstruction accuracy for fold 5, epoch 55: 0.5462724827229977\n","Training loss for fold 5, epoch 55: 169.64143937633884\n","Validation elbo for fold 5, epoch 56: -20411.899092631968\n","Reconstruction accuracy for fold 5, epoch 56: 0.544348806142807\n","Training loss for fold 5, epoch 56: 169.48744447769658\n","Validation elbo for fold 5, epoch 57: -20344.817335285647\n","Reconstruction accuracy for fold 5, epoch 57: 0.547719344496727\n","Training loss for fold 5, epoch 57: 169.06590344828945\n","Validation elbo for fold 5, epoch 58: -20354.430677979173\n","Reconstruction accuracy for fold 5, epoch 58: 0.5466555207967758\n","Training loss for fold 5, epoch 58: 167.91727792063068\n","Validation elbo for fold 5, epoch 59: -20281.946802023966\n","Reconstruction accuracy for fold 5, epoch 59: 0.5494366884231567\n","Training loss for fold 5, epoch 59: 167.71229036392705\n","Validation elbo for fold 5, epoch 60: -20213.71395701293\n","Reconstruction accuracy for fold 5, epoch 60: 0.5512733832001686\n","Training loss for fold 5, epoch 60: 166.64180583338583\n","Validation elbo for fold 5, epoch 61: -20180.232880843727\n","Reconstruction accuracy for fold 5, epoch 61: 0.5535903349518776\n","Training loss for fold 5, epoch 61: 166.22883064516128\n","Validation elbo for fold 5, epoch 62: -20181.88145887309\n","Reconstruction accuracy for fold 5, epoch 62: 0.5531615130603313\n","Training loss for fold 5, epoch 62: 165.1725679213001\n","Validation elbo for fold 5, epoch 63: -20157.300879146915\n","Reconstruction accuracy for fold 5, epoch 63: 0.552692599594593\n","Training loss for fold 5, epoch 63: 165.77665292063068\n","Validation elbo for fold 5, epoch 64: -20230.3428860095\n","Reconstruction accuracy for fold 5, epoch 64: 0.5528200902044773\n","Training loss for fold 5, epoch 64: 165.71519248716294\n","Validation elbo for fold 5, epoch 65: -20114.931016585622\n","Reconstruction accuracy for fold 5, epoch 65: 0.5521978214383125\n","Training loss for fold 5, epoch 65: 164.65938198950982\n","Validation elbo for fold 5, epoch 66: -20073.974407162073\n","Reconstruction accuracy for fold 5, epoch 66: 0.5554238371551037\n","Training loss for fold 5, epoch 66: 163.83116543677545\n","Validation elbo for fold 5, epoch 67: -20041.24544092144\n","Reconstruction accuracy for fold 5, epoch 67: 0.555962048470974\n","Training loss for fold 5, epoch 67: 163.97706333283455\n","Validation elbo for fold 5, epoch 68: -20070.212215248437\n","Reconstruction accuracy for fold 5, epoch 68: 0.5561037845909595\n","Training loss for fold 5, epoch 68: 163.46637332054877\n","Validation elbo for fold 5, epoch 69: -20030.115674120545\n","Reconstruction accuracy for fold 5, epoch 69: 0.5570525601506233\n","Training loss for fold 5, epoch 69: 162.95751288629347\n","Validation elbo for fold 5, epoch 70: -19969.340918675724\n","Reconstruction accuracy for fold 5, epoch 70: 0.5557206012308598\n","Training loss for fold 5, epoch 70: 162.85472968316847\n","Validation elbo for fold 5, epoch 71: -19986.475704294156\n","Reconstruction accuracy for fold 5, epoch 71: 0.5557726062834263\n","Training loss for fold 5, epoch 71: 162.27879948769845\n","Validation elbo for fold 5, epoch 72: -19929.47982714953\n","Reconstruction accuracy for fold 5, epoch 72: 0.5587921664118767\n","Training loss for fold 5, epoch 72: 161.05986884332472\n","Validation elbo for fold 5, epoch 73: -19907.990037987962\n","Reconstruction accuracy for fold 5, epoch 73: 0.5591011010110378\n","Training loss for fold 5, epoch 73: 161.18519272342806\n","Validation elbo for fold 5, epoch 74: -19896.74804285591\n","Reconstruction accuracy for fold 5, epoch 74: 0.559924028813839\n","Training loss for fold 5, epoch 74: 160.64217007544732\n","Validation elbo for fold 5, epoch 75: -19897.099889377387\n","Reconstruction accuracy for fold 5, epoch 75: 0.561636820435524\n","Training loss for fold 5, epoch 75: 160.95603745983493\n","Validation elbo for fold 5, epoch 76: -19880.802017717597\n","Reconstruction accuracy for fold 5, epoch 76: 0.5611749365925789\n","Training loss for fold 5, epoch 76: 161.0340066725208\n","Validation elbo for fold 5, epoch 77: -19834.955602744652\n","Reconstruction accuracy for fold 5, epoch 77: 0.5631992816925049\n","Training loss for fold 5, epoch 77: 160.02724013790007\n","Validation elbo for fold 5, epoch 78: -19816.517205310447\n","Reconstruction accuracy for fold 5, epoch 78: 0.5633291304111481\n","Training loss for fold 5, epoch 78: 159.1215803084835\n","Validation elbo for fold 5, epoch 79: -19804.4643826783\n","Reconstruction accuracy for fold 5, epoch 79: 0.5634769536554813\n","Training loss for fold 5, epoch 79: 159.05263470065208\n","Validation elbo for fold 5, epoch 80: -19806.960402796212\n","Reconstruction accuracy for fold 5, epoch 80: 0.5634278729557991\n","Training loss for fold 5, epoch 80: 159.14600569202054\n","Validation elbo for fold 5, epoch 81: -19777.388190431302\n","Reconstruction accuracy for fold 5, epoch 81: 0.5646056309342384\n","Training loss for fold 5, epoch 81: 158.23544311523438\n","Validation elbo for fold 5, epoch 82: -19741.934787313876\n","Reconstruction accuracy for fold 5, epoch 82: 0.5671112015843391\n","Training loss for fold 5, epoch 82: 158.43526064965033\n","Validation elbo for fold 5, epoch 83: -19793.099066860774\n","Reconstruction accuracy for fold 5, epoch 83: 0.5642390437424183\n","Training loss for fold 5, epoch 83: 157.89229485296434\n","Validation elbo for fold 5, epoch 84: -19755.9118599832\n","Reconstruction accuracy for fold 5, epoch 84: 0.5624110698699951\n","Training loss for fold 5, epoch 84: 157.44753117715157\n","Validation elbo for fold 5, epoch 85: -19717.456236368474\n","Reconstruction accuracy for fold 5, epoch 85: 0.5655324161052704\n","Training loss for fold 5, epoch 85: 157.77134926088394\n","Validation elbo for fold 5, epoch 86: -19707.050736720834\n","Reconstruction accuracy for fold 5, epoch 86: 0.5677289217710495\n","Training loss for fold 5, epoch 86: 157.13567352294922\n","Validation elbo for fold 5, epoch 87: -19704.9392078578\n","Reconstruction accuracy for fold 5, epoch 87: 0.5671690031886101\n","Training loss for fold 5, epoch 87: 157.1727275233115\n","Validation elbo for fold 5, epoch 88: -19691.138466975608\n","Reconstruction accuracy for fold 5, epoch 88: 0.5647837445139885\n","Training loss for fold 5, epoch 88: 157.15358660298008\n","Validation elbo for fold 5, epoch 89: -19674.119229615375\n","Reconstruction accuracy for fold 5, epoch 89: 0.5690276883542538\n","Training loss for fold 5, epoch 89: 156.3370073380009\n","Validation elbo for fold 5, epoch 90: -19683.632627624705\n","Reconstruction accuracy for fold 5, epoch 90: 0.5684116296470165\n","Training loss for fold 5, epoch 90: 156.03204025760775\n","Validation elbo for fold 5, epoch 91: -19690.186724748608\n","Reconstruction accuracy for fold 5, epoch 91: 0.5650876872241497\n","Training loss for fold 5, epoch 91: 155.35697321737968\n","Validation elbo for fold 5, epoch 92: -19671.647227269103\n","Reconstruction accuracy for fold 5, epoch 92: 0.5676271431148052\n","Training loss for fold 5, epoch 92: 156.36754534321446\n","Validation elbo for fold 5, epoch 93: -19661.377974922387\n","Reconstruction accuracy for fold 5, epoch 93: 0.568265188485384\n","Training loss for fold 5, epoch 93: 155.626348926175\n","Validation elbo for fold 5, epoch 94: -19655.398709363355\n","Reconstruction accuracy for fold 5, epoch 94: 0.5669019855558872\n","Training loss for fold 5, epoch 94: 155.42721483784337\n","Validation elbo for fold 5, epoch 95: -19605.006477607243\n","Reconstruction accuracy for fold 5, epoch 95: 0.5677763521671295\n","Training loss for fold 5, epoch 95: 154.66572644633632\n","Validation elbo for fold 5, epoch 96: -19694.08245205046\n","Reconstruction accuracy for fold 5, epoch 96: 0.5687560886144638\n","Training loss for fold 5, epoch 96: 154.43338098833638\n","Validation elbo for fold 5, epoch 97: -19626.721243463537\n","Reconstruction accuracy for fold 5, epoch 97: 0.5665199086070061\n","Training loss for fold 5, epoch 97: 154.5498153932633\n","Validation elbo for fold 5, epoch 98: -19607.580783337544\n","Reconstruction accuracy for fold 5, epoch 98: 0.5697554722428322\n","Training loss for fold 5, epoch 98: 154.0231441374748\n","Validation elbo for fold 5, epoch 99: -19632.37197653772\n","Reconstruction accuracy for fold 5, epoch 99: 0.5689946413040161\n","Training loss for fold 5, epoch 99: 153.41776127969064\n","Validation elbo for fold 5, epoch 100: -19565.785679283472\n","Reconstruction accuracy for fold 5, epoch 100: 0.5692515596747398\n","Training loss for fold 5, epoch 100: 153.48067892751385\n","Validation elbo for fold 5, epoch 101: -19620.842537760604\n","Reconstruction accuracy for fold 5, epoch 101: 0.5692410469055176\n","Training loss for fold 5, epoch 101: 153.7325181038149\n","Validation elbo for fold 5, epoch 102: -19543.283970699093\n","Reconstruction accuracy for fold 5, epoch 102: 0.5690481476485729\n","Training loss for fold 5, epoch 102: 152.96854917464717\n","Validation elbo for fold 5, epoch 103: -19613.148554303734\n","Reconstruction accuracy for fold 5, epoch 103: 0.5704349987208843\n","Training loss for fold 5, epoch 103: 154.25239833708733\n","Validation elbo for fold 5, epoch 104: -19761.144202888496\n","Reconstruction accuracy for fold 5, epoch 104: 0.565791416913271\n","Training loss for fold 5, epoch 104: 153.18084544520224\n","Validation elbo for fold 5, epoch 105: -19621.426196345914\n","Reconstruction accuracy for fold 5, epoch 105: 0.5665897317230701\n","Training loss for fold 5, epoch 105: 153.41042967765563\n","Validation elbo for fold 5, epoch 106: -19601.204377940736\n","Reconstruction accuracy for fold 5, epoch 106: 0.5683260336518288\n","Training loss for fold 5, epoch 106: 152.6470986643145\n","Validation elbo for fold 5, epoch 107: -19571.140916723703\n","Reconstruction accuracy for fold 5, epoch 107: 0.5731943212449551\n","Training loss for fold 5, epoch 107: 152.62325028450257\n","Validation elbo for fold 5, epoch 108: -19528.320456763657\n","Reconstruction accuracy for fold 5, epoch 108: 0.5711702555418015\n","Training loss for fold 5, epoch 108: 152.3678990025674\n","Validation elbo for fold 5, epoch 109: -19532.91971684999\n","Reconstruction accuracy for fold 5, epoch 109: 0.5719725824892521\n","Training loss for fold 5, epoch 109: 152.1580820391255\n","Validation elbo for fold 5, epoch 110: -19527.984722726567\n","Reconstruction accuracy for fold 5, epoch 110: 0.5723055750131607\n","Training loss for fold 5, epoch 110: 151.2661620109312\n","Validation elbo for fold 5, epoch 111: -19509.187122611496\n","Reconstruction accuracy for fold 5, epoch 111: 0.5720418617129326\n","Training loss for fold 5, epoch 111: 151.2782922560169\n","Validation elbo for fold 5, epoch 112: -19497.56978194652\n","Reconstruction accuracy for fold 5, epoch 112: 0.5710585229098797\n","Training loss for fold 5, epoch 112: 150.8184595415669\n","Validation elbo for fold 5, epoch 113: -19488.008004294723\n","Reconstruction accuracy for fold 5, epoch 113: 0.5712381601333618\n","Training loss for fold 5, epoch 113: 150.59696812783517\n","Validation elbo for fold 5, epoch 114: -19496.347060938606\n","Reconstruction accuracy for fold 5, epoch 114: 0.5721176415681839\n","Training loss for fold 5, epoch 114: 151.0865978117912\n","Validation elbo for fold 5, epoch 115: -19516.70986907222\n","Reconstruction accuracy for fold 5, epoch 115: 0.5705432780086994\n","Training loss for fold 5, epoch 115: 151.61446848223287\n","Validation elbo for fold 5, epoch 116: -19486.23346407235\n","Reconstruction accuracy for fold 5, epoch 116: 0.5726743787527084\n","Training loss for fold 5, epoch 116: 150.099492472987\n","Validation elbo for fold 5, epoch 117: -19467.546257815695\n","Reconstruction accuracy for fold 5, epoch 117: 0.5721675641834736\n","Training loss for fold 5, epoch 117: 150.38840017011088\n","Validation elbo for fold 5, epoch 118: -19478.300113318975\n","Reconstruction accuracy for fold 5, epoch 118: 0.5719168558716774\n","Training loss for fold 5, epoch 118: 150.33768979964717\n","Validation elbo for fold 5, epoch 119: -19443.488600088\n","Reconstruction accuracy for fold 5, epoch 119: 0.5723956041038036\n","Training loss for fold 5, epoch 119: 150.07481482721144\n","Validation elbo for fold 5, epoch 120: -19504.80265767599\n","Reconstruction accuracy for fold 5, epoch 120: 0.5734677091240883\n","Training loss for fold 5, epoch 120: 150.02519865958922\n","Validation elbo for fold 5, epoch 121: -19439.0736016099\n","Reconstruction accuracy for fold 5, epoch 121: 0.5742513686418533\n","Training loss for fold 5, epoch 121: 149.95786962201518\n","Validation elbo for fold 5, epoch 122: -19548.062508269235\n","Reconstruction accuracy for fold 5, epoch 122: 0.5706316381692886\n","Training loss for fold 5, epoch 122: 149.69925443587763\n","Validation elbo for fold 5, epoch 123: -19486.536354230157\n","Reconstruction accuracy for fold 5, epoch 123: 0.5741873420774937\n","Training loss for fold 5, epoch 123: 149.10575792866368\n","Validation elbo for fold 5, epoch 124: -19423.519591107484\n","Reconstruction accuracy for fold 5, epoch 124: 0.572543554008007\n","Training loss for fold 5, epoch 124: 148.69181060791016\n","Validation elbo for fold 5, epoch 125: -19440.650407824658\n","Reconstruction accuracy for fold 5, epoch 125: 0.5742672607302666\n","Training loss for fold 5, epoch 125: 149.00183043941374\n","Validation elbo for fold 5, epoch 126: -19488.266714743244\n","Reconstruction accuracy for fold 5, epoch 126: 0.5731619745492935\n","Training loss for fold 5, epoch 126: 148.89290741951234\n","Validation elbo for fold 5, epoch 127: -19418.02915238057\n","Reconstruction accuracy for fold 5, epoch 127: 0.574997004121542\n","Training loss for fold 5, epoch 127: 148.0180278901131\n","Validation elbo for fold 5, epoch 128: -19407.1973045759\n","Reconstruction accuracy for fold 5, epoch 128: 0.5738240666687489\n","Training loss for fold 5, epoch 128: 147.93372443414503\n","Validation elbo for fold 5, epoch 129: -19403.91250705559\n","Reconstruction accuracy for fold 5, epoch 129: 0.5745474323630333\n","Training loss for fold 5, epoch 129: 147.88687478342365\n","Validation elbo for fold 5, epoch 130: -19478.324574213344\n","Reconstruction accuracy for fold 5, epoch 130: 0.5744937732815742\n","Training loss for fold 5, epoch 130: 147.97444571218182\n","Validation elbo for fold 5, epoch 131: -19464.855282271696\n","Reconstruction accuracy for fold 5, epoch 131: 0.5737207792699337\n","Training loss for fold 5, epoch 131: 148.26458420292025\n","Validation elbo for fold 5, epoch 132: -19423.606476879566\n","Reconstruction accuracy for fold 5, epoch 132: 0.5759669207036495\n","Training loss for fold 5, epoch 132: 147.96350109961725\n","Validation elbo for fold 5, epoch 133: -19418.913786971614\n","Reconstruction accuracy for fold 5, epoch 133: 0.5725287571549416\n","Training loss for fold 5, epoch 133: 147.1165045461347\n","Validation elbo for fold 5, epoch 134: -19436.449053506705\n","Reconstruction accuracy for fold 5, epoch 134: 0.5727637112140656\n","Training loss for fold 5, epoch 134: 147.27906036376953\n","Validation elbo for fold 5, epoch 135: -19397.23887596035\n","Reconstruction accuracy for fold 5, epoch 135: 0.5778975076973438\n","Training loss for fold 5, epoch 135: 147.7569796654486\n","Validation elbo for fold 5, epoch 136: -19403.669969159786\n","Reconstruction accuracy for fold 5, epoch 136: 0.5789130628108978\n","Training loss for fold 5, epoch 136: 147.2050564673639\n","Validation elbo for fold 5, epoch 137: -19363.788691783047\n","Reconstruction accuracy for fold 5, epoch 137: 0.576714351773262\n","Training loss for fold 5, epoch 137: 147.0313574267972\n","Validation elbo for fold 5, epoch 138: -19428.319028369573\n","Reconstruction accuracy for fold 5, epoch 138: 0.5760187767446041\n","Training loss for fold 5, epoch 138: 147.0575284650249\n","Validation elbo for fold 5, epoch 139: -19396.435378634247\n","Reconstruction accuracy for fold 5, epoch 139: 0.5755420997738838\n","Training loss for fold 5, epoch 139: 146.51236134190714\n","Validation elbo for fold 5, epoch 140: -19369.188980240197\n","Reconstruction accuracy for fold 5, epoch 140: 0.5741235874593258\n","Training loss for fold 5, epoch 140: 146.59277097640498\n","Validation elbo for fold 5, epoch 141: -19378.073663797997\n","Reconstruction accuracy for fold 5, epoch 141: 0.5754815489053726\n","Training loss for fold 5, epoch 141: 146.40533865651776\n","Validation elbo for fold 5, epoch 142: -19414.329980961586\n","Reconstruction accuracy for fold 5, epoch 142: 0.5737264454364777\n","Training loss for fold 5, epoch 142: 146.5049904854067\n","Validation elbo for fold 5, epoch 143: -19402.895574235547\n","Reconstruction accuracy for fold 5, epoch 143: 0.577196266502142\n","Training loss for fold 5, epoch 143: 145.82920209823115\n","Validation elbo for fold 5, epoch 144: -19411.87420287094\n","Reconstruction accuracy for fold 5, epoch 144: 0.5732703842222691\n","Training loss for fold 5, epoch 144: 146.2291652310279\n","Validation elbo for fold 5, epoch 145: -19410.22756019942\n","Reconstruction accuracy for fold 5, epoch 145: 0.5759949907660484\n","Training loss for fold 5, epoch 145: 146.26645746538716\n","Validation elbo for fold 5, epoch 146: -19393.26368615043\n","Reconstruction accuracy for fold 5, epoch 146: 0.5761219300329685\n","Training loss for fold 5, epoch 146: 145.5689209968813\n","Validation elbo for fold 5, epoch 147: -19387.338506562883\n","Reconstruction accuracy for fold 5, epoch 147: 0.5751694366335869\n","Training loss for fold 5, epoch 147: 145.98917511970765\n","Validation elbo for fold 5, epoch 148: -19352.511683483157\n","Reconstruction accuracy for fold 5, epoch 148: 0.5751254558563232\n","Training loss for fold 5, epoch 148: 146.4891871790732\n","Validation elbo for fold 5, epoch 149: -19394.873192902567\n","Reconstruction accuracy for fold 5, epoch 149: 0.5757449716329575\n","Training loss for fold 5, epoch 149: 145.6943471354823\n","Validation elbo for fold 5, epoch 150: -19327.467113416336\n","Reconstruction accuracy for fold 5, epoch 150: 0.5801654942333698\n","Training loss for fold 5, epoch 150: 145.3129159250567\n","Validation elbo for fold 5, epoch 151: -19403.821231898186\n","Reconstruction accuracy for fold 5, epoch 151: 0.5752857364714146\n","Training loss for fold 5, epoch 151: 145.06183328936177\n","Validation elbo for fold 5, epoch 152: -19364.627995775034\n","Reconstruction accuracy for fold 5, epoch 152: 0.5765344388782978\n","Training loss for fold 5, epoch 152: 145.2844732961347\n","Validation elbo for fold 5, epoch 153: -19355.054030154875\n","Reconstruction accuracy for fold 5, epoch 153: 0.5762817971408367\n","Training loss for fold 5, epoch 153: 145.07396550332345\n","Validation elbo for fold 5, epoch 154: -19329.318179411326\n","Reconstruction accuracy for fold 5, epoch 154: 0.5777594894170761\n","Training loss for fold 5, epoch 154: 144.3659775026383\n","Validation elbo for fold 5, epoch 155: -19383.148290744306\n","Reconstruction accuracy for fold 5, epoch 155: 0.578854151070118\n","Training loss for fold 5, epoch 155: 144.78568317044167\n","Validation elbo for fold 5, epoch 156: -19365.30979169\n","Reconstruction accuracy for fold 5, epoch 156: 0.5758890621364117\n","Training loss for fold 5, epoch 156: 144.6013380481351\n","Validation elbo for fold 5, epoch 157: -19359.719129684992\n","Reconstruction accuracy for fold 5, epoch 157: 0.5768374167382717\n","Training loss for fold 5, epoch 157: 144.75323757048577\n","Validation elbo for fold 5, epoch 158: -19375.409910717746\n","Reconstruction accuracy for fold 5, epoch 158: 0.5772943049669266\n","Training loss for fold 5, epoch 158: 144.77392467375725\n","Validation elbo for fold 5, epoch 159: -19315.82992278229\n","Reconstruction accuracy for fold 5, epoch 159: 0.5791011229157448\n","Training loss for fold 5, epoch 159: 145.06189949281753\n","Validation elbo for fold 5, epoch 160: -19444.41034484432\n","Reconstruction accuracy for fold 5, epoch 160: 0.5752754993736744\n","Training loss for fold 5, epoch 160: 146.18049818469632\n","Validation elbo for fold 5, epoch 161: -19391.607859445558\n","Reconstruction accuracy for fold 5, epoch 161: 0.5764442682266235\n","Training loss for fold 5, epoch 161: 145.04315530100178\n","Validation elbo for fold 5, epoch 162: -19339.19728216002\n","Reconstruction accuracy for fold 5, epoch 162: 0.5778283625841141\n","Training loss for fold 5, epoch 162: 144.13022625830865\n","Validation elbo for fold 5, epoch 163: -19312.283963056125\n","Reconstruction accuracy for fold 5, epoch 163: 0.5763423703610897\n","Training loss for fold 5, epoch 163: 143.691044222924\n","Validation elbo for fold 5, epoch 164: -19362.107214802727\n","Reconstruction accuracy for fold 5, epoch 164: 0.5765625089406967\n","Training loss for fold 5, epoch 164: 143.78558398831277\n","Validation elbo for fold 5, epoch 165: -19371.02368574482\n","Reconstruction accuracy for fold 5, epoch 165: 0.5740486420691013\n","Training loss for fold 5, epoch 165: 142.70237362769342\n","Validation elbo for fold 5, epoch 166: -19357.83129128965\n","Reconstruction accuracy for fold 5, epoch 166: 0.5755667164921761\n","Training loss for fold 5, epoch 166: 143.94801084456904\n","Validation elbo for fold 5, epoch 167: -19385.64450186552\n","Reconstruction accuracy for fold 5, epoch 167: 0.5739865563809872\n","Training loss for fold 5, epoch 167: 143.67380868234943\n","Validation elbo for fold 5, epoch 168: -19389.458963116034\n","Reconstruction accuracy for fold 5, epoch 168: 0.5780284591019154\n","Training loss for fold 5, epoch 168: 143.144716693509\n","Validation elbo for fold 5, epoch 169: -19396.614471925375\n","Reconstruction accuracy for fold 5, epoch 169: 0.5784146822988987\n","Training loss for fold 5, epoch 169: 143.76773908061367\n","Validation elbo for fold 5, epoch 170: -19365.03959942682\n","Reconstruction accuracy for fold 5, epoch 170: 0.5769115313887596\n","Training loss for fold 5, epoch 170: 143.32246362009357\n","Validation elbo for fold 5, epoch 171: -19356.674228830594\n","Reconstruction accuracy for fold 5, epoch 171: 0.576661940664053\n","Training loss for fold 5, epoch 171: 143.14736753894437\n","Validation elbo for fold 5, epoch 172: -19396.396401233425\n","Reconstruction accuracy for fold 5, epoch 172: 0.5753060691058636\n","Training loss for fold 5, epoch 172: 143.08706468151462\n","Validation elbo for fold 5, epoch 173: -19376.79426250946\n","Reconstruction accuracy for fold 5, epoch 173: 0.5764101184904575\n","Training loss for fold 5, epoch 173: 142.79039272185295\n","Validation elbo for fold 5, epoch 174: -19329.229490197475\n","Reconstruction accuracy for fold 5, epoch 174: 0.5768903754651546\n","Training loss for fold 5, epoch 174: 143.3510259812878\n","Validation elbo for fold 5, epoch 175: -19320.25439107389\n","Reconstruction accuracy for fold 5, epoch 175: 0.5785957053303719\n","Training loss for fold 5, epoch 175: 142.91194595829134\n","Validation elbo for fold 5, epoch 176: -19353.436022273854\n","Reconstruction accuracy for fold 5, epoch 176: 0.5773338563740253\n","Training loss for fold 5, epoch 176: 142.69346840150894\n","Validation elbo for fold 5, epoch 177: -19372.215518952067\n","Reconstruction accuracy for fold 5, epoch 177: 0.5756574347615242\n","Training loss for fold 5, epoch 177: 142.60036123952557\n","Validation elbo for fold 5, epoch 178: -19381.047520745647\n","Reconstruction accuracy for fold 5, epoch 178: 0.5780027359724045\n","Training loss for fold 5, epoch 178: 143.70611055435674\n","Validation elbo for fold 5, epoch 179: -19376.0117438966\n","Reconstruction accuracy for fold 5, epoch 179: 0.5760615020990372\n","Training loss for fold 5, epoch 179: 142.53553968860257\n","Validation elbo for fold 5, epoch 180: -19356.134537722777\n","Reconstruction accuracy for fold 5, epoch 180: 0.5769277177751064\n","Training loss for fold 5, epoch 180: 142.37209787676412\n","Validation elbo for fold 5, epoch 181: -19363.902251266787\n","Reconstruction accuracy for fold 5, epoch 181: 0.5775618925690651\n","Training loss for fold 5, epoch 181: 142.82786609280495\n","Validation elbo for fold 5, epoch 182: -19376.195804902352\n","Reconstruction accuracy for fold 5, epoch 182: 0.5777829997241497\n","Training loss for fold 5, epoch 182: 142.59483903454196\n","Validation elbo for fold 5, epoch 183: -19361.285701661\n","Reconstruction accuracy for fold 5, epoch 183: 0.5796527452766895\n","Training loss for fold 5, epoch 183: 141.85911055534118\n","Validation elbo for fold 5, epoch 184: -19352.682498571725\n","Reconstruction accuracy for fold 5, epoch 184: 0.5780532173812389\n","Training loss for fold 5, epoch 184: 142.4486829696163\n","Validation elbo for fold 5, epoch 185: -19360.27757328121\n","Reconstruction accuracy for fold 5, epoch 185: 0.5811796858906746\n","Training loss for fold 5, epoch 185: 141.7005575856855\n","Validation elbo for fold 5, epoch 186: -19332.55502815101\n","Reconstruction accuracy for fold 5, epoch 186: 0.5804607383906841\n","Training loss for fold 5, epoch 186: 141.68219621719854\n","Validation elbo for fold 5, epoch 187: -19344.096107142454\n","Reconstruction accuracy for fold 5, epoch 187: 0.5783394537866116\n","Training loss for fold 5, epoch 187: 141.29013073828912\n","Validation elbo for fold 5, epoch 188: -19365.3915941755\n","Reconstruction accuracy for fold 5, epoch 188: 0.5778781436383724\n","Training loss for fold 5, epoch 188: 141.2165868205409\n","Validation elbo for fold 5, epoch 189: -19445.863754682374\n","Reconstruction accuracy for fold 5, epoch 189: 0.5755894035100937\n","Training loss for fold 5, epoch 189: 143.77128182688068\n","Validation elbo for fold 5, epoch 190: -19416.593969853406\n","Reconstruction accuracy for fold 5, epoch 190: 0.5769560672342777\n","Training loss for fold 5, epoch 190: 141.7755942806121\n","Validation elbo for fold 5, epoch 191: -19412.13593037421\n","Reconstruction accuracy for fold 5, epoch 191: 0.5751215890049934\n","Training loss for fold 5, epoch 191: 141.95457064720893\n","Validation elbo for fold 5, epoch 192: -19319.936594821396\n","Reconstruction accuracy for fold 5, epoch 192: 0.5783415399491787\n","Training loss for fold 5, epoch 192: 141.73451429797757\n","Validation elbo for fold 5, epoch 193: -19324.578679549424\n","Reconstruction accuracy for fold 5, epoch 193: 0.5777218863368034\n","Training loss for fold 5, epoch 193: 142.5945560086158\n","Validation elbo for fold 5, epoch 194: -19358.57638797763\n","Reconstruction accuracy for fold 5, epoch 194: 0.5750379338860512\n","Training loss for fold 5, epoch 194: 141.76873311688823\n","Validation elbo for fold 5, epoch 195: -19341.0619333749\n","Reconstruction accuracy for fold 5, epoch 195: 0.5782834626734257\n","Training loss for fold 5, epoch 195: 141.49306118872857\n","Validation elbo for fold 5, epoch 196: -19369.744431703883\n","Reconstruction accuracy for fold 5, epoch 196: 0.5798903182148933\n","Training loss for fold 5, epoch 196: 142.23942467474168\n","Validation elbo for fold 5, epoch 197: -19382.55779505223\n","Reconstruction accuracy for fold 5, epoch 197: 0.5761003606021404\n","Training loss for fold 5, epoch 197: 141.53178122735792\n","Validation elbo for fold 5, epoch 198: -19333.291149220582\n","Reconstruction accuracy for fold 5, epoch 198: 0.5757688991725445\n","Training loss for fold 5, epoch 198: 141.7812611979823\n","Validation elbo for fold 5, epoch 199: -19335.717402096754\n","Reconstruction accuracy for fold 5, epoch 199: 0.5788591392338276\n","Training loss for fold 5, epoch 199: 140.96519261021768\n","Validation elbo for fold 5, epoch 200: -19283.038438478492\n","Reconstruction accuracy for fold 5, epoch 200: 0.5806608349084854\n","Training loss for fold 5, epoch 200: 140.6326560974121\n","Validation elbo for fold 5, epoch 201: -19372.367691398777\n","Reconstruction accuracy for fold 5, epoch 201: 0.5762682370841503\n","Training loss for fold 5, epoch 201: 140.6252429100775\n","Validation elbo for fold 5, epoch 202: -19326.25977704025\n","Reconstruction accuracy for fold 5, epoch 202: 0.5759250186383724\n","Training loss for fold 5, epoch 202: 140.65126935897334\n","Validation elbo for fold 5, epoch 203: -19350.730061454487\n","Reconstruction accuracy for fold 5, epoch 203: 0.5785815939307213\n","Training loss for fold 5, epoch 203: 140.75849040862053\n","Validation elbo for fold 5, epoch 204: -19350.47375534729\n","Reconstruction accuracy for fold 5, epoch 204: 0.5783455520868301\n","Training loss for fold 5, epoch 204: 140.36232203821982\n","Validation elbo for fold 5, epoch 205: -19370.185170531477\n","Reconstruction accuracy for fold 5, epoch 205: 0.5802538618445396\n","Training loss for fold 5, epoch 205: 140.84086350471742\n","Validation elbo for fold 5, epoch 206: -19330.682153743477\n","Reconstruction accuracy for fold 5, epoch 206: 0.5777752585709095\n","Training loss for fold 5, epoch 206: 141.0646166647634\n","Validation elbo for fold 5, epoch 207: -19312.31458741511\n","Reconstruction accuracy for fold 5, epoch 207: 0.5786940231919289\n","Training loss for fold 5, epoch 207: 140.50033557030463\n","Validation elbo for fold 5, epoch 208: -19334.133901384994\n","Reconstruction accuracy for fold 5, epoch 208: 0.5785160511732101\n","Training loss for fold 5, epoch 208: 140.15158179498488\n","Validation elbo for fold 5, epoch 209: -19339.202055146252\n","Reconstruction accuracy for fold 5, epoch 209: 0.580913070589304\n","Training loss for fold 5, epoch 209: 140.51384501303397\n","Validation elbo for fold 5, epoch 210: -19405.321315341458\n","Reconstruction accuracy for fold 5, epoch 210: 0.5770567357540131\n","Training loss for fold 5, epoch 210: 139.8457172762963\n","Validation elbo for fold 5, epoch 211: -19325.99342428109\n","Reconstruction accuracy for fold 5, epoch 211: 0.5792377553880215\n","Training loss for fold 5, epoch 211: 139.700799511325\n","Validation elbo for fold 5, epoch 212: -19340.85018080596\n","Reconstruction accuracy for fold 5, epoch 212: 0.5782787539064884\n","Training loss for fold 5, epoch 212: 141.01803121259135\n","Validation elbo for fold 5, epoch 213: -19361.222023754388\n","Reconstruction accuracy for fold 5, epoch 213: 0.5786512978374958\n","Training loss for fold 5, epoch 213: 139.9475928275816\n","Validation elbo for fold 5, epoch 214: -19308.31386733513\n","Reconstruction accuracy for fold 5, epoch 214: 0.5775437727570534\n","Training loss for fold 5, epoch 214: 139.98367026544386\n","Validation elbo for fold 5, epoch 215: -19352.287553386654\n","Reconstruction accuracy for fold 5, epoch 215: 0.5788442045450211\n","Training loss for fold 5, epoch 215: 140.61258697509766\n","Validation elbo for fold 5, epoch 216: -19323.499751940286\n","Reconstruction accuracy for fold 5, epoch 216: 0.5803100131452084\n","Training loss for fold 5, epoch 216: 139.75462439752394\n","Validation elbo for fold 5, epoch 217: -19383.213403388447\n","Reconstruction accuracy for fold 5, epoch 217: 0.5767370350658894\n","Training loss for fold 5, epoch 217: 140.75296340450163\n","Validation elbo for fold 5, epoch 218: -19356.117469094912\n","Reconstruction accuracy for fold 5, epoch 218: 0.57499935105443\n","Training loss for fold 5, epoch 218: 140.11447229693013\n","Validation elbo for fold 5, epoch 219: -19344.90734276072\n","Reconstruction accuracy for fold 5, epoch 219: 0.5780975967645645\n","Training loss for fold 5, epoch 219: 140.01288912373204\n","Validation elbo for fold 5, epoch 220: -19345.065214781993\n","Reconstruction accuracy for fold 5, epoch 220: 0.5792367830872536\n","Training loss for fold 5, epoch 220: 139.75033458586663\n","Validation elbo for fold 5, epoch 221: -19329.798714880588\n","Reconstruction accuracy for fold 5, epoch 221: 0.5792826935648918\n","Training loss for fold 5, epoch 221: 140.16452284782164\n","Validation elbo for fold 5, epoch 222: -19398.067769515088\n","Reconstruction accuracy for fold 5, epoch 222: 0.5780955255031586\n","Training loss for fold 5, epoch 222: 139.72818682270665\n","Validation elbo for fold 5, epoch 223: -19335.64524369935\n","Reconstruction accuracy for fold 5, epoch 223: 0.5795517936348915\n","Training loss for fold 5, epoch 223: 140.57198985930413\n","Validation elbo for fold 5, epoch 224: -19303.217063257427\n","Reconstruction accuracy for fold 5, epoch 224: 0.5770796909928322\n","Training loss for fold 5, epoch 224: 140.34531870195943\n","Validation elbo for fold 5, epoch 225: -19375.71311354904\n","Reconstruction accuracy for fold 5, epoch 225: 0.575298860669136\n","Training loss for fold 5, epoch 225: 139.68747231268114\n","Validation elbo for fold 5, epoch 226: -19359.20977593164\n","Reconstruction accuracy for fold 5, epoch 226: 0.576255526393652\n","Training loss for fold 5, epoch 226: 139.5602418222735\n","Validation elbo for fold 5, epoch 227: -19352.89015288867\n","Reconstruction accuracy for fold 5, epoch 227: 0.5763537064194679\n","Training loss for fold 5, epoch 227: 139.61691234957786\n","Validation elbo for fold 5, epoch 228: -19329.89834267427\n","Reconstruction accuracy for fold 5, epoch 228: 0.5766861326992512\n","Training loss for fold 5, epoch 228: 139.1274818912629\n","Validation elbo for fold 5, epoch 229: -19331.7343252076\n","Reconstruction accuracy for fold 5, epoch 229: 0.5804955847561359\n","Training loss for fold 5, epoch 229: 139.1512670209331\n","Validation elbo for fold 5, epoch 230: -19310.826531831386\n","Reconstruction accuracy for fold 5, epoch 230: 0.5784564465284348\n","Training loss for fold 5, epoch 230: 139.0729587924096\n","Validation elbo for fold 5, epoch 231: -19383.505260040984\n","Reconstruction accuracy for fold 5, epoch 231: 0.5783223137259483\n","Training loss for fold 5, epoch 231: 139.9925671239053\n","Validation elbo for fold 5, epoch 232: -19331.046124529938\n","Reconstruction accuracy for fold 5, epoch 232: 0.5791428871452808\n","Training loss for fold 5, epoch 232: 139.73599267775012\n","Validation elbo for fold 5, epoch 233: -19378.06170793113\n","Reconstruction accuracy for fold 5, epoch 233: 0.5786458924412727\n","Training loss for fold 5, epoch 233: 140.7273672780683\n","Validation elbo for fold 5, epoch 234: -19373.404743876607\n","Reconstruction accuracy for fold 5, epoch 234: 0.5805247724056244\n","Training loss for fold 5, epoch 234: 139.3233206964308\n","Validation elbo for fold 5, epoch 235: -19357.072288167896\n","Reconstruction accuracy for fold 5, epoch 235: 0.5792247503995895\n","Training loss for fold 5, epoch 235: 138.80252173639113\n","Validation elbo for fold 5, epoch 236: -19367.414438109387\n","Reconstruction accuracy for fold 5, epoch 236: 0.5787969045341015\n","Training loss for fold 5, epoch 236: 139.09683030651462\n","Validation elbo for fold 5, epoch 237: -19366.66023070725\n","Reconstruction accuracy for fold 5, epoch 237: 0.5791069343686104\n","Training loss for fold 5, epoch 237: 138.86521653206117\n","Validation elbo for fold 5, epoch 238: -19313.11555993314\n","Reconstruction accuracy for fold 5, epoch 238: 0.578698169440031\n","Training loss for fold 5, epoch 238: 139.78548628284085\n","Validation elbo for fold 5, epoch 239: -19355.0840555216\n","Reconstruction accuracy for fold 5, epoch 239: 0.5800626203417778\n","Training loss for fold 5, epoch 239: 139.41578120570028\n","Validation elbo for fold 5, epoch 240: -19359.56071621816\n","Reconstruction accuracy for fold 5, epoch 240: 0.5802935473620892\n","Training loss for fold 5, epoch 240: 139.25426704652847\n","Validation elbo for fold 5, epoch 241: -19398.106974725168\n","Reconstruction accuracy for fold 5, epoch 241: 0.5802653394639492\n","Training loss for fold 5, epoch 241: 138.96401559152912\n","Validation elbo for fold 5, epoch 242: -19432.92247980254\n","Reconstruction accuracy for fold 5, epoch 242: 0.5782000720500946\n","Training loss for fold 5, epoch 242: 138.27903390699817\n","Validation elbo for fold 5, epoch 243: -19334.451306754137\n","Reconstruction accuracy for fold 5, epoch 243: 0.5807985700666904\n","Training loss for fold 5, epoch 243: 139.02929552139776\n","Validation elbo for fold 5, epoch 244: -19340.874539449935\n","Reconstruction accuracy for fold 5, epoch 244: 0.578061506152153\n","Training loss for fold 5, epoch 244: 139.1705653282904\n","Validation elbo for fold 5, epoch 245: -19292.099542107397\n","Reconstruction accuracy for fold 5, epoch 245: 0.5800229273736477\n","Training loss for fold 5, epoch 245: 138.72061600223665\n","Validation elbo for fold 5, epoch 246: -19350.6276461816\n","Reconstruction accuracy for fold 5, epoch 246: 0.5756025426089764\n","Training loss for fold 5, epoch 246: 138.89419567969537\n","Validation elbo for fold 5, epoch 247: -19326.7241884308\n","Reconstruction accuracy for fold 5, epoch 247: 0.5760673098266125\n","Training loss for fold 5, epoch 247: 138.13027991017987\n","Validation elbo for fold 5, epoch 248: -19302.329613809765\n","Reconstruction accuracy for fold 5, epoch 248: 0.5802332609891891\n","Training loss for fold 5, epoch 248: 139.14504648024035\n","Validation elbo for fold 5, epoch 249: -19388.572470478735\n","Reconstruction accuracy for fold 5, epoch 249: 0.5779878050088882\n","Training loss for fold 5, epoch 249: 138.95919307585686\n","Validation elbo for fold 5, epoch 250: -19302.441099006537\n","Reconstruction accuracy for fold 5, epoch 250: 0.5804684832692146\n","Training loss for fold 5, epoch 250: 137.6127812785487\n","Validation elbo for fold 5, epoch 251: -19334.25780185588\n","Reconstruction accuracy for fold 5, epoch 251: 0.5810313038527966\n","Training loss for fold 5, epoch 251: 138.19090861658896\n","Validation elbo for fold 5, epoch 252: -19327.55128691606\n","Reconstruction accuracy for fold 5, epoch 252: 0.5781429521739483\n","Training loss for fold 5, epoch 252: 138.80924323297316\n","Validation elbo for fold 5, epoch 253: -19328.613041174955\n","Reconstruction accuracy for fold 5, epoch 253: 0.5769470781087875\n","Training loss for fold 5, epoch 253: 138.87415252193327\n","Validation elbo for fold 5, epoch 254: -19354.50723492883\n","Reconstruction accuracy for fold 5, epoch 254: 0.5816311724483967\n","Training loss for fold 5, epoch 254: 138.49179987753593\n","Validation elbo for fold 5, epoch 255: -19341.41564706382\n","Reconstruction accuracy for fold 5, epoch 255: 0.5787606798112392\n","Training loss for fold 5, epoch 255: 139.18570758450417\n","Validation elbo for fold 5, epoch 256: -19378.36285834935\n","Reconstruction accuracy for fold 5, epoch 256: 0.5809255167841911\n","Training loss for fold 5, epoch 256: 138.40373389951645\n","Validation elbo for fold 5, epoch 257: -19388.68550163797\n","Reconstruction accuracy for fold 5, epoch 257: 0.5795486196875572\n","Training loss for fold 5, epoch 257: 138.4697986725838\n","Validation elbo for fold 5, epoch 258: -19309.158598889775\n","Reconstruction accuracy for fold 5, epoch 258: 0.5818000249564648\n","Training loss for fold 5, epoch 258: 137.87260178596742\n","Validation elbo for fold 5, epoch 259: -19357.14037455933\n","Reconstruction accuracy for fold 5, epoch 259: 0.5793030261993408\n","Training loss for fold 5, epoch 259: 137.89938169910062\n","Validation elbo for fold 5, epoch 260: -19337.968507280744\n","Reconstruction accuracy for fold 5, epoch 260: 0.5803069658577442\n","Training loss for fold 5, epoch 260: 138.47160228606194\n","Validation elbo for fold 5, epoch 261: -19397.01506396634\n","Reconstruction accuracy for fold 5, epoch 261: 0.5798615589737892\n","Training loss for fold 5, epoch 261: 137.64900244435955\n","Validation elbo for fold 5, epoch 262: -19328.413776015652\n","Reconstruction accuracy for fold 5, epoch 262: 0.5815186090767384\n","Training loss for fold 5, epoch 262: 138.37301820324313\n","Validation elbo for fold 5, epoch 263: -19332.127614894165\n","Reconstruction accuracy for fold 5, epoch 263: 0.5803376622498035\n","Training loss for fold 5, epoch 263: 138.4849473276446\n","Validation elbo for fold 5, epoch 264: -19326.44621494951\n","Reconstruction accuracy for fold 5, epoch 264: 0.579878281801939\n","Training loss for fold 5, epoch 264: 138.14934773598947\n","Validation elbo for fold 5, epoch 265: -19365.455261182844\n","Reconstruction accuracy for fold 5, epoch 265: 0.5803945027291775\n","Training loss for fold 5, epoch 265: 138.08385701333322\n","Validation elbo for fold 5, epoch 266: -19343.016526890202\n","Reconstruction accuracy for fold 5, epoch 266: 0.5789580047130585\n","Training loss for fold 5, epoch 266: 137.54940648232736\n","Validation elbo for fold 5, epoch 267: -19415.413339999737\n","Reconstruction accuracy for fold 5, epoch 267: 0.5809508264064789\n","Training loss for fold 5, epoch 267: 138.0607661585654\n","Validation elbo for fold 5, epoch 268: -19407.44058230719\n","Reconstruction accuracy for fold 5, epoch 268: 0.5769427940249443\n","Training loss for fold 5, epoch 268: 138.47781039822488\n","Validation elbo for fold 5, epoch 269: -19379.565350176625\n","Reconstruction accuracy for fold 5, epoch 269: 0.581478513777256\n","Training loss for fold 5, epoch 269: 138.18946100050402\n","Validation elbo for fold 5, epoch 270: -19328.82973616771\n","Reconstruction accuracy for fold 5, epoch 270: 0.5786656700074673\n","Training loss for fold 5, epoch 270: 138.02472403741652\n","Validation elbo for fold 5, epoch 271: -19353.4825292229\n","Reconstruction accuracy for fold 5, epoch 271: 0.582472912967205\n","Training loss for fold 5, epoch 271: 137.1186167809271\n","Validation elbo for fold 5, epoch 272: -19365.929379350066\n","Reconstruction accuracy for fold 5, epoch 272: 0.579794205725193\n","Training loss for fold 5, epoch 272: 138.52408206078314\n","Validation elbo for fold 5, epoch 273: -19373.00757184477\n","Reconstruction accuracy for fold 5, epoch 273: 0.5802741944789886\n","Training loss for fold 5, epoch 273: 138.42359185987902\n","Validation elbo for fold 5, epoch 274: -19396.485615984675\n","Reconstruction accuracy for fold 5, epoch 274: 0.5806761868298054\n","Training loss for fold 5, epoch 274: 137.4939688405683\n","Validation elbo for fold 5, epoch 275: -19317.149444849103\n","Reconstruction accuracy for fold 5, epoch 275: 0.5817687623202801\n","Training loss for fold 5, epoch 275: 137.33231747534967\n","Validation elbo for fold 5, epoch 276: -19329.096090287254\n","Reconstruction accuracy for fold 5, epoch 276: 0.5804787240922451\n","Training loss for fold 5, epoch 276: 137.50535078971618\n","Validation elbo for fold 5, epoch 277: -19367.319566257\n","Reconstruction accuracy for fold 5, epoch 277: 0.5777749940752983\n","Training loss for fold 5, epoch 277: 137.44425521358366\n","Validation elbo for fold 5, epoch 278: -19366.791080463714\n","Reconstruction accuracy for fold 5, epoch 278: 0.5803657360374928\n","Training loss for fold 5, epoch 278: 137.7520564909904\n","Validation elbo for fold 5, epoch 279: -19367.270961147915\n","Reconstruction accuracy for fold 5, epoch 279: 0.5771713741123676\n","Training loss for fold 5, epoch 279: 137.8789962030226\n","Validation elbo for fold 5, epoch 280: -19328.405736625045\n","Reconstruction accuracy for fold 5, epoch 280: 0.5788589976727962\n","Training loss for fold 5, epoch 280: 137.1480028706212\n","Validation elbo for fold 5, epoch 281: -19315.047459592955\n","Reconstruction accuracy for fold 5, epoch 281: 0.5820122882723808\n","Training loss for fold 5, epoch 281: 137.21687796808058\n","Validation elbo for fold 5, epoch 282: -19370.83976959643\n","Reconstruction accuracy for fold 5, epoch 282: 0.5772965177893639\n","Training loss for fold 5, epoch 282: 136.4846308308263\n","Validation elbo for fold 5, epoch 283: -19307.748881024105\n","Reconstruction accuracy for fold 5, epoch 283: 0.5796845518052578\n","Training loss for fold 5, epoch 283: 136.90834045410156\n","Validation elbo for fold 5, epoch 284: -19361.990874229545\n","Reconstruction accuracy for fold 5, epoch 284: 0.5783579982817173\n","Training loss for fold 5, epoch 284: 136.6481073441044\n","Validation elbo for fold 5, epoch 285: -19360.297862625368\n","Reconstruction accuracy for fold 5, epoch 285: 0.5766416154801846\n","Training loss for fold 5, epoch 285: 137.1036903627457\n","Validation elbo for fold 5, epoch 286: -19350.664808875343\n","Reconstruction accuracy for fold 5, epoch 286: 0.5802551135420799\n","Training loss for fold 5, epoch 286: 137.25908660888672\n","Validation elbo for fold 5, epoch 287: -19336.341863787587\n","Reconstruction accuracy for fold 5, epoch 287: 0.5800550132989883\n","Training loss for fold 5, epoch 287: 137.5045302606398\n","Validation elbo for fold 5, epoch 288: -19363.853391307683\n","Reconstruction accuracy for fold 5, epoch 288: 0.5771914310753345\n","Training loss for fold 5, epoch 288: 137.3217310751638\n","Validation elbo for fold 5, epoch 289: -19383.75224495856\n","Reconstruction accuracy for fold 5, epoch 289: 0.5781895630061626\n","Training loss for fold 5, epoch 289: 137.41590007658928\n","Validation elbo for fold 5, epoch 290: -19296.443372304697\n","Reconstruction accuracy for fold 5, epoch 290: 0.580750584602356\n","Training loss for fold 5, epoch 290: 137.05838923300468\n","Validation elbo for fold 5, epoch 291: -19363.67153360073\n","Reconstruction accuracy for fold 5, epoch 291: 0.5788920409977436\n","Training loss for fold 5, epoch 291: 137.4631275053947\n","Validation elbo for fold 5, epoch 292: -19352.05995988396\n","Reconstruction accuracy for fold 5, epoch 292: 0.579993475228548\n","Training loss for fold 5, epoch 292: 136.70975974298292\n","Validation elbo for fold 5, epoch 293: -19404.025009782632\n","Reconstruction accuracy for fold 5, epoch 293: 0.5782862231135368\n","Training loss for fold 5, epoch 293: 136.96899881670552\n","Validation elbo for fold 5, epoch 294: -19321.667090412553\n","Reconstruction accuracy for fold 5, epoch 294: 0.5812880918383598\n","Training loss for fold 5, epoch 294: 136.76716183077903\n","Validation elbo for fold 5, epoch 295: -19340.452497107024\n","Reconstruction accuracy for fold 5, epoch 295: 0.5818141289055347\n","Training loss for fold 5, epoch 295: 137.71205606768208\n","Validation elbo for fold 5, epoch 296: -19350.34747884104\n","Reconstruction accuracy for fold 5, epoch 296: 0.5786929167807102\n","Training loss for fold 5, epoch 296: 136.87837883733934\n","Validation elbo for fold 5, epoch 297: -19367.295321958103\n","Reconstruction accuracy for fold 5, epoch 297: 0.5795509591698647\n","Training loss for fold 5, epoch 297: 137.02050042921496\n","Validation elbo for fold 5, epoch 298: -19356.760488181706\n","Reconstruction accuracy for fold 5, epoch 298: 0.5758611373603344\n","Training loss for fold 5, epoch 298: 138.6083012242471\n","Validation elbo for fold 5, epoch 299: -19458.55108439945\n","Reconstruction accuracy for fold 5, epoch 299: 0.5777626857161522\n","Training loss for fold 5, epoch 299: 137.49420953566027\n","Validation elbo for fold 5, epoch 300: -19324.308914979483\n","Reconstruction accuracy for fold 5, epoch 300: 0.5800782442092896\n","Training loss for fold 5, epoch 300: 136.54071746333952\n","Validation elbo for fold 5, epoch 301: -19370.902598017838\n","Reconstruction accuracy for fold 5, epoch 301: 0.5794566534459591\n","Training loss for fold 5, epoch 301: 137.9912947377851\n","Validation elbo for fold 5, epoch 302: -19330.9586486761\n","Reconstruction accuracy for fold 5, epoch 302: 0.5795809850096703\n","Training loss for fold 5, epoch 302: 136.4079085319273\n","Validation elbo for fold 5, epoch 303: -19381.90561484151\n","Reconstruction accuracy for fold 5, epoch 303: 0.5790646262466908\n","Training loss for fold 5, epoch 303: 136.71536624047064\n","Validation elbo for fold 5, epoch 304: -19390.87051276519\n","Reconstruction accuracy for fold 5, epoch 304: 0.5763024054467678\n","Training loss for fold 5, epoch 304: 137.1097814498409\n","Validation elbo for fold 5, epoch 305: -19397.536400932455\n","Reconstruction accuracy for fold 5, epoch 305: 0.5817914456129074\n","Training loss for fold 5, epoch 305: 137.383053687311\n","Validation elbo for fold 5, epoch 306: -19310.907745263095\n","Reconstruction accuracy for fold 5, epoch 306: 0.579412404447794\n","Training loss for fold 5, epoch 306: 136.85216620660597\n","Validation elbo for fold 5, epoch 307: -19323.135363452548\n","Reconstruction accuracy for fold 5, epoch 307: 0.5795797370374203\n","Training loss for fold 5, epoch 307: 136.74512727798955\n","Validation elbo for fold 5, epoch 308: -19367.950007186708\n","Reconstruction accuracy for fold 5, epoch 308: 0.5800106301903725\n","Training loss for fold 5, epoch 308: 137.13413829188192\n","Validation elbo for fold 5, epoch 309: -19345.818560040214\n","Reconstruction accuracy for fold 5, epoch 309: 0.5799763351678848\n","Training loss for fold 5, epoch 309: 136.87348310409052\n","Validation elbo for fold 5, epoch 310: -19324.632583936076\n","Reconstruction accuracy for fold 5, epoch 310: 0.5804936476051807\n","Training loss for fold 5, epoch 310: 136.45396558700068\n","Validation elbo for fold 5, epoch 311: -19319.423013373642\n","Reconstruction accuracy for fold 5, epoch 311: 0.5785102397203445\n","Training loss for fold 5, epoch 311: 136.60251039074313\n","Validation elbo for fold 5, epoch 312: -19377.224101594686\n","Reconstruction accuracy for fold 5, epoch 312: 0.5788222104310989\n","Training loss for fold 5, epoch 312: 135.56300403225808\n","Validation elbo for fold 5, epoch 313: -19391.528032356924\n","Reconstruction accuracy for fold 5, epoch 313: 0.5761238746345043\n","Training loss for fold 5, epoch 313: 138.22251289121567\n","Validation elbo for fold 5, epoch 314: -19312.85660085356\n","Reconstruction accuracy for fold 5, epoch 314: 0.5807267986238003\n","Training loss for fold 5, epoch 314: 137.8619138656124\n","Validation elbo for fold 5, epoch 315: -19333.51964594491\n","Reconstruction accuracy for fold 5, epoch 315: 0.5813895910978317\n","Training loss for fold 5, epoch 315: 135.70273848502868\n","Validation elbo for fold 5, epoch 316: -19403.37674978048\n","Reconstruction accuracy for fold 5, epoch 316: 0.5814045295119286\n","Training loss for fold 5, epoch 316: 137.0450656029486\n","Validation elbo for fold 5, epoch 317: -19340.726243065197\n","Reconstruction accuracy for fold 5, epoch 317: 0.5792094096541405\n","Training loss for fold 5, epoch 317: 135.85564521051222\n","Validation elbo for fold 5, epoch 318: -19399.41406651308\n","Reconstruction accuracy for fold 5, epoch 318: 0.5805146619677544\n","Training loss for fold 5, epoch 318: 137.29296235115297\n","Validation elbo for fold 5, epoch 319: -19335.95045954227\n","Reconstruction accuracy for fold 5, epoch 319: 0.5803340710699558\n","Training loss for fold 5, epoch 319: 136.06514370825982\n","Validation elbo for fold 5, epoch 320: -19372.75936964363\n","Reconstruction accuracy for fold 5, epoch 320: 0.5784334950149059\n","Training loss for fold 5, epoch 320: 136.0275187338552\n","Validation elbo for fold 5, epoch 321: -19354.135398197643\n","Reconstruction accuracy for fold 5, epoch 321: 0.581203319132328\n","Training loss for fold 5, epoch 321: 136.38735851164788\n","Validation elbo for fold 5, epoch 322: -19334.371197526285\n","Reconstruction accuracy for fold 5, epoch 322: 0.5790225826203823\n","Training loss for fold 5, epoch 322: 136.31054576750725\n","Validation elbo for fold 5, epoch 323: -19318.746867612914\n","Reconstruction accuracy for fold 5, epoch 323: 0.5797701478004456\n","Training loss for fold 5, epoch 323: 136.3935797906691\n","Validation elbo for fold 5, epoch 324: -19328.3437539659\n","Reconstruction accuracy for fold 5, epoch 324: 0.5803791470825672\n","Training loss for fold 5, epoch 324: 135.3067843529486\n","Validation elbo for fold 5, epoch 325: -19340.35258601681\n","Reconstruction accuracy for fold 5, epoch 325: 0.5810604766011238\n","Training loss for fold 5, epoch 325: 135.00151603452622\n","Validation elbo for fold 5, epoch 326: -19351.234941237555\n","Reconstruction accuracy for fold 5, epoch 326: 0.5813888944685459\n","Training loss for fold 5, epoch 326: 136.8298496123283\n","Validation elbo for fold 5, epoch 327: -19357.56954514768\n","Reconstruction accuracy for fold 5, epoch 327: 0.5826192237436771\n","Training loss for fold 5, epoch 327: 136.73103197159307\n","Validation elbo for fold 5, epoch 328: -19350.63303286155\n","Reconstruction accuracy for fold 5, epoch 328: 0.5801410265266895\n","Training loss for fold 5, epoch 328: 136.1230585652013\n","Validation elbo for fold 5, epoch 329: -19335.284411050925\n","Reconstruction accuracy for fold 5, epoch 329: 0.5793410576879978\n","Training loss for fold 5, epoch 329: 135.57421911916424\n","Validation elbo for fold 5, epoch 330: -19359.252123504724\n","Reconstruction accuracy for fold 5, epoch 330: 0.5802675522863865\n","Training loss for fold 5, epoch 330: 135.84103184361612\n","Validation elbo for fold 5, epoch 331: -19369.071116050323\n","Reconstruction accuracy for fold 5, epoch 331: 0.5818105302751064\n","Training loss for fold 5, epoch 331: 135.93632187381868\n","Validation elbo for fold 5, epoch 332: -19331.522799273684\n","Reconstruction accuracy for fold 5, epoch 332: 0.5813460350036621\n","Training loss for fold 5, epoch 332: 135.85263221494614\n","Validation elbo for fold 5, epoch 333: -19325.44858956887\n","Reconstruction accuracy for fold 5, epoch 333: 0.5824156627058983\n","Training loss for fold 5, epoch 333: 134.91976633379537\n","Validation elbo for fold 5, epoch 334: -19352.11840566016\n","Reconstruction accuracy for fold 5, epoch 334: 0.5816784724593163\n","Training loss for fold 5, epoch 334: 135.58089373188633\n","Validation elbo for fold 5, epoch 335: -19339.789972383704\n","Reconstruction accuracy for fold 5, epoch 335: 0.5801885984838009\n","Training loss for fold 5, epoch 335: 134.7805981789866\n","Validation elbo for fold 5, epoch 336: -19426.153142209936\n","Reconstruction accuracy for fold 5, epoch 336: 0.5774614922702312\n","Training loss for fold 5, epoch 336: 136.31931809456117\n","Validation elbo for fold 5, epoch 337: -19405.25140080168\n","Reconstruction accuracy for fold 5, epoch 337: 0.5781152918934822\n","Training loss for fold 5, epoch 337: 136.25650147468812\n","Validation elbo for fold 5, epoch 338: -19338.513625572414\n","Reconstruction accuracy for fold 5, epoch 338: 0.5832372009754181\n","Training loss for fold 5, epoch 338: 136.43456243699598\n","Validation elbo for fold 5, epoch 339: -19393.333520775835\n","Reconstruction accuracy for fold 5, epoch 339: 0.578347485512495\n","Training loss for fold 5, epoch 339: 136.03375391806327\n","Validation elbo for fold 5, epoch 340: -19373.137344607425\n","Reconstruction accuracy for fold 5, epoch 340: 0.5814887434244156\n","Training loss for fold 5, epoch 340: 136.58120395291238\n","Validation elbo for fold 5, epoch 341: -19375.93652021156\n","Reconstruction accuracy for fold 5, epoch 341: 0.5812219902873039\n","Training loss for fold 5, epoch 341: 135.43989698348506\n","Validation elbo for fold 5, epoch 342: -19379.716599392705\n","Reconstruction accuracy for fold 5, epoch 342: 0.5821602493524551\n","Training loss for fold 5, epoch 342: 136.44671015585624\n","Validation elbo for fold 5, epoch 343: -19344.878874360897\n","Reconstruction accuracy for fold 5, epoch 343: 0.5807106196880341\n","Training loss for fold 5, epoch 343: 136.0380496363486\n","Validation elbo for fold 5, epoch 344: -19379.242622659305\n","Reconstruction accuracy for fold 5, epoch 344: 0.5789179019629955\n","Training loss for fold 5, epoch 344: 136.14431110505134\n","Validation elbo for fold 5, epoch 345: -19354.64962363799\n","Reconstruction accuracy for fold 5, epoch 345: 0.5809671357274055\n","Training loss for fold 5, epoch 345: 135.4337419079196\n","Validation elbo for fold 5, epoch 346: -19329.21967259918\n","Reconstruction accuracy for fold 5, epoch 346: 0.5785937681794167\n","Training loss for fold 5, epoch 346: 136.34003165460402\n","Validation elbo for fold 5, epoch 347: -19409.04698503696\n","Reconstruction accuracy for fold 5, epoch 347: 0.580032467842102\n","Training loss for fold 5, epoch 347: 136.10081728043096\n","Validation elbo for fold 5, epoch 348: -19351.24153363102\n","Reconstruction accuracy for fold 5, epoch 348: 0.580711305141449\n","Training loss for fold 5, epoch 348: 135.40562537408644\n","Validation elbo for fold 5, epoch 349: -19349.117109172767\n","Reconstruction accuracy for fold 5, epoch 349: 0.5811817459762096\n","Training loss for fold 5, epoch 349: 135.69294381910754\n","Validation elbo for fold 5, epoch 350: -19357.403646646926\n","Reconstruction accuracy for fold 5, epoch 350: 0.580257460474968\n","Training loss for fold 5, epoch 350: 134.93680129512663\n","Validation elbo for fold 5, epoch 351: -19363.53447469696\n","Reconstruction accuracy for fold 5, epoch 351: 0.5795284286141396\n","Training loss for fold 5, epoch 351: 134.91087095199092\n","Validation elbo for fold 5, epoch 352: -19387.602401038333\n","Reconstruction accuracy for fold 5, epoch 352: 0.5791297554969788\n","Training loss for fold 5, epoch 352: 135.98996279316563\n","Validation elbo for fold 5, epoch 353: -19421.406753679847\n","Reconstruction accuracy for fold 5, epoch 353: 0.5770658664405346\n","Training loss for fold 5, epoch 353: 136.14591475455993\n","Validation elbo for fold 5, epoch 354: -19400.430760903284\n","Reconstruction accuracy for fold 5, epoch 354: 0.5789463892579079\n","Training loss for fold 5, epoch 354: 136.18121756276776\n","Validation elbo for fold 5, epoch 355: -19378.598465261635\n","Reconstruction accuracy for fold 5, epoch 355: 0.580259807407856\n","Training loss for fold 5, epoch 355: 135.95913179459112\n","Validation elbo for fold 5, epoch 356: -19350.675547287967\n","Reconstruction accuracy for fold 5, epoch 356: 0.5792448073625565\n","Training loss for fold 5, epoch 356: 135.75791438933342\n","Validation elbo for fold 5, epoch 357: -19308.501320778312\n","Reconstruction accuracy for fold 5, epoch 357: 0.5820351019501686\n","Training loss for fold 5, epoch 357: 135.45144357988912\n","Validation elbo for fold 5, epoch 358: -19400.64598881811\n","Reconstruction accuracy for fold 5, epoch 358: 0.5791784375905991\n","Training loss for fold 5, epoch 358: 135.40377672256963\n","Validation elbo for fold 5, epoch 359: -19380.33023628433\n","Reconstruction accuracy for fold 5, epoch 359: 0.5801684036850929\n","Training loss for fold 5, epoch 359: 134.92899691674018\n","Validation elbo for fold 5, epoch 360: -19382.66848652897\n","Reconstruction accuracy for fold 5, epoch 360: 0.5787989795207977\n","Training loss for fold 5, epoch 360: 135.83276748657227\n","Validation elbo for fold 5, epoch 361: -19338.151620190743\n","Reconstruction accuracy for fold 5, epoch 361: 0.5804381929337978\n","Training loss for fold 5, epoch 361: 135.95857743294007\n","Validation elbo for fold 5, epoch 362: -19532.801268555726\n","Reconstruction accuracy for fold 5, epoch 362: 0.5762763917446136\n","Training loss for fold 5, epoch 362: 135.139404296875\n","Validation elbo for fold 5, epoch 363: -19388.404679124473\n","Reconstruction accuracy for fold 5, epoch 363: 0.5807818323373795\n","Training loss for fold 5, epoch 363: 136.89770557034402\n","Validation elbo for fold 5, epoch 364: -19380.83433221894\n","Reconstruction accuracy for fold 5, epoch 364: 0.5794591493904591\n","Training loss for fold 5, epoch 364: 135.56526073332756\n","Validation elbo for fold 5, epoch 365: -19467.463379729685\n","Reconstruction accuracy for fold 5, epoch 365: 0.5794555470347404\n","Training loss for fold 5, epoch 365: 135.68547956405146\n","Validation elbo for fold 5, epoch 366: -19341.490505228674\n","Reconstruction accuracy for fold 5, epoch 366: 0.5830438919365406\n","Training loss for fold 5, epoch 366: 135.1748278217931\n","Validation elbo for fold 5, epoch 367: -19388.27459807804\n","Reconstruction accuracy for fold 5, epoch 367: 0.5825807750225067\n","Training loss for fold 5, epoch 367: 134.84157623783236\n","Validation elbo for fold 5, epoch 368: -19375.368745306994\n","Reconstruction accuracy for fold 5, epoch 368: 0.5823519192636013\n","Training loss for fold 5, epoch 368: 135.05958126437278\n","Validation elbo for fold 5, epoch 369: -19397.895031329404\n","Reconstruction accuracy for fold 5, epoch 369: 0.5805460624396801\n","Training loss for fold 5, epoch 369: 134.9739527548513\n","Validation elbo for fold 5, epoch 370: -19373.081601102822\n","Reconstruction accuracy for fold 5, epoch 370: 0.5784677900373936\n","Training loss for fold 5, epoch 370: 134.98603993077433\n","Validation elbo for fold 5, epoch 371: -19343.46834967461\n","Reconstruction accuracy for fold 5, epoch 371: 0.5793136693537235\n","Training loss for fold 5, epoch 371: 135.03134905907416\n","Validation elbo for fold 5, epoch 372: -19399.577157030188\n","Reconstruction accuracy for fold 5, epoch 372: 0.5777193978428841\n","Training loss for fold 5, epoch 372: 136.11928521433185\n","Validation elbo for fold 5, epoch 373: -19336.615226911686\n","Reconstruction accuracy for fold 5, epoch 373: 0.5809634141623974\n","Training loss for fold 5, epoch 373: 135.3944969177246\n","Validation elbo for fold 5, epoch 374: -19378.323643789612\n","Reconstruction accuracy for fold 5, epoch 374: 0.5819374844431877\n","Training loss for fold 5, epoch 374: 134.7866912349578\n","Validation elbo for fold 5, epoch 375: -19396.992491376626\n","Reconstruction accuracy for fold 5, epoch 375: 0.5798188224434853\n","Training loss for fold 5, epoch 375: 135.31007471392232\n","Validation elbo for fold 5, epoch 376: -19317.511917528293\n","Reconstruction accuracy for fold 5, epoch 376: 0.5807646885514259\n","Training loss for fold 5, epoch 376: 134.58184629871\n","Validation elbo for fold 5, epoch 377: -19389.085131935877\n","Reconstruction accuracy for fold 5, epoch 377: 0.5802674144506454\n","Training loss for fold 5, epoch 377: 135.59618476129347\n","Validation elbo for fold 5, epoch 378: -19347.271779052266\n","Reconstruction accuracy for fold 5, epoch 378: 0.5811717920005322\n","Training loss for fold 5, epoch 378: 134.97178219210716\n","Validation elbo for fold 5, epoch 379: -19366.839450939828\n","Reconstruction accuracy for fold 5, epoch 379: 0.5817105509340763\n","Training loss for fold 5, epoch 379: 135.24378081290953\n","Validation elbo for fold 5, epoch 380: -19375.4546140973\n","Reconstruction accuracy for fold 5, epoch 380: 0.5811878442764282\n","Training loss for fold 5, epoch 380: 134.9743664649225\n","Validation elbo for fold 5, epoch 381: -19333.236773640776\n","Reconstruction accuracy for fold 5, epoch 381: 0.5799901597201824\n","Training loss for fold 5, epoch 381: 134.4886494298135\n","Validation elbo for fold 5, epoch 382: -19404.781495538573\n","Reconstruction accuracy for fold 5, epoch 382: 0.580610778182745\n","Training loss for fold 5, epoch 382: 135.05598941926033\n","Validation elbo for fold 5, epoch 383: -19400.49067381069\n","Reconstruction accuracy for fold 5, epoch 383: 0.5806204602122307\n","Training loss for fold 5, epoch 383: 135.4489582430932\n","Validation elbo for fold 5, epoch 384: -19365.243722634164\n","Reconstruction accuracy for fold 5, epoch 384: 0.5811592116951942\n","Training loss for fold 5, epoch 384: 133.9448005922379\n","Validation elbo for fold 5, epoch 385: -19400.568421268494\n","Reconstruction accuracy for fold 5, epoch 385: 0.578591413795948\n","Training loss for fold 5, epoch 385: 135.10149789625598\n","Validation elbo for fold 5, epoch 386: -19393.65042788162\n","Reconstruction accuracy for fold 5, epoch 386: 0.5809758454561234\n","Training loss for fold 5, epoch 386: 135.21574758714246\n","Validation elbo for fold 5, epoch 387: -19439.02033370147\n","Reconstruction accuracy for fold 5, epoch 387: 0.5794619135558605\n","Training loss for fold 5, epoch 387: 135.26583050143333\n","Validation elbo for fold 5, epoch 388: -19408.823183951852\n","Reconstruction accuracy for fold 5, epoch 388: 0.5766713321208954\n","Training loss for fold 5, epoch 388: 135.09295838879\n","Validation elbo for fold 5, epoch 389: -19349.402549122766\n","Reconstruction accuracy for fold 5, epoch 389: 0.5804440043866634\n","Training loss for fold 5, epoch 389: 134.57156015211535\n","Validation elbo for fold 5, epoch 390: -19363.060935791582\n","Reconstruction accuracy for fold 5, epoch 390: 0.5803646296262741\n","Training loss for fold 5, epoch 390: 134.52082923150832\n","Validation elbo for fold 5, epoch 391: -19389.070668259665\n","Reconstruction accuracy for fold 5, epoch 391: 0.5799307003617287\n","Training loss for fold 5, epoch 391: 135.04797203310073\n","Validation elbo for fold 5, epoch 392: -19424.78009636954\n","Reconstruction accuracy for fold 5, epoch 392: 0.5816920176148415\n","Training loss for fold 5, epoch 392: 134.1431171048072\n","Validation elbo for fold 5, epoch 393: -19350.04889103469\n","Reconstruction accuracy for fold 5, epoch 393: 0.5815656296908855\n","Training loss for fold 5, epoch 393: 135.4310073852539\n","Validation elbo for fold 5, epoch 394: -19417.031425612593\n","Reconstruction accuracy for fold 5, epoch 394: 0.5782754346728325\n","Training loss for fold 5, epoch 394: 134.4893510880009\n","Validation elbo for fold 5, epoch 395: -19356.57156611311\n","Reconstruction accuracy for fold 5, epoch 395: 0.5791882537305355\n","Training loss for fold 5, epoch 395: 135.1186406535487\n","Validation elbo for fold 5, epoch 396: -19379.351872222294\n","Reconstruction accuracy for fold 5, epoch 396: 0.5822497233748436\n","Training loss for fold 5, epoch 396: 134.4566928494361\n","Validation elbo for fold 5, epoch 397: -19387.965465015084\n","Reconstruction accuracy for fold 5, epoch 397: 0.579740971326828\n","Training loss for fold 5, epoch 397: 135.0716937895744\n","Validation elbo for fold 5, epoch 398: -19354.705085468006\n","Reconstruction accuracy for fold 5, epoch 398: 0.5803845413029194\n","Training loss for fold 5, epoch 398: 135.85928455475837\n","Validation elbo for fold 5, epoch 399: -19403.41692472084\n","Reconstruction accuracy for fold 5, epoch 399: 0.5778957046568394\n","Training loss for fold 5, epoch 399: 135.18329497306578\n","Validation elbo for fold 5, epoch 400: -19371.610295836348\n","Reconstruction accuracy for fold 5, epoch 400: 0.5809454210102558\n","Training loss for fold 5, epoch 400: 134.5252310229886\n","Validation elbo for fold 5, epoch 401: -19332.975594407282\n","Reconstruction accuracy for fold 5, epoch 401: 0.5831175968050957\n","Training loss for fold 5, epoch 401: 134.04789118612968\n","Validation elbo for fold 5, epoch 402: -19419.950099592024\n","Reconstruction accuracy for fold 5, epoch 402: 0.579903457313776\n","Training loss for fold 5, epoch 402: 134.8370672656644\n","Validation elbo for fold 5, epoch 403: -19355.59368259154\n","Reconstruction accuracy for fold 5, epoch 403: 0.581268310546875\n","Training loss for fold 5, epoch 403: 134.55262608681954\n","Validation elbo for fold 5, epoch 404: -19383.40612087372\n","Reconstruction accuracy for fold 5, epoch 404: 0.580072432756424\n","Training loss for fold 5, epoch 404: 134.46752289802797\n","Validation elbo for fold 5, epoch 405: -19368.91224602857\n","Reconstruction accuracy for fold 5, epoch 405: 0.578944731503725\n","Training loss for fold 5, epoch 405: 134.36619370983493\n","Validation elbo for fold 5, epoch 406: -19413.696874587116\n","Reconstruction accuracy for fold 5, epoch 406: 0.5807414576411247\n","Training loss for fold 5, epoch 406: 134.080012044599\n","Validation elbo for fold 5, epoch 407: -19376.128084999138\n","Reconstruction accuracy for fold 5, epoch 407: 0.5807940065860748\n","Training loss for fold 5, epoch 407: 134.03379944832093\n","Validation elbo for fold 5, epoch 408: -19369.242380999938\n","Reconstruction accuracy for fold 5, epoch 408: 0.5794248506426811\n","Training loss for fold 5, epoch 408: 134.1810531616211\n","Validation elbo for fold 5, epoch 409: -19404.701220359857\n","Reconstruction accuracy for fold 5, epoch 409: 0.5787992589175701\n","Training loss for fold 5, epoch 409: 134.26609506914693\n","Validation elbo for fold 5, epoch 410: -19392.27710017073\n","Reconstruction accuracy for fold 5, epoch 410: 0.581611268222332\n","Training loss for fold 5, epoch 410: 134.95616679037772\n","Validation elbo for fold 5, epoch 411: -19362.80290649192\n","Reconstruction accuracy for fold 5, epoch 411: 0.5802840143442154\n","Training loss for fold 5, epoch 411: 134.57035532305318\n","Validation elbo for fold 5, epoch 412: -19372.747571118256\n","Reconstruction accuracy for fold 5, epoch 412: 0.5820252858102322\n","Training loss for fold 5, epoch 412: 134.49307398642264\n","Validation elbo for fold 5, epoch 413: -19374.40858825792\n","Reconstruction accuracy for fold 5, epoch 413: 0.5792672075331211\n","Training loss for fold 5, epoch 413: 134.02654130997198\n","Validation elbo for fold 5, epoch 414: -19333.878928404207\n","Reconstruction accuracy for fold 5, epoch 414: 0.5814577713608742\n","Training loss for fold 5, epoch 414: 134.52320098876953\n","Validation elbo for fold 5, epoch 415: -19354.69841198352\n","Reconstruction accuracy for fold 5, epoch 415: 0.5800760313868523\n","Training loss for fold 5, epoch 415: 134.8766169394216\n","Validation elbo for fold 5, epoch 416: -19404.64298488757\n","Reconstruction accuracy for fold 5, epoch 416: 0.5803362913429737\n","Training loss for fold 5, epoch 416: 134.6033850639097\n","Validation elbo for fold 5, epoch 417: -19439.768185120443\n","Reconstruction accuracy for fold 5, epoch 417: 0.5790206454694271\n","Training loss for fold 5, epoch 417: 135.01119576731037\n","Validation elbo for fold 5, epoch 418: -19354.645930077088\n","Reconstruction accuracy for fold 5, epoch 418: 0.5801534689962864\n","Training loss for fold 5, epoch 418: 134.011350816296\n","Validation elbo for fold 5, epoch 419: -19364.755836226665\n","Reconstruction accuracy for fold 5, epoch 419: 0.5792694203555584\n","Training loss for fold 5, epoch 419: 134.25501472719253\n","Validation elbo for fold 5, epoch 420: -19399.695207303103\n","Reconstruction accuracy for fold 5, epoch 420: 0.5801769830286503\n","Training loss for fold 5, epoch 420: 134.52351662420458\n","Validation elbo for fold 5, epoch 421: -19356.735841446593\n","Reconstruction accuracy for fold 5, epoch 421: 0.5777993276715279\n","Training loss for fold 5, epoch 421: 133.99245588241084\n","Validation elbo for fold 5, epoch 422: -19366.384679095016\n","Reconstruction accuracy for fold 5, epoch 422: 0.5784124732017517\n","Training loss for fold 5, epoch 422: 133.87578275126796\n","Validation elbo for fold 5, epoch 423: -19397.437208004347\n","Reconstruction accuracy for fold 5, epoch 423: 0.5799645707011223\n","Training loss for fold 5, epoch 423: 134.11634186775453\n","Validation elbo for fold 5, epoch 424: -19411.799019347625\n","Reconstruction accuracy for fold 5, epoch 424: 0.5786682963371277\n","Training loss for fold 5, epoch 424: 134.07760509367913\n","Validation elbo for fold 5, epoch 425: -19388.57346706158\n","Reconstruction accuracy for fold 5, epoch 425: 0.5804361253976822\n","Training loss for fold 5, epoch 425: 135.12207535774476\n","Validation elbo for fold 5, epoch 426: -19413.239761945257\n","Reconstruction accuracy for fold 5, epoch 426: 0.580076988786459\n","Training loss for fold 5, epoch 426: 134.3052481374433\n","Validation elbo for fold 5, epoch 427: -19365.268034701723\n","Reconstruction accuracy for fold 5, epoch 427: 0.5805737152695656\n","Training loss for fold 5, epoch 427: 134.1036573840726\n","Validation elbo for fold 5, epoch 428: -19379.200385074175\n","Reconstruction accuracy for fold 5, epoch 428: 0.580960500985384\n","Training loss for fold 5, epoch 428: 134.34539438063098\n","Validation elbo for fold 5, epoch 429: -19358.849925110004\n","Reconstruction accuracy for fold 5, epoch 429: 0.5815948098897934\n","Training loss for fold 5, epoch 429: 133.96150810487808\n","Validation elbo for fold 5, epoch 430: -19371.38407647393\n","Reconstruction accuracy for fold 5, epoch 430: 0.5791041702032089\n","Training loss for fold 5, epoch 430: 134.19698702904486\n","Validation elbo for fold 5, epoch 431: -19433.49139163739\n","Reconstruction accuracy for fold 5, epoch 431: 0.5792019367218018\n","Training loss for fold 5, epoch 431: 134.21372407482517\n","Validation elbo for fold 5, epoch 432: -19363.227097171977\n","Reconstruction accuracy for fold 5, epoch 432: 0.5811570063233376\n","Training loss for fold 5, epoch 432: 134.0336707330519\n","Validation elbo for fold 5, epoch 433: -19313.91115284256\n","Reconstruction accuracy for fold 5, epoch 433: 0.5829404518008232\n","Training loss for fold 5, epoch 433: 133.33979268227853\n","Validation elbo for fold 5, epoch 434: -19376.159041943254\n","Reconstruction accuracy for fold 5, epoch 434: 0.5822432190179825\n","Training loss for fold 5, epoch 434: 133.9950363405289\n","Validation elbo for fold 5, epoch 435: -19354.981591384865\n","Reconstruction accuracy for fold 5, epoch 435: 0.5799215734004974\n","Training loss for fold 5, epoch 435: 133.4131395893712\n","Validation elbo for fold 5, epoch 436: -19392.518139537497\n","Reconstruction accuracy for fold 5, epoch 436: 0.5801493301987648\n","Training loss for fold 5, epoch 436: 134.0414770803144\n","Validation elbo for fold 5, epoch 437: -19407.213824385042\n","Reconstruction accuracy for fold 5, epoch 437: 0.5818604528903961\n","Training loss for fold 5, epoch 437: 134.08523682625062\n","Validation elbo for fold 5, epoch 438: -19438.006269316254\n","Reconstruction accuracy for fold 5, epoch 438: 0.5791462138295174\n","Training loss for fold 5, epoch 438: 134.25958781088553\n","Validation elbo for fold 5, epoch 439: -19345.313714558695\n","Reconstruction accuracy for fold 5, epoch 439: 0.5801630094647408\n","Training loss for fold 5, epoch 439: 133.52461390341483\n","Validation elbo for fold 5, epoch 440: -19387.182152685615\n","Reconstruction accuracy for fold 5, epoch 440: 0.5807176679372787\n","Training loss for fold 5, epoch 440: 134.28717102543\n","Validation elbo for fold 5, epoch 441: -19346.05927960173\n","Reconstruction accuracy for fold 5, epoch 441: 0.5807113014161587\n","Training loss for fold 5, epoch 441: 134.16845838485224\n","Validation elbo for fold 5, epoch 442: -19394.473125354874\n","Reconstruction accuracy for fold 5, epoch 442: 0.5815031230449677\n","Training loss for fold 5, epoch 442: 134.5107607687673\n","Validation elbo for fold 5, epoch 443: -19367.259256881545\n","Reconstruction accuracy for fold 5, epoch 443: 0.5816577300429344\n","Training loss for fold 5, epoch 443: 134.3470705093876\n","Validation elbo for fold 5, epoch 444: -19397.029050943664\n","Reconstruction accuracy for fold 5, epoch 444: 0.5808079726994038\n","Training loss for fold 5, epoch 444: 134.5268686356083\n","Validation elbo for fold 5, epoch 445: -19365.674771985745\n","Reconstruction accuracy for fold 5, epoch 445: 0.5796855203807354\n","Training loss for fold 5, epoch 445: 134.6961774518413\n","Validation elbo for fold 5, epoch 446: -19391.207338637403\n","Reconstruction accuracy for fold 5, epoch 446: 0.5804362669587135\n","Training loss for fold 5, epoch 446: 134.15595872940557\n","Validation elbo for fold 5, epoch 447: -19391.194800140172\n","Reconstruction accuracy for fold 5, epoch 447: 0.5823227353394032\n","Training loss for fold 5, epoch 447: 133.4563102722168\n","Validation elbo for fold 5, epoch 448: -19438.18442472756\n","Reconstruction accuracy for fold 5, epoch 448: 0.5791760832071304\n","Training loss for fold 5, epoch 448: 134.78403362151116\n","Validation elbo for fold 5, epoch 449: -19415.771306429055\n","Reconstruction accuracy for fold 5, epoch 449: 0.5786463096737862\n","Training loss for fold 5, epoch 449: 133.8294543604697\n","Validation elbo for fold 5, epoch 450: -19447.778204968745\n","Reconstruction accuracy for fold 5, epoch 450: 0.5783732011914253\n","Training loss for fold 5, epoch 450: 134.47246896066974\n","Validation elbo for fold 5, epoch 451: -19394.032571528693\n","Reconstruction accuracy for fold 5, epoch 451: 0.5806219689548016\n","Training loss for fold 5, epoch 451: 134.73065160935926\n","Validation elbo for fold 5, epoch 452: -19349.60865992133\n","Reconstruction accuracy for fold 5, epoch 452: 0.580796767026186\n","Training loss for fold 5, epoch 452: 134.47186894570626\n","Validation elbo for fold 5, epoch 453: -19416.038998606164\n","Reconstruction accuracy for fold 5, epoch 453: 0.5812562853097916\n","Training loss for fold 5, epoch 453: 133.82983644547002\n","Validation elbo for fold 5, epoch 454: -19389.004703690596\n","Reconstruction accuracy for fold 5, epoch 454: 0.5814652405679226\n","Training loss for fold 5, epoch 454: 134.00310627106697\n","Validation elbo for fold 5, epoch 455: -19392.619268789542\n","Reconstruction accuracy for fold 5, epoch 455: 0.5831384770572186\n","Training loss for fold 5, epoch 455: 133.64673811389554\n","Validation elbo for fold 5, epoch 456: -19455.453415002714\n","Reconstruction accuracy for fold 5, epoch 456: 0.5814497545361519\n","Training loss for fold 5, epoch 456: 134.55489497030936\n","Validation elbo for fold 5, epoch 457: -19336.996433267\n","Reconstruction accuracy for fold 5, epoch 457: 0.5816155448555946\n","Training loss for fold 5, epoch 457: 134.01925671485162\n","Validation elbo for fold 5, epoch 458: -19408.06922371475\n","Reconstruction accuracy for fold 5, epoch 458: 0.5782770924270153\n","Training loss for fold 5, epoch 458: 134.3595755792433\n","Validation elbo for fold 5, epoch 459: -19384.994324443644\n","Reconstruction accuracy for fold 5, epoch 459: 0.5810053013265133\n","Training loss for fold 5, epoch 459: 134.25234456216134\n","Validation elbo for fold 5, epoch 460: -19390.924430264095\n","Reconstruction accuracy for fold 5, epoch 460: 0.5824066698551178\n","Training loss for fold 5, epoch 460: 133.40709956999748\n","Validation elbo for fold 5, epoch 461: -19389.05434954283\n","Reconstruction accuracy for fold 5, epoch 461: 0.5804640613496304\n","Training loss for fold 5, epoch 461: 133.9029302289409\n","Validation elbo for fold 5, epoch 462: -19490.848376836537\n","Reconstruction accuracy for fold 5, epoch 462: 0.5809671357274055\n","Training loss for fold 5, epoch 462: 134.0493658742597\n","Validation elbo for fold 5, epoch 463: -19335.662103795104\n","Reconstruction accuracy for fold 5, epoch 463: 0.5806446522474289\n","Training loss for fold 5, epoch 463: 134.05627355267924\n","Validation elbo for fold 5, epoch 464: -19427.105961577327\n","Reconstruction accuracy for fold 5, epoch 464: 0.5817317143082619\n","Training loss for fold 5, epoch 464: 133.35691636608493\n","Validation elbo for fold 5, epoch 465: -19427.15434393631\n","Reconstruction accuracy for fold 5, epoch 465: 0.5808310583233833\n","Training loss for fold 5, epoch 465: 133.82160469793504\n","Validation elbo for fold 5, epoch 466: -19382.47242853382\n","Reconstruction accuracy for fold 5, epoch 466: 0.5817961506545544\n","Training loss for fold 5, epoch 466: 134.10578832318706\n","Validation elbo for fold 5, epoch 467: -19361.477574244054\n","Reconstruction accuracy for fold 5, epoch 467: 0.5814762935042381\n","Training loss for fold 5, epoch 467: 133.82571411132812\n","Validation elbo for fold 5, epoch 468: -19385.02840402047\n","Reconstruction accuracy for fold 5, epoch 468: 0.5820901431143284\n","Training loss for fold 5, epoch 468: 133.81610304309476\n","Validation elbo for fold 5, epoch 469: -19380.601482461025\n","Reconstruction accuracy for fold 5, epoch 469: 0.5808437913656235\n","Training loss for fold 5, epoch 469: 133.9582300493794\n","Validation elbo for fold 5, epoch 470: -19341.936883828734\n","Reconstruction accuracy for fold 5, epoch 470: 0.5797628201544285\n","Training loss for fold 5, epoch 470: 133.76831300797002\n","Validation elbo for fold 5, epoch 471: -19387.572697534066\n","Reconstruction accuracy for fold 5, epoch 471: 0.5811557546257973\n","Training loss for fold 5, epoch 471: 133.23217662688225\n","Validation elbo for fold 5, epoch 472: -19391.693265919563\n","Reconstruction accuracy for fold 5, epoch 472: 0.5822364501655102\n","Training loss for fold 5, epoch 472: 134.12880842147334\n","Validation elbo for fold 5, epoch 473: -19416.12691796963\n","Reconstruction accuracy for fold 5, epoch 473: 0.5807796195149422\n","Training loss for fold 5, epoch 473: 133.6926778977917\n","Validation elbo for fold 5, epoch 474: -19372.273313192876\n","Reconstruction accuracy for fold 5, epoch 474: 0.5812865644693375\n","Training loss for fold 5, epoch 474: 133.41185526694022\n","Validation elbo for fold 5, epoch 475: -19406.55629023715\n","Reconstruction accuracy for fold 5, epoch 475: 0.5802441798150539\n","Training loss for fold 5, epoch 475: 133.73463489163308\n","Validation elbo for fold 5, epoch 476: -19434.370428615526\n","Reconstruction accuracy for fold 5, epoch 476: 0.580461423844099\n","Training loss for fold 5, epoch 476: 134.83127680132466\n","Validation elbo for fold 5, epoch 477: -19394.73673535236\n","Reconstruction accuracy for fold 5, epoch 477: 0.5792828351259232\n","Training loss for fold 5, epoch 477: 134.2756223370952\n","Validation elbo for fold 5, epoch 478: -19388.919423766518\n","Reconstruction accuracy for fold 5, epoch 478: 0.5816075280308723\n","Training loss for fold 5, epoch 478: 133.97830249417214\n","Validation elbo for fold 5, epoch 479: -19373.376310512398\n","Reconstruction accuracy for fold 5, epoch 479: 0.5827219560742378\n","Training loss for fold 5, epoch 479: 132.67850949687343\n","Validation elbo for fold 5, epoch 480: -19379.841711971294\n","Reconstruction accuracy for fold 5, epoch 480: 0.5781249850988388\n","Training loss for fold 5, epoch 480: 132.04919070582235\n","Validation elbo for fold 5, epoch 481: -19364.220644000354\n","Reconstruction accuracy for fold 5, epoch 481: 0.5799027718603611\n","Training loss for fold 5, epoch 481: 134.06627778084047\n","Validation elbo for fold 5, epoch 482: -19383.155103754514\n","Reconstruction accuracy for fold 5, epoch 482: 0.5780818350613117\n","Training loss for fold 5, epoch 482: 133.50790737521262\n","Validation elbo for fold 5, epoch 483: -19364.163881198194\n","Reconstruction accuracy for fold 5, epoch 483: 0.5809823460876942\n","Training loss for fold 5, epoch 483: 133.4528891040433\n","Validation elbo for fold 5, epoch 484: -19413.086344128173\n","Reconstruction accuracy for fold 5, epoch 484: 0.5806577950716019\n","Training loss for fold 5, epoch 484: 133.6951563435216\n","Validation elbo for fold 5, epoch 485: -19415.33473330354\n","Reconstruction accuracy for fold 5, epoch 485: 0.5798592045903206\n","Training loss for fold 5, epoch 485: 133.07142823742282\n","Validation elbo for fold 5, epoch 486: -19367.808160932516\n","Reconstruction accuracy for fold 5, epoch 486: 0.5814013443887234\n","Training loss for fold 5, epoch 486: 132.70533112556703\n","Validation elbo for fold 5, epoch 487: -19413.371556668815\n","Reconstruction accuracy for fold 5, epoch 487: 0.5811047218739986\n","Training loss for fold 5, epoch 487: 133.55309517152847\n","Validation elbo for fold 5, epoch 488: -19347.450937943147\n","Reconstruction accuracy for fold 5, epoch 488: 0.5821826569736004\n","Training loss for fold 5, epoch 488: 133.5201082537251\n","Validation elbo for fold 5, epoch 489: -19360.479284690082\n","Reconstruction accuracy for fold 5, epoch 489: 0.5814350917935371\n","Training loss for fold 5, epoch 489: 132.5777175657211\n","Validation elbo for fold 5, epoch 490: -19424.89785258669\n","Reconstruction accuracy for fold 5, epoch 490: 0.5799517147243023\n","Training loss for fold 5, epoch 490: 132.77680169382404\n","Validation elbo for fold 5, epoch 491: -19366.322973852042\n","Reconstruction accuracy for fold 5, epoch 491: 0.5826662369072437\n","Training loss for fold 5, epoch 491: 132.4947231661889\n","Validation elbo for fold 5, epoch 492: -19378.64460215303\n","Reconstruction accuracy for fold 5, epoch 492: 0.5836653374135494\n","Training loss for fold 5, epoch 492: 133.62953272173482\n","Validation elbo for fold 5, epoch 493: -19496.32084390974\n","Reconstruction accuracy for fold 5, epoch 493: 0.5791954472661018\n","Training loss for fold 5, epoch 493: 133.4175180004489\n","Validation elbo for fold 5, epoch 494: -19372.893561126868\n","Reconstruction accuracy for fold 5, epoch 494: 0.5827994011342525\n","Training loss for fold 5, epoch 494: 133.47544430148216\n","Validation elbo for fold 5, epoch 495: -19360.12070020054\n","Reconstruction accuracy for fold 5, epoch 495: 0.5806716270744801\n","Training loss for fold 5, epoch 495: 133.05195113151305\n","Validation elbo for fold 5, epoch 496: -19433.07203873594\n","Reconstruction accuracy for fold 5, epoch 496: 0.5788011886179447\n","Training loss for fold 5, epoch 496: 134.76847174859816\n","Validation elbo for fold 5, epoch 497: -19456.356538411397\n","Reconstruction accuracy for fold 5, epoch 497: 0.5815703310072422\n","Training loss for fold 5, epoch 497: 136.04759167086692\n","Validation elbo for fold 5, epoch 498: -19359.80537136215\n","Reconstruction accuracy for fold 5, epoch 498: 0.58209428191185\n","Training loss for fold 5, epoch 498: 133.9740775323683\n","Validation elbo for fold 5, epoch 499: -19353.795142733154\n","Reconstruction accuracy for fold 5, epoch 499: 0.5834104791283607\n","Training loss for fold 5, epoch 499: 134.33445259832567\n"]}]},{"cell_type":"code","source":["MSA_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xE7n6DQ3iQz8","executionInfo":{"status":"ok","timestamp":1711051899599,"user_tz":300,"elapsed":525,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"c4f7f0f1-4f92-4afe-a836-7378b1e6fe63"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'PF00067_full'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["fig, axs = plt.subplots(5, 2, sharex = \"all\")\n","for k in range(K):\n","  axs[k,0].plot(valid_recon_accs[k+1][1:], label = \"reconstruction accuracy\", color = 'r')\n","  #plt.plot(test_loss_epoch, label = \"test\", color = 'b')\n","  #plt.ylim((140, 180))\n","  axs[k,0].set_xlabel('epoch')\n","  axs[k,0].set_ylabel(f\"Fold {k+1}\")\n","handles, labels = axs[0,0].get_legend_handles_labels()\n","fig.legend(handles, labels,loc = \"upper left\")\n","\n","for k in range(K):\n","  axs[k,1].plot([x/batch_size for x in valid_elbos[k+1]][1:], label = \"elbo\", color = 'b')\n","  #plt.plot(test_loss_epoch, label = \"test\", color = 'b')\n","  #plt.ylim((140, 180))\n","  axs[k,1].set_xlabel('epoch')\n","handles, labels = axs[0,1].get_legend_handles_labels()\n","fig.legend(handles, labels,  loc = \"upper right\")\n"],"metadata":{"id":"fKVNSGX_2kbG","colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"status":"ok","timestamp":1711051903100,"user_tz":300,"elapsed":2103,"user":{"displayName":"Mengze Tang","userId":"00338099096995044238"}},"outputId":"91a38502-2b5f-4953-c0de-0c6be838afc3"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f409011baf0>"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}