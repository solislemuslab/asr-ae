{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install Bio --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpVe3aBa2M-U","executionInfo":{"status":"ok","timestamp":1708117563078,"user_tz":300,"elapsed":16684,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"438ea8d3-ac78-4380-a8e8-d193939e05ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from Bio import SeqIO\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"gHH4o7vw2Qzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdxbGwGD1oi1","executionInfo":{"status":"ok","timestamp":1708119608288,"user_tz":300,"elapsed":989,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"c59d2a47-9c57-41d7-8d64-751c83a34a27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Data loading and parsing"],"metadata":{"id":"H9ITDfTlZ2D-"}},{"cell_type":"markdown","source":["Start by defining some useful utility functions for data parsing"],"metadata":{"id":"c8Kuxqtp9-ut"}},{"cell_type":"code","source":["def parse_fasta(file_path) -> list:\n","    \"Parse a fasta file into lists of sequences and their corresponding ids\"\n","    sequences, ids = [], []\n","    with open(file_path, 'r') as fasta_file:\n","        for record in SeqIO.parse(fasta_file, \"fasta\"):\n","            ids.append(record.id)\n","            sequences.append(record.seq)\n","    return ids, sequences\n","\n","def integer_encode(sequence: str) -> torch.tensor:\n","    \"Encode a protein sequence (string) as column vector of integers\"\n","    sequence = sequence.replace('X', '-')  # X also means missing\n","    encoding = [amino_acids.index(aa) for aa in sequence]\n","    return torch.tensor(encoding).reshape(-1, 1)\n","\n","\n","def integer_decode(int_seq: torch.tensor) -> str:\n","    \"Decode an integer encoded protein sequence back to string\"\n","    # Convert the column vector to a list\n","    encoded_list = int_seq.flatten().tolist()\n","    # Decode each integer back to the corresponding amino acid\n","    decoded_sequence = ''.join([amino_acids[i] for i in encoded_list])\n","    return decoded_sequence\n","\n","\n","def onehot_encode(sequence: str) -> torch.tensor:\n","    \"Encode a protein sequence (string) as matrix with one-hot row vectors\"\n","    sequence = sequence.replace('X', '-')  # X also means missing\n","    # Convert to column vector with character entries\n","    char_vec = np.array(list(sequence)).reshape(-1, 1)\n","    # Use global instantiated OneHotEncoder sklearn object to transform\n","    one_hot_encoded_array = onehot_encoder.transform(char_vec)\n","    return torch.tensor(one_hot_encoded_array) # return as torch tensor\n","\n","def onehot_decode(onehot_ary: torch.tensor) -> str:\n","    \"Decode a one-hot encoded sequence back to a sequence of amino acids\"\n","    char_vec = onehot_encoder.inverse_transform(onehot_ary) # column vector with character entries\n","    cs = [c[0] for c in char_vec]\n","    return ''.join(cs)"],"metadata":{"id":"yy7ZFywp9nd7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our data consists of multiple sequence alignments (MSAs), which are saved as fasta files. In particular, we have MSAs for five different \"domains\" or \"families\" of proteins. They are the result of applying the MUSCLE alignment algorithm to sequences within each domain curated from previous studies (DSRM: Dias et al. 2017, RIG-like receptor: Mukherjee et al. 2014; Pugh et al. 2016, and CARD: Korithoski et al. 2015.) We assume knowledge of the phylogeny relating the sequences within each of the domains."],"metadata":{"id":"F1fACnhW-Wd7"}},{"cell_type":"code","source":["project_folder = 'drive/MyDrive/ASR-AE'\n","train_file1 = f'{project_folder}/Training Data/card1_muscle.fasta'\n","train_file2 = f'{project_folder}/Training Data/drsm1_muscle.fasta'\n","train_file3 = f'{project_folder}/Training Data/rd1_muscle.fasta'\n","train_file4 = f'{project_folder}/drsm2_mucsle.fasta' #originally, we were going to use for validation\n","train_file5 = f'{project_folder}/drsm3_mucsle.fasta' #originally, we were going to use for testing\n","\n","# Get data for only the first MSA\n","ids, seqs = parse_fasta(train_file1)\n","seqs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZAXx78E2u4z","executionInfo":{"status":"ok","timestamp":1708031125956,"user_tz":300,"elapsed":847,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"179368e1-2fb4-44de-8458-62343fb15846"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Seq('---------------KGDPVDKIKVITK-N---FVDGFVENLLDRDV-INRRNL...---'),\n"," Seq('---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEI...---'),\n"," Seq('-----------------DPLKSIETKAT-K---MIKNIFDDLIEQDV-INSNQI...---'),\n"," Seq('-------------PLQKDSVDTLKSMAK-N---LVGGILSDFKEKNV-IDENYL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKV-LTKQEL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKV-LTKQEL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKV-LTKQEL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKV-LTKQEL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKA-LTKQEL...---'),\n"," Seq('------------------------MAGN-----RVNDFIEDLKGKKA-LTKQEL...---')]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["We will need to encode our data. Our neural network will eventually require us to work with one-hot encoded data so that each sequence becomes a $n_l \\times n_c$ matrix, where $n_l$ is the sequence length in the MSA and $n_c = 21$ is the number of distinct character (number of amino acids plus one for a gap)."],"metadata":{"id":"oaVj9rjlOvru"}},{"cell_type":"code","source":["# amino acid characters\n","amino_acids_str = '-ACDEFGHIKLMNPQRSTVWY' # \"-\" = missing\n","amino_acids = list(amino_acids_str)\n","\n","# instantiage and fit OneHotEncoder transormation object\n","onehot_encoder = OneHotEncoder(categories=[amino_acids], sparse_output=False)\n","onehot_encoder.fit(np.array(list(amino_acids_str)).reshape(-1, 1))\n","\n","# encode the first sequence in two ways\n","int_code = integer_encode(seqs[0])\n","oh_code = onehot_encode(seqs[0])\n","print(int_code.shape)\n","print(oh_code.shape)\n","\n","# check that they decode back to the same strings\n","print(integer_decode(int_code))\n","print(onehot_decode(oh_code))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b_-2zS43IBJ","executionInfo":{"status":"ok","timestamp":1708031136883,"user_tz":300,"elapsed":122,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"cad069f8-2530-4217-f4c7-a7029dd9d39e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([130, 1])\n","torch.Size([130, 21])\n","---------------KGDPVDKIKVITK-N---FVDGFVENLLDRDV-INRRNLQKLGNT----IGDIVKG--TQNLFEEFKEQ-SEK-GN---IVMV-----IG-------NPK--KQLSLKL------\n","---------------KGDPVDKIKVITK-N---FVDGFVENLLDRDV-INRRNLQKLGNT----IGDIVKG--TQNLFEEFKEQ-SEK-GN---IVMV-----IG-------NPK--KQLSLKL------\n"]}]},{"cell_type":"markdown","source":["Now we one-hot encode each sequence in the MSA and stack the $n$ matrices into a tensor."],"metadata":{"id":"1lEBeZpOY80B"}},{"cell_type":"code","source":["onehot_encoded_sequences = [onehot_encode(seq) for seq in seqs]\n","data_tensor = torch.stack(onehot_encoded_sequences)\n","data_tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NXiOW31QPnKf","executionInfo":{"status":"ok","timestamp":1708031141522,"user_tz":300,"elapsed":1119,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"c72accac-1c07-4af3-bc66-dbfb362c2428"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1273, 130, 21])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Build Dataset class"],"metadata":{"id":"ZpVBk8UnZyhi"}},{"cell_type":"code","source":["class MSA_Dataset(Dataset):\n","    '''\n","    Dataset class for multiple sequence alignment.\n","    '''\n","\n","    def __init__(self, seq_msa_binary, seq_weight, seq_keys):\n","        '''\n","        seq_msa_binary: a three dimensional tensor.\n","                        size: [num_of_sequences, length_of_msa, num_amino_acid_types]\n","        seq_weight: one dimensional tensor.\n","                    size: [num_sequences].\n","                    Weights for sequences in a MSA.\n","                    The sum of seq_weight has to be equal to 1 when training latent space models using VAE\n","        seq_keys: name of sequences in MSA\n","        '''\n","        super(MSA_Dataset).__init__()\n","        self.seq_msa_binary = seq_msa_binary.to(torch.float32) # for training\n","        self.seq_weight = seq_weight\n","        self.seq_keys = seq_keys\n","\n","    def __len__(self):\n","        assert(self.seq_msa_binary.shape[0] == len(self.seq_weight))\n","        assert(self.seq_msa_binary.shape[0] == len(self.seq_keys))\n","        return self.seq_msa_binary.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return self.seq_msa_binary[idx,:,:], self.seq_weight[idx], self.seq_keys[idx]\n","\n","n_seq = len(ids)\n","wts = torch.ones(n_seq) / n_seq\n","data = MSA_Dataset(data_tensor, wts, ids)\n","# Get a random sample\n","data[100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_CQK9KabuZM","executionInfo":{"status":"ok","timestamp":1708031145855,"user_tz":300,"elapsed":119,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"2f0c8369-cdbd-46c7-f084-337531c9ab7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.]]),\n"," tensor(0.0008),\n"," 'XP_008018881.1__Chlorocebus_sabaeus')"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["We see that a data item is a tuple containing the one-hot representation of the sequence, the weight assigned to the sequence (explained later), and the name of the sequence"],"metadata":{"id":"kZwu9Oan2I2C"}},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"ZP182gD7i_k_"}},{"cell_type":"markdown","source":["This code is adopted with a few changes from the PEVAE paper"],"metadata":{"id":"XOCX0z1i_pxI"}},{"cell_type":"code","source":["class VAE(nn.Module):\n","    def __init__(self, nl, nc=21, dim_latent_vars=10, num_hidden_units=[256, 256]):\n","        \"\"\"\n","        For now, we keep our model simple with both encoder and decoder having\n","        only fully connected layers (and the same number of them)\n","\n","        Our default is that the latent embeddings are dimension 10 and there are\n","        256 neurons in each of the hidden layers of the encoder and decoder\n","        \"\"\"\n","        super(VAE, self).__init__()\n","\n","        ## num of amino acid types\n","        self.nc = nc\n","\n","        ## length of sequences in the MSA\n","        self.nl = nl\n","\n","        ## dimension of input\n","        self.dim_input = nc * nl\n","\n","        ## dimension of latent space\n","        self.dim_latent_vars = dim_latent_vars\n","\n","        ## num of hidden neurons in encoder and decoder networks\n","        self.num_hidden_units = num_hidden_units\n","\n","        ## encoder\n","        self.encoder_linears = nn.ModuleList()\n","        self.encoder_linears.append(nn.Linear(self.dim_input, num_hidden_units[0]))\n","        for i in range(1, len(num_hidden_units)):\n","            self.encoder_linears.append(nn.Linear(num_hidden_units[i-1], num_hidden_units[i]))\n","        self.encoder_mu = nn.Linear(num_hidden_units[-1], dim_latent_vars)\n","        self.encoder_logsigma = nn.Linear(num_hidden_units[-1], dim_latent_vars)\n","\n","        ## decoder\n","        self.decoder_linears = nn.ModuleList()\n","        self.decoder_linears.append(nn.Linear(dim_latent_vars, num_hidden_units[0]))\n","        for i in range(1, len(num_hidden_units)):\n","            self.decoder_linears.append(nn.Linear(num_hidden_units[i-1], num_hidden_units[i]))\n","        self.decoder_linears.append(nn.Linear(num_hidden_units[-1], self.dim_input))\n","\n","    def encoder(self, x):\n","        '''\n","        encoder transforms x into latent space z\n","        '''\n","        # convert from matrix to vector by concatenating rows (which are one-hot vectors)\n","        h = torch.flatten(x, start_dim=1) # start_dim=1 to maintain batch dimension\n","        for T in self.encoder_linears:\n","            h = T(h)\n","            h = F.relu(h)\n","        mu = self.encoder_mu(h)\n","        sigma = torch.exp(self.encoder_logsigma(h))\n","        return mu, sigma\n","\n","    def decoder(self, z):\n","        '''\n","        decoder transforms latent space z into p, which is the probability  of x being 1.\n","        '''\n","        h = z\n","        for i in range(len(self.decoder_linears)-1):\n","            h = self.decoder_linears[i](h)\n","            h = F.relu(h)\n","        h = self.decoder_linears[-1](h) #Should now have dimension nc*nl\n","\n","        fixed_shape = tuple(h.shape[0:-1])\n","        h = torch.unsqueeze(h, -1)\n","        h = torch.reshape(h, fixed_shape + (-1, self.nc))\n","        log_p = F.log_softmax(h, dim = -1)\n","        #log_p = torch.reshape(log_p, fixed_shape + (-1,))\n","\n","        return log_p\n","\n","    def compute_weighted_elbo(self, x, weight):\n","        ## sample z from q(z|x)\n","        mu, sigma = self.encoder(x)\n","        eps = torch.randn_like(sigma)\n","        z = mu + sigma*eps\n","\n","        ## compute log p(x|z)\n","        log_p = self.decoder(z)\n","        log_PxGz = torch.sum(x*log_p, -1)\n","\n","        ## compute elbo\n","        elbo = log_PxGz - torch.sum(0.5*(sigma**2 + mu**2 - 2*torch.log(sigma) - 1), -1)\n","        weight = weight / torch.sum(weight)\n","        elbo = torch.sum(elbo*weight)\n","\n","        return elbo\n","\n","    def compute_elbo_with_multiple_samples(self, x, num_samples):\n","        '''\n","        Evidence lower bound is an lower bound of log P(x). Although it is a lower\n","        bound, we can use elbo to approximate log P(x).\n","        Using multiple samples to calculate the elbo makes it be a better approximation\n","        of log P(x).\n","        '''\n","\n","        with torch.no_grad():\n","            x = x.expand(num_samples, x.shape[0], x.shape[1])\n","            mu, sigma = self.encoder(x)\n","            eps = torch.randn_like(mu)\n","            z = mu + sigma * eps\n","            log_Pz = torch.sum(-0.5*z**2 - 0.5*torch.log(2*z.new_tensor(np.pi)), -1)\n","            log_p = self.decoder(z)\n","            log_PxGz = torch.sum(x*log_p, -1)\n","            log_Pxz = log_Pz + log_PxGz\n","\n","            log_QzGx = torch.sum(-0.5*(eps)**2 -\n","                                 0.5*torch.log(2*z.new_tensor(np.pi))\n","                                 - torch.log(sigma), -1)\n","            log_weight = (log_Pxz - log_QzGx).detach().data\n","            log_weight = log_weight.double()\n","            log_weight_max = torch.max(log_weight, 0)[0]\n","            log_weight = log_weight - log_weight_max\n","            weight = torch.exp(log_weight)\n","            elbo = torch.log(torch.mean(weight, 0)) + log_weight_max\n","            return elbo"],"metadata":{"id":"WkGJuspMi7WM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dimensions of one-hot encoding\n","nl = data_tensor.shape[1]\n","nc = data_tensor.shape[2]\n","# For architecture hyper-parameters, we rely on the defaults in the class definition\n","model = VAE(nl = nl, nc = nc)"],"metadata":{"id":"5bRNCyUW1ZCW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's check that our model processes data the way we want it to"],"metadata":{"id":"52W7UtKW_YFn"}},{"cell_type":"code","source":["#Encoding\n","one_hot_ary = data[100][0]\n","batch_one_hot_ary = torch.unsqueeze(one_hot_ary, 0)\n","latent_parameters = model.encoder(batch_one_hot_ary)\n","print(f\"Mean and variance of latent vector: {latent_parameters}\")\n","#Decoding\n","mn_z = latent_parameters[0]\n","recon_log_probs = model.decoder(mn_z)\n","print(f\"Decoded output has shape {recon_log_probs.shape} and is given by\")\n","print(recon_log_probs)\n","probs = torch.exp(recon_log_probs.squeeze())\n","print(\"The probability for each amino acid in each position is\")\n","print(probs)\n","print(\"Rows should sum to 1: \")\n","print(torch.sum(probs, dim = 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8sUpcEKJ6gXL","executionInfo":{"status":"ok","timestamp":1708031252317,"user_tz":300,"elapsed":114,"user":{"displayName":"Evan Gorstein","userId":"01543935332825698741"}},"outputId":"4c60f648-1b3a-4ada-c5ed-865019cd4d21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean and variance of latent vector: (tensor([[-0.0189,  0.0212, -0.0329,  0.0069, -0.0412,  0.0215,  0.0807,  0.0102,\n","         -0.0417, -0.0510]], grad_fn=<AddmmBackward0>), tensor([[0.9599, 1.0618, 1.0214, 0.9816, 0.9903, 1.0196, 0.9594, 1.0351, 1.0125,\n","         0.9293]], grad_fn=<ExpBackward0>))\n","Decoded output has shape torch.Size([1, 130, 21]) and is given by\n","tensor([[[-3.1071, -2.9985, -2.9959,  ..., -3.0843, -3.0167, -3.0363],\n","         [-3.0460, -3.0296, -3.0044,  ..., -3.0338, -3.1036, -3.0152],\n","         [-3.0653, -2.9674, -3.0949,  ..., -3.0450, -3.0645, -3.1256],\n","         ...,\n","         [-3.1468, -3.0576, -3.0766,  ..., -3.0858, -3.0362, -3.0575],\n","         [-3.0835, -3.0468, -2.9983,  ..., -3.0853, -3.0078, -2.9356],\n","         [-3.1057, -3.0256, -3.1402,  ..., -3.0402, -3.1947, -3.0470]]],\n","       grad_fn=<LogSoftmaxBackward0>)\n","The probability for each amino acid in each position is\n","tensor([[0.0447, 0.0499, 0.0500,  ..., 0.0458, 0.0490, 0.0480],\n","        [0.0475, 0.0483, 0.0496,  ..., 0.0481, 0.0449, 0.0490],\n","        [0.0466, 0.0514, 0.0453,  ..., 0.0476, 0.0467, 0.0439],\n","        ...,\n","        [0.0430, 0.0470, 0.0461,  ..., 0.0457, 0.0480, 0.0470],\n","        [0.0458, 0.0475, 0.0499,  ..., 0.0457, 0.0494, 0.0531],\n","        [0.0448, 0.0485, 0.0433,  ..., 0.0478, 0.0410, 0.0475]],\n","       grad_fn=<ExpBackward0>)\n","Rows should sum to 1: \n","tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"]}]},{"cell_type":"markdown","source":["The decoder outputs log probabilities for amino acids with the same dimension as input of the encoder"],"metadata":{"id":"zX7XVeszDDvp"}},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","# Training hyperparameters\n","num_epochs = 30\n","learning_rate = 1e-3\n","batch_size = 128\n","\n","data_loader = DataLoader(data, batch_size = batch_size, shuffle = True)"],"metadata":{"id":"eGC6MDgl2ztW"},"execution_count":null,"outputs":[]}]}