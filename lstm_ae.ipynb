{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWMsLr7KHeHp",
        "outputId": "1f72d7cf-d05c-40ef-c751-21ee99648da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras==3.0.0 --upgrade --quiet\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roHKl4tqTE3Y",
        "outputId": "39878f53-f1b8-4dd0-90a6-3548782dcdb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An LSTM Autoencoder"
      ],
      "metadata": {
        "id": "dKPsBBQWqwb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "n_in = 9\n",
        "# learning_rate = 1e-3\n",
        "num_epoch = 300"
      ],
      "metadata": {
        "id": "b8wIjATlwG3L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMAE(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm1 = keras.layers.LSTM(100, activation='relu',\n",
        "                                       input_shape=(n_in,1), return_sequences=True)\n",
        "        # Can we only use return_sequence in the last LSTM encoder layer\n",
        "        # and donâ€™t use RepeatVector before the first LSTM decoder layer?\n",
        "\n",
        "        # Maybe we will still use RepeatVector because we are actually\n",
        "        # encoding the very vector.\n",
        "\n",
        "        # self.repeatvector = keras.layers.RepeatVector(n_in)\n",
        "        self.lstm2 = keras.layers.LSTM(100, activation='relu',\n",
        "                                       return_sequences=True)\n",
        "        self.compress = keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "\n",
        "    def encode(self, x):\n",
        "        # return self.repeatvector(self.lstm1(x))\n",
        "        return self.lstm1(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.compress(self.lstm2(z))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        return self.decode(self.encode(x))"
      ],
      "metadata": {
        "id": "56Z8-576TcUW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "\n",
        "sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "sequence = sequence.reshape((1, n_in, 1))\n",
        "\n",
        "model = LSTMAE()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdCsbChcuc0F",
        "outputId": "d171d0d5-a9a1-49de-df71-e7656a2efff2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(sequence, sequence, epochs=num_epoch, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSCrwaEewt95",
        "outputId": "f32ed09b-02b8-4710-9b6b-65420e69feb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae37f5f1ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate recreation\n",
        "yhat = model.predict(sequence, verbose=0)\n",
        "print(yhat[0,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBN8LvU4zZT-",
        "outputId": "265f37b1-e1e9-4955-9c18-469716793ef0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.11402848 0.20080328 0.29531628 0.39493078 0.49756372 0.60109377\n",
            " 0.70345855 0.8027534  0.8971434 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An LSTM Autoencoder with maksing"
      ],
      "metadata": {
        "id": "rIiL7Pluiv0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLSTMAE(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm1 = keras.layers.LSTM(100, activation='relu',\n",
        "                                       input_shape=(n_in,1))\n",
        "        # The vector we repeat here is the encoding\n",
        "        self.repeatvector = keras.layers.RepeatVector(n_in)\n",
        "        self.lstm2 = keras.layers.LSTM(100, activation='relu',\n",
        "                                       return_sequences=True)\n",
        "        self.compress = keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = keras.layers.Masking(mask_value=0.0)(x)\n",
        "        return self.repeatvector(self.lstm1(x))\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.compress(self.lstm2(z))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        return self.decode(self.encode(x))"
      ],
      "metadata": {
        "id": "sYuDQ0F7i2Lu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLSTMAE()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(sequence, sequence, epochs=num_epoch, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_9au9byj_nI",
        "outputId": "3d03e24a-6b86-4477-c8cd-5fa45c27953d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae37f4e7cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate recreation\n",
        "yhat = model.predict(sequence, verbose=0)\n",
        "print(yhat[0,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7HOWYD5ltZC",
        "outputId": "540fa803-8f42-4b3e-97fc-3983f3221b40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10634747 0.20153731 0.2991102  0.39874396 0.49926123 0.6000028\n",
            " 0.70046484 0.80029273 0.8992775 ]\n"
          ]
        }
      ]
    }
  ]
}