{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mLxnQ-qHr",
        "outputId": "6e6859b5-3f3d-4a9b-c1bf-48bfd49e199f"
      },
      "id": "3i2mLxnQ-qHr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install Bio --quiet\n",
        "!pip install keras==3.0.0 --upgrade --quiet"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.275033900Z",
          "start_time": "2023-10-29T05:21:04.751989100Z"
        },
        "id": "1373a93c978d2fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf0dea2-61cb-4734-8689-c03df0059c21"
      },
      "id": "1373a93c978d2fb5"
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import keras\n",
        "from keras import backend as K, layers, activations\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "SQQNsD3Dfz7z"
      },
      "id": "SQQNsD3Dfz7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nphKeyspBbHX",
        "outputId": "b42f5ac0-e02b-4f09-c8e1-4404696d184f"
      },
      "id": "nphKeyspBbHX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9Mcj8HqXRo",
        "outputId": "5d92514c-36bb-4f2b-ebc1-38e1b0a3673c"
      },
      "id": "vR9Mcj8HqXRo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "nTavCEWq6jXX"
      },
      "id": "nTavCEWq6jXX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "du6GuldEgp52"
      },
      "id": "du6GuldEgp52"
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "folder_path = 'drive/MyDrive/ae_training'\n",
        "file_name1 = f'{folder_path}/card1_1273x130.fasta'\n",
        "file_name2 = f'{folder_path}/drsm1_1376x177.fasta'\n",
        "file_name3 = f'{folder_path}/rd1_935x221.fasta'\n",
        "file_name4 = f'{folder_path}/drsm3_718x103_testing.fasta'\n",
        "\n",
        "amino_acids_str = ' ACDEFGHIKLMNPQRSTVWY-'\n",
        "amino_acids = [' ', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "               'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
        "\n",
        "onehot_encoder = OneHotEncoder(categories=[amino_acids])\n",
        "onehot_encoder.fit(np.array(list(amino_acids_str)).reshape(-1, 1))\n",
        "\n",
        "# Hyperparameters\n",
        "max_len = 221\n",
        "num_epochs = 30\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "5Yjt2lUQwFGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8167c24a-d990-4285-f10f-cde169a0d459"
      },
      "id": "5Yjt2lUQwFGV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def parse_fasta(file_path) -> list:\n",
        "    \"Parse a fasta file into an array of Seq\"\n",
        "    sequences = []\n",
        "    with open(file_path, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(record.seq)\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def integer_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of integers\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    encoding = [amino_acids.index(aa) for aa in sequence]\n",
        "    # Pad the sequence to the specified maximum length\n",
        "    if len(encoding) < max_length:\n",
        "        encoding += [0] * (max_length - len(encoding))\n",
        "    return torch.tensor(encoding).reshape(-1, 1)\n",
        "\n",
        "\n",
        "def integer_decode(int_seq) -> str:\n",
        "    \"Decode an integer encoded sequence back to a sequence of amino acids\"\n",
        "    # Convert the torch tensor to a list of integers\n",
        "    encoded_list = int_seq.flatten().tolist()\n",
        "    # Decode each integer back to the corresponding amino acid\n",
        "    decoded_sequence = ''.join([amino_acids[i] for i in encoded_list])\n",
        "    return decoded_sequence\n",
        "\n",
        "\n",
        "def onehot_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of one-hot vectors\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    # Pad the sequence with whitespaces\n",
        "    padding = ' ' * (max_length - len(sequence))\n",
        "    sequence += padding\n",
        "    protein_sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
        "    one_hot_encoded_sequence = onehot_encoder.transform(protein_sequence_array)\n",
        "    one_hot_encoded_array = one_hot_encoded_sequence.toarray()\n",
        "    return torch.tensor(one_hot_encoded_array)  # Whitespace is [1,0,...,0] for now\n",
        "\n",
        "\n",
        "def onehot_decode(onehot_seq: torch.tensor) -> str:\n",
        "    \"Decode a one-hot encoded sequence back to a sequence of amino acids\"\n",
        "    original_seq = onehot_encoder.inverse_transform(onehot_seq)\n",
        "    s = [''.join(c) for c in original_seq]\n",
        "    return ''.join(s)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.319409200Z",
          "start_time": "2023-10-29T05:21:08.296000400Z"
        },
        "id": "2525961040f75438"
      },
      "id": "2525961040f75438"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:09.164320800Z",
          "start_time": "2023-10-29T05:21:08.311283200Z"
        },
        "id": "55bb307a28da7571",
        "outputId": "5930d3f5-3088-4a18-afa7-74ae1d5bdd93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55bb307a28da7571"
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]  # onehot encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIVmYtGNyIf",
        "outputId": "dffbf4e8-9ae4-4f2d-e0f1-53e1d61149ed"
      },
      "id": "NaIVmYtGNyIf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        ...,\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yfhfB6K4PVIq",
        "outputId": "2b2c82c9-b6f1-4101-ceaa-1773a04ceb8b"
      },
      "id": "yfhfB6K4PVIq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "int_encoded_sequences = [integer_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(int_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPM4Fsb3HDIO",
        "outputId": "123aea55-51b9-48fa-bfa8-675ae402402f"
      },
      "id": "IPM4Fsb3HDIO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integer_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "woxfrJVxY9Va",
        "outputId": "0226265a-984f-482c-b37d-6549073f1ef0"
      },
      "id": "woxfrJVxY9Va",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences1 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "sequences2 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "sequences3 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "\n",
        "data = torch.cat((sequences1, sequences2, sequences3))\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPbKvpm_iShN",
        "outputId": "35290033-6b77-4df8-ea77-1d99be856db5"
      },
      "id": "vPbKvpm_iShN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3584, 221, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataloaders"
      ],
      "metadata": {
        "id": "ruWPTFpWgiKO"
      },
      "id": "ruWPTFpWgiKO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the training dataset as in PyTorch `DataLoader`.\n",
        "\n",
        "Ideally, the model (as `keras.Model`) should be instantiated as a PyTorch `Module` in PyTorch backend."
      ],
      "metadata": {
        "id": "o8_fLUlbjbEn"
      },
      "id": "o8_fLUlbjbEn"
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.encoding = onehot_encode\n",
        "\n",
        "        sequences1 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "        sequences2 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "        sequences3 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "        self.data = torch.cat((sequences1, sequences2, sequences3))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name4)])[:,:,1:]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "ShVn_fXNTFy1"
      },
      "id": "ShVn_fXNTFy1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch Datasets\n",
        "train_dataset = TrainDataset()\n",
        "val_dataset = TestDataset()\n",
        "\n",
        "# Create DataLoaders for the Datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c-3Hl4NElUe4"
      },
      "id": "c-3Hl4NElUe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the LSTM Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "ItsoiY3OY1Ve"
      },
      "id": "ItsoiY3OY1Ve"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rewrite the code to build the model: **Protein sequence LSTM Variational AutoEncoder (VAE)**\n",
        "\n",
        "Write it in Keras 3 as subclass of `keras.Model` to handle variable length sequences (and missing characters).\n",
        "\n",
        "Sources:\n",
        "- VAE in Keras 3: https://keras.io/examples/generative/vae/\n",
        "- LSTM Autoencoder: https://machinelearningmastery.com/lstm-autoencoders/\n",
        "- Variable length: https://machinelearningmastery.com/handle-missing-timesteps-sequence-prediction-problems-python/\n"
      ],
      "metadata": {
        "id": "4AKZbyCahwZ6"
      },
      "id": "4AKZbyCahwZ6"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KZcoro0Zu9-A"
      },
      "id": "KZcoro0Zu9-A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling layer"
      ],
      "metadata": {
        "id": "AZq4z0JnvBa2"
      },
      "id": "AZq4z0JnvBa2"
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"Uses (z_mean, z_log_var) to sample z, the vector encoding a sequence.\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = keras.ops.shape(z_mean)[0]\n",
        "        dim = keras.ops.shape(z_mean)[1]\n",
        "        epsilon = keras.random.normal(shape=(batch, dim))\n",
        "        return z_mean + keras.ops.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "F2UKmYnRqiW0"
      },
      "id": "F2UKmYnRqiW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "K-OeJWfDvX-t"
      },
      "id": "K-OeJWfDvX-t"
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64\n",
        "# input_shape = (max_len, 1)  # (max_len, 1) for integer encoding\n",
        "input_shape = (max_len, 21)  # (max_len, 21) for one-hot encoding\n",
        "\n",
        "encoder_inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Masking(mask_value=0.0)(encoder_inputs)\n",
        "z_mean = layers.LSTM(latent_dim, activation='relu',\n",
        "                     input_shape=input_shape, name=\"z_mean\")(x)\n",
        "z_log_var = layers.LSTM(latent_dim, activation='relu',\n",
        "                        input_shape=input_shape, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "wwthT3fRvcoK",
        "outputId": "89a4f25d-8b7b-46f0-c609-86c09f1282d9"
      },
      "id": "wwthT3fRvcoK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (\u001b[38;5;33mAny\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mLSTM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (\u001b[38;5;33mSampling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n",
              "│                           │                        │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n",
              "│                           │                        │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "KRsFMEjV2cwN"
      },
      "id": "KRsFMEjV2cwN"
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.RepeatVector(max_len)(latent_inputs)\n",
        "x = layers.LSTM(latent_dim, activation='relu', return_sequences=True)(x)\n",
        "x = layers.TimeDistributed(layers.Dense(21))(x)\n",
        "decoder_outputs = layers.Softmax()(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "RyVG3dRg2ejP",
        "outputId": "fb9c181d-3cc8-422e-da71-64af51ce4c9e"
      },
      "id": "RyVG3dRg2ejP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │      \u001b[38;5;34m33,024\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)               │       \u001b[38;5;34m1,365\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │      <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,365</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,389\u001b[0m (134.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,389</span> (134.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,389\u001b[0m (134.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,389</span> (134.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Model"
      ],
      "metadata": {
        "id": "hFntz4ZJ5trY"
      },
      "id": "hFntz4ZJ5trY"
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]"
      ],
      "metadata": {
        "id": "mob3gBeT5BMS"
      },
      "id": "mob3gBeT5BMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LJ67OFHcMxia"
      },
      "id": "LJ67OFHcMxia"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder, decoder).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    for i, x in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        x = x.to(device)\n",
        "        z_mean, z_log_var, z = model.encoder(x)\n",
        "        reconstruction = model.decoder(z)\n",
        "\n",
        "        # Compute reconstruction loss and kl divergence\n",
        "        # x = activations.sigmoid(x / 4)\n",
        "        # reconstruction = activations.sigmoid(reconstruction / 4)\n",
        "        # print(reconstruction)\n",
        "\n",
        "        reconstruction_loss = keras.ops.mean(\n",
        "            keras.ops.sum(\n",
        "                keras.losses.binary_crossentropy(x, reconstruction),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "        kl_loss = -0.5 * (1 + z_log_var - keras.ops.square(z_mean) - keras.ops.exp(z_log_var))\n",
        "        kl_loss = keras.ops.mean(keras.ops.sum(kl_loss, axis=1))\n",
        "\n",
        "        # Backprop and optimize\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_dataloader), reconstruction_loss.item(), kl_loss.item()))\n",
        "\n",
        "model.save_weights(f'{folder_path}/vae.weights.h5', overwrite=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu-aFtsi_aR8",
        "outputId": "850241b3-f4fe-4c5c-b3c1-189c80880d72"
      },
      "id": "yu-aFtsi_aR8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/30], Step [10/28], Reconst Loss: 45.0928, KL Div: 0.1838\n",
            "Epoch[1/30], Step [20/28], Reconst Loss: 49.0607, KL Div: 0.1842\n",
            "Epoch[2/30], Step [10/28], Reconst Loss: 44.0683, KL Div: 0.1944\n",
            "Epoch[2/30], Step [20/28], Reconst Loss: 45.3819, KL Div: 0.1839\n",
            "Epoch[3/30], Step [10/28], Reconst Loss: 51.4112, KL Div: 0.1822\n",
            "Epoch[3/30], Step [20/28], Reconst Loss: 44.3656, KL Div: 0.1839\n",
            "Epoch[4/30], Step [10/28], Reconst Loss: 37.8212, KL Div: 0.1877\n",
            "Epoch[4/30], Step [20/28], Reconst Loss: 42.0968, KL Div: 0.1845\n",
            "Epoch[5/30], Step [10/28], Reconst Loss: 40.2617, KL Div: 0.1882\n",
            "Epoch[5/30], Step [20/28], Reconst Loss: 37.6822, KL Div: 0.1903\n",
            "Epoch[6/30], Step [10/28], Reconst Loss: 40.3969, KL Div: 0.1884\n",
            "Epoch[6/30], Step [20/28], Reconst Loss: 31.4183, KL Div: 0.1861\n",
            "Epoch[7/30], Step [10/28], Reconst Loss: 34.8602, KL Div: 0.1828\n",
            "Epoch[7/30], Step [20/28], Reconst Loss: 34.3044, KL Div: 0.1880\n",
            "Epoch[8/30], Step [10/28], Reconst Loss: 33.1734, KL Div: 0.1888\n",
            "Epoch[8/30], Step [20/28], Reconst Loss: 32.2972, KL Div: 0.1872\n",
            "Epoch[9/30], Step [10/28], Reconst Loss: 35.7318, KL Div: 0.1941\n",
            "Epoch[9/30], Step [20/28], Reconst Loss: 37.1929, KL Div: 0.1869\n",
            "Epoch[10/30], Step [10/28], Reconst Loss: 31.9796, KL Div: 0.1918\n",
            "Epoch[10/30], Step [20/28], Reconst Loss: 33.2603, KL Div: 0.1859\n",
            "Epoch[11/30], Step [10/28], Reconst Loss: 34.2906, KL Div: 0.1903\n",
            "Epoch[11/30], Step [20/28], Reconst Loss: 31.7163, KL Div: 0.1860\n",
            "Epoch[12/30], Step [10/28], Reconst Loss: 33.1211, KL Div: 0.1839\n",
            "Epoch[12/30], Step [20/28], Reconst Loss: 35.7853, KL Div: 0.1871\n",
            "Epoch[13/30], Step [10/28], Reconst Loss: 32.5275, KL Div: 0.1902\n",
            "Epoch[13/30], Step [20/28], Reconst Loss: 31.2647, KL Div: 0.1849\n",
            "Epoch[14/30], Step [10/28], Reconst Loss: 35.2057, KL Div: 0.1924\n",
            "Epoch[14/30], Step [20/28], Reconst Loss: 34.1037, KL Div: 0.1832\n",
            "Epoch[15/30], Step [10/28], Reconst Loss: 29.9897, KL Div: 0.1864\n",
            "Epoch[15/30], Step [20/28], Reconst Loss: 30.5331, KL Div: 0.1889\n",
            "Epoch[16/30], Step [10/28], Reconst Loss: 34.9482, KL Div: 0.1847\n",
            "Epoch[16/30], Step [20/28], Reconst Loss: 32.7977, KL Div: 0.1684\n",
            "Epoch[17/30], Step [10/28], Reconst Loss: 36.4960, KL Div: 0.1578\n",
            "Epoch[17/30], Step [20/28], Reconst Loss: 30.8969, KL Div: 0.1652\n",
            "Epoch[18/30], Step [10/28], Reconst Loss: 31.4150, KL Div: 0.1622\n",
            "Epoch[18/30], Step [20/28], Reconst Loss: 35.1095, KL Div: 0.1569\n",
            "Epoch[19/30], Step [10/28], Reconst Loss: 32.9678, KL Div: 0.1622\n",
            "Epoch[19/30], Step [20/28], Reconst Loss: 32.4674, KL Div: 0.1601\n",
            "Epoch[20/30], Step [10/28], Reconst Loss: 34.6685, KL Div: 0.1602\n",
            "Epoch[20/30], Step [20/28], Reconst Loss: 32.8733, KL Div: 0.1610\n",
            "Epoch[21/30], Step [10/28], Reconst Loss: 30.9103, KL Div: 0.1622\n",
            "Epoch[21/30], Step [20/28], Reconst Loss: 34.6863, KL Div: 0.1598\n",
            "Epoch[22/30], Step [10/28], Reconst Loss: 30.6930, KL Div: 0.1632\n",
            "Epoch[22/30], Step [20/28], Reconst Loss: 32.4108, KL Div: 0.1636\n",
            "Epoch[23/30], Step [10/28], Reconst Loss: 34.8157, KL Div: 0.1674\n",
            "Epoch[23/30], Step [20/28], Reconst Loss: 31.2139, KL Div: 0.1575\n",
            "Epoch[24/30], Step [10/28], Reconst Loss: 32.2293, KL Div: 0.1558\n",
            "Epoch[24/30], Step [20/28], Reconst Loss: 34.2274, KL Div: 0.1620\n",
            "Epoch[25/30], Step [10/28], Reconst Loss: 30.5290, KL Div: 0.1612\n",
            "Epoch[25/30], Step [20/28], Reconst Loss: 31.0566, KL Div: 0.1640\n",
            "Epoch[26/30], Step [10/28], Reconst Loss: 32.4875, KL Div: 0.1604\n",
            "Epoch[26/30], Step [20/28], Reconst Loss: 32.3244, KL Div: 0.1588\n",
            "Epoch[27/30], Step [10/28], Reconst Loss: 31.6330, KL Div: 0.1549\n",
            "Epoch[27/30], Step [20/28], Reconst Loss: 29.3562, KL Div: 0.1670\n",
            "Epoch[28/30], Step [10/28], Reconst Loss: 30.3998, KL Div: 0.1629\n",
            "Epoch[28/30], Step [20/28], Reconst Loss: 33.4915, KL Div: 0.1590\n",
            "Epoch[29/30], Step [10/28], Reconst Loss: 30.4143, KL Div: 0.1601\n",
            "Epoch[29/30], Step [20/28], Reconst Loss: 30.0693, KL Div: 0.1623\n",
            "Epoch[30/30], Step [10/28], Reconst Loss: 31.5667, KL Div: 0.1672\n",
            "Epoch[30/30], Step [20/28], Reconst Loss: 32.9758, KL Div: 0.1587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "BbcsXjoPfyZl"
      },
      "id": "BbcsXjoPfyZl"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder, decoder).to(device)\n",
        "model.load_weights(f'{folder_path}/vae.weights.h5', skip_mismatch=False)"
      ],
      "metadata": {
        "id": "CcJBt_aNhlEG"
      },
      "id": "CcJBt_aNhlEG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for i, x in enumerate(val_dataloader):\n",
        "        x = x.to(device)\n",
        "        z_mean, z_log_var, z = model.encoder(x)\n",
        "        reconstruction = model.decoder(z)\n",
        "\n",
        "        reconstruction_loss = keras.ops.mean(\n",
        "            keras.ops.sum(\n",
        "                keras.losses.binary_crossentropy(x, reconstruction),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print (\"Step [{}/{}], Reconst Loss: {:.4f}\"\n",
        "                .format(i+1, len(val_dataloader), reconstruction_loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7D6GrP3f4go",
        "outputId": "07f94ae5-d916-4a02-c6dd-e87ce16f5f61"
      },
      "id": "S7D6GrP3f4go",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [1/6], Reconst Loss: 25.7242\n",
            "Step [2/6], Reconst Loss: 25.7049\n",
            "Step [3/6], Reconst Loss: 25.6525\n",
            "Step [4/6], Reconst Loss: 25.5412\n",
            "Step [5/6], Reconst Loss: 24.6944\n",
            "Step [6/6], Reconst Loss: 25.0702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name4)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWiuSxtzhC61",
        "outputId": "d7f3a394-ff93-4c96-eb82-32c71ea24772"
      },
      "id": "DWiuSxtzhC61",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([718, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSeecvE9i8jX",
        "outputId": "b6e43dcd-bbf2-474b-ff13-b2be1ec94ac5"
      },
      "id": "BSeecvE9i8jX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin = onehot_decode(data[0])\n",
        "origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UdwK0OMRjC_l",
        "outputId": "36ca31bb-dc01-4482-9463-00a1dfd331ee"
      },
      "id": "UdwK0OMRjC_l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DHLNLLCAMCEQKGWA-YNFTEPAQPE--NA---------ES-V-D-KMVFLCLPEDQVFGGIGKDV-ESAKWHAAHVA--------LMYFHL----------                                                                                                                      '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[0][:,1:].reshape(1, 221, 21)\n",
        "z_mean, z_log_var, z = model.encoder(x)\n",
        "reconst = model.decoder(z)\n",
        "reconst.reshape(221, 21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p6eYc1XjZuD",
        "outputId": "1e1c3907-cc37-4328-a014-d17fdb1257ab"
      },
      "id": "_p6eYc1XjZuD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0470, 0.0319, 0.0438,  ..., 0.0298, 0.0436, 0.2209],\n",
              "        [0.0452, 0.0252, 0.0382,  ..., 0.0189, 0.0345, 0.2919],\n",
              "        [0.0430, 0.0215, 0.0348,  ..., 0.0135, 0.0288, 0.3406],\n",
              "        ...,\n",
              "        [0.0308, 0.0100, 0.0246,  ..., 0.0020, 0.0147, 0.5118],\n",
              "        [0.0308, 0.0100, 0.0246,  ..., 0.0020, 0.0147, 0.5118],\n",
              "        [0.0308, 0.0100, 0.0246,  ..., 0.0020, 0.0147, 0.5118]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconst.detach().numpy()\n",
        "reconst = keras.utils.to_categorical(np.argmax(reconst.detach().numpy(), axis=2), 21)\n",
        "reconst = reconst.reshape(221, 21)[:103]\n",
        "reconst = np.hstack((np.zeros((reconst.shape[0], 1)), reconst))\n",
        "reconst = onehot_decode(reconst)"
      ],
      "metadata": {
        "id": "DEin5btHlP7_"
      },
      "id": "DEin5btHlP7_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A8bUqDH45xM1",
        "outputId": "4bac0f70-c3f9-4d14-9a58-ee8058e33bf6"
      },
      "id": "A8bUqDH45xM1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-------------------------------------------------------------------------------------------------------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}