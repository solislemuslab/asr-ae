{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mLxnQ-qHr",
        "outputId": "6254024f-f7a0-4f3b-f78d-1e5d6169bf9a"
      },
      "id": "3i2mLxnQ-qHr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install Bio --quiet\n",
        "!pip install keras==3.0.0 --upgrade --quiet"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.275033900Z",
          "start_time": "2023-10-29T05:21:04.751989100Z"
        },
        "id": "1373a93c978d2fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1180cd1e-996f-4636-b536-22a695e1029d"
      },
      "id": "1373a93c978d2fb5"
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "SQQNsD3Dfz7z"
      },
      "id": "SQQNsD3Dfz7z",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nphKeyspBbHX",
        "outputId": "c2e1943c-fe5a-4098-f79a-c72f056d0764"
      },
      "id": "nphKeyspBbHX",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9Mcj8HqXRo",
        "outputId": "5beb199a-a10f-47f2-c8fb-8fddf3d73712"
      },
      "id": "vR9Mcj8HqXRo",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "nTavCEWq6jXX"
      },
      "id": "nTavCEWq6jXX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "du6GuldEgp52"
      },
      "id": "du6GuldEgp52"
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "folder_path = 'drive/MyDrive/ae_training'\n",
        "amino_acids_str = ' ACDEFGHIKLMNPQRSTVWY-'\n",
        "amino_acids = [' ', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "               'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
        "onehot_encoder = OneHotEncoder(categories=[amino_acids])\n",
        "onehot_encoder.fit(np.array(list(amino_acids_str)).reshape(-1, 1))\n",
        "\n",
        "# Hyperparameters\n",
        "max_len = 221"
      ],
      "metadata": {
        "id": "5Yjt2lUQwFGV"
      },
      "id": "5Yjt2lUQwFGV",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def parse_fasta(file_path) -> list:\n",
        "    \"Parse a fasta file into an array of Seq\"\n",
        "    sequences = []\n",
        "    with open(file_path, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(record.seq)\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def integer_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of integers\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    encoding = [amino_acids.index(aa) for aa in sequence]\n",
        "    # Pad the sequence to the specified maximum length\n",
        "    if len(encoding) < max_length:\n",
        "        encoding += [0] * (max_length - len(encoding))\n",
        "    return torch.tensor(encoding).reshape(-1, 1)\n",
        "\n",
        "\n",
        "def integer_decode(int_seq) -> str:\n",
        "    \"Decode an integer encoded sequence back to a sequence of amino acids\"\n",
        "    # Convert the torch tensor to a list of integers\n",
        "    encoded_list = int_seq.flatten().tolist()\n",
        "\n",
        "    # Decode each integer back to the corresponding amino acid\n",
        "    decoded_sequence = ''.join([amino_acids[i] for i in encoded_list])\n",
        "\n",
        "    return decoded_sequence\n",
        "\n",
        "\n",
        "def onehot_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of one-hot vectors\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    # Pad the sequence with whitespaces\n",
        "    padding = ' ' * (max_length - len(sequence))\n",
        "    sequence += padding\n",
        "    protein_sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
        "    one_hot_encoded_sequence = onehot_encoder.transform(protein_sequence_array)\n",
        "    one_hot_encoded_array = one_hot_encoded_sequence.toarray()\n",
        "    return torch.tensor(one_hot_encoded_array)\n",
        "\n",
        "\n",
        "def onehot_decode(onehot_seq: torch.tensor) -> str:\n",
        "    \"Decode a one-hot encoded sequence back to a sequence of amino acids\"\n",
        "    original_seq = onehot_encoder.inverse_transform(onehot_seq)\n",
        "    s = [''.join(c) for c in original_seq]\n",
        "    return ''.join(s)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.319409200Z",
          "start_time": "2023-10-29T05:21:08.296000400Z"
        },
        "id": "2525961040f75438"
      },
      "id": "2525961040f75438"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "file_name = f'{folder_path}/card1_1273x130.fasta'\n",
        "\n",
        "sequences = parse_fasta(file_name)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape\n",
        "# data[1]\n",
        "# sequences[0]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:09.164320800Z",
          "start_time": "2023-10-29T05:21:08.311283200Z"
        },
        "id": "55bb307a28da7571",
        "outputId": "55bb97fa-d949-493f-f27a-8cbf75a714b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55bb307a28da7571"
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIVmYtGNyIf",
        "outputId": "79209609-eff0-49dc-bae0-c271555c6fc8"
      },
      "id": "NaIVmYtGNyIf",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        ...,\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yfhfB6K4PVIq",
        "outputId": "6c8b95b4-d31b-4832-8486-7242bc4e03ea"
      },
      "id": "yfhfB6K4PVIq",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name)\n",
        "int_encoded_sequences = [integer_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(int_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPM4Fsb3HDIO",
        "outputId": "0bc0f725-1a4c-4ac6-b4cf-492c363ee15e"
      },
      "id": "IPM4Fsb3HDIO",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integer_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "woxfrJVxY9Va",
        "outputId": "cbe3dab5-8331-472c-eb26-bf81ee6b761f"
      },
      "id": "woxfrJVxY9Va",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataloaders"
      ],
      "metadata": {
        "id": "ruWPTFpWgiKO"
      },
      "id": "ruWPTFpWgiKO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Build the training dataset as in PyTorch `DataLoader`.\n",
        "\n",
        "Ideally, the model (as `keras.Model`) should be instantiated as a PyTorch `Module` in PyTorch backend."
      ],
      "metadata": {
        "id": "o8_fLUlbjbEn"
      },
      "id": "o8_fLUlbjbEn"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "ShVn_fXNTFy1"
      },
      "id": "ShVn_fXNTFy1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the LSTM Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "ItsoiY3OY1Ve"
      },
      "id": "ItsoiY3OY1Ve"
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Rewrite the code to build the model: **Protein sequence LSTM Variational AutoEncoder (VAE)**\n",
        "\n",
        "Write it in Keras 3 as subclass of `keras.Model` to handle variable length sequences (and missing characters).\n",
        "\n",
        "Sources:\n",
        "- VAE in Keras 3: https://keras.io/examples/generative/vae/\n",
        "- LSTM Autoencoder: https://machinelearningmastery.com/lstm-autoencoders/\n",
        "- Variable length: https://machinelearningmastery.com/handle-missing-timesteps-sequence-prediction-problems-python/\n"
      ],
      "metadata": {
        "id": "4AKZbyCahwZ6"
      },
      "id": "4AKZbyCahwZ6"
    },
    {
      "cell_type": "code",
      "source": [
        "# an example lstm vae\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, RepeatVector, Masking\n",
        "from keras.layers import Flatten, Dense, Dropout, Lambda\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras import losses\n",
        "\n",
        "\n",
        "def create_lstm_vae(input_dim,\n",
        "    timesteps,\n",
        "    batch_size,\n",
        "    intermediate_dim,\n",
        "    latent_dim,\n",
        "    epsilon_std=1.):\n",
        "\n",
        "    \"\"\"\n",
        "    Creates an LSTM Variational Autoencoder (VAE). Returns VAE, Encoder, Generator.\n",
        "\n",
        "    # Arguments\n",
        "        input_dim: int.\n",
        "        timesteps: int, input timestep dimension.\n",
        "        batch_size: int.\n",
        "        intermediate_dim: int, output shape of LSTM.\n",
        "        latent_dim: int, latent z-layer shape.\n",
        "        epsilon_std: float, z-layer sigma.\n",
        "    \"\"\"\n",
        "    x = Input(shape=(timesteps, input_dim,))\n",
        "    masked_inputs = Masking(mask_value=0.0)(x)  # Assuming 0.0 is the mask value\n",
        "\n",
        "    # LSTM encoding\n",
        "    h = LSTM(intermediate_dim)(masked_inputs)\n",
        "\n",
        "    # VAE Z layer\n",
        "    z_mean = Dense(latent_dim)(h)\n",
        "    z_log_sigma = Dense(latent_dim)(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_sigma = args\n",
        "        epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                                  mean=0., stddev=epsilon_std)\n",
        "        return z_mean + z_log_sigma * epsilon\n",
        "\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    # so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
        "\n",
        "    # decoded LSTM layer\n",
        "    decoder_h = LSTM(intermediate_dim, return_sequences=True)\n",
        "    decoder_mean = LSTM(input_dim, return_sequences=True)\n",
        "\n",
        "    h_decoded = RepeatVector(timesteps)(z)\n",
        "    h_decoded = decoder_h(h_decoded)\n",
        "\n",
        "    # decoded layer\n",
        "    x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "    # end-to-end autoencoder\n",
        "    vae = Model(x, x_decoded_mean)\n",
        "\n",
        "    # encoder, from inputs to latent space\n",
        "    encoder = Model(x, z_mean)\n",
        "\n",
        "    # generator, from latent space to reconstructed inputs\n",
        "    decoder_input = Input(shape=(latent_dim,))\n",
        "\n",
        "    _h_decoded = RepeatVector(timesteps)(decoder_input)\n",
        "    _h_decoded = decoder_h(_h_decoded)\n",
        "\n",
        "    _x_decoded_mean = decoder_mean(_h_decoded)\n",
        "    generator = Model(decoder_input, _x_decoded_mean)\n",
        "\n",
        "    def vae_loss(x, x_decoded_mean):\n",
        "        xent_loss = losses.mse(x, x_decoded_mean)\n",
        "        kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
        "        loss = xent_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
        "\n",
        "    return vae, encoder, generator"
      ],
      "metadata": {
        "id": "ljF7ULcIjfSL"
      },
      "id": "ljF7ULcIjfSL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LJ67OFHcMxia"
      },
      "id": "LJ67OFHcMxia"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kOEE1_2lIkX"
      },
      "id": "1kOEE1_2lIkX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}