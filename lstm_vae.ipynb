{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mLxnQ-qHr",
        "outputId": "ec089380-b8ec-4b85-b526-834344b1176c"
      },
      "id": "3i2mLxnQ-qHr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "!pip install Bio --quiet\n",
        "!pip install keras==3.0.0 --upgrade --quiet"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.275033900Z",
          "start_time": "2023-10-29T05:21:04.751989100Z"
        },
        "id": "1373a93c978d2fb5"
      },
      "id": "1373a93c978d2fb5"
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import keras\n",
        "from keras import backend as K, layers, activations\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "SQQNsD3Dfz7z"
      },
      "id": "SQQNsD3Dfz7z",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nphKeyspBbHX",
        "outputId": "b57d1fe4-2eec-4732-a9b1-4b6879819aa9"
      },
      "id": "nphKeyspBbHX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9Mcj8HqXRo",
        "outputId": "4d6d4b3f-fed6-455d-c374-bf0379564a91"
      },
      "id": "vR9Mcj8HqXRo",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "nTavCEWq6jXX"
      },
      "id": "nTavCEWq6jXX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "du6GuldEgp52"
      },
      "id": "du6GuldEgp52"
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "folder_path = 'drive/MyDrive/ae_training'\n",
        "file_name1 = f'{folder_path}/card1_1273x130.fasta'\n",
        "file_name2 = f'{folder_path}/drsm1_1376x177.fasta'\n",
        "file_name3 = f'{folder_path}/rd1_935x221.fasta'\n",
        "file_name4 = f'{folder_path}/drsm3_718x103_testing.fasta'\n",
        "\n",
        "amino_acids_str = ' ACDEFGHIKLMNPQRSTVWY-'\n",
        "amino_acids = [' ', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "               'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
        "\n",
        "onehot_encoder = OneHotEncoder(categories=[amino_acids])\n",
        "onehot_encoder.fit(np.array(list(amino_acids_str)).reshape(-1, 1))\n",
        "\n",
        "# Hyperparameters\n",
        "max_len = 221\n",
        "num_epochs = 30\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "5Yjt2lUQwFGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9e4c4a-6c46-4d05-8e5c-c5b10aebb404"
      },
      "id": "5Yjt2lUQwFGV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def parse_fasta(file_path) -> list:\n",
        "    \"Parse a fasta file into an array of Seq\"\n",
        "    sequences = []\n",
        "    with open(file_path, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(record.seq)\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def integer_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of integers\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    encoding = [amino_acids.index(aa) for aa in sequence]\n",
        "    # Pad the sequence to the specified maximum length\n",
        "    if len(encoding) < max_length:\n",
        "        encoding += [0] * (max_length - len(encoding))\n",
        "    return torch.tensor(encoding).reshape(-1, 1)\n",
        "\n",
        "\n",
        "def integer_decode(int_seq) -> str:\n",
        "    \"Decode an integer encoded sequence back to a sequence of amino acids\"\n",
        "    # Convert the torch tensor to a list of integers\n",
        "    encoded_list = int_seq.flatten().tolist()\n",
        "    # Decode each integer back to the corresponding amino acid\n",
        "    decoded_sequence = ''.join([amino_acids[i] for i in encoded_list])\n",
        "    return decoded_sequence\n",
        "\n",
        "\n",
        "def onehot_encode(sequence, max_length) -> torch.tensor:\n",
        "    \"Encode a protein sequence into a sequence of one-hot vectors\"\n",
        "    sequence = sequence.replace('X', '-')  # X also means missing\n",
        "    # Pad the sequence with whitespaces\n",
        "    padding = ' ' * (max_length - len(sequence))\n",
        "    sequence += padding\n",
        "    protein_sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
        "    one_hot_encoded_sequence = onehot_encoder.transform(protein_sequence_array)\n",
        "    one_hot_encoded_array = one_hot_encoded_sequence.toarray()\n",
        "    return torch.tensor(one_hot_encoded_array)  # Whitespace is [1,0,...,0] for now\n",
        "\n",
        "\n",
        "def onehot_decode(onehot_seq: torch.tensor) -> str:\n",
        "    \"Decode a one-hot encoded sequence back to a sequence of amino acids\"\n",
        "    original_seq = onehot_encoder.inverse_transform(onehot_seq)\n",
        "    s = [''.join(c) for c in original_seq]\n",
        "    return ''.join(s)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.319409200Z",
          "start_time": "2023-10-29T05:21:08.296000400Z"
        },
        "id": "2525961040f75438"
      },
      "id": "2525961040f75438"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "onehot_encoded_sequences = [onehot_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(onehot_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:09.164320800Z",
          "start_time": "2023-10-29T05:21:08.311283200Z"
        },
        "id": "55bb307a28da7571",
        "outputId": "e2482e32-e766-4a2f-cf76-9d5dab6aecc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55bb307a28da7571"
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]  # onehot encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIVmYtGNyIf",
        "outputId": "23e01a65-019d-4cea-c0fd-7fa38f062323"
      },
      "id": "NaIVmYtGNyIf",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        ...,\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yfhfB6K4PVIq",
        "outputId": "7e4ed630-d680-4962-f468-3458adb89942"
      },
      "id": "yfhfB6K4PVIq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = parse_fasta(file_name1)\n",
        "int_encoded_sequences = [integer_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(int_encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPM4Fsb3HDIO",
        "outputId": "01c6f830-cbad-469d-cf32-9b703489d0e0"
      },
      "id": "IPM4Fsb3HDIO",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 221, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integer_decode(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "woxfrJVxY9Va",
        "outputId": "0c76bb31-d7db-4299-c2db-17af53f7142e"
      },
      "id": "woxfrJVxY9Va",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------------KNDPWDVLKNSAM-K---VLKDFCDDLIEQDV-FNQNEIKNMGKQ----LSTVKDK--SEDLVKIVTHK-GSQ-IG---DIFVKRV--LM-------AAK--QLHS---------                                                                                           '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences1 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "sequences2 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "sequences3 = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "\n",
        "data = torch.cat((sequences1, sequences2, sequences3))\n",
        "# data.shape\n",
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPbKvpm_iShN",
        "outputId": "9f792cfc-2553-45b3-a1c2-1dafe2d1b797"
      },
      "id": "vPbKvpm_iShN",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataloaders"
      ],
      "metadata": {
        "id": "ruWPTFpWgiKO"
      },
      "id": "ruWPTFpWgiKO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the training dataset as in PyTorch `DataLoader`.\n",
        "\n",
        "Ideally, the model (as `keras.Model`) should be instantiated as a PyTorch `Module` in PyTorch backend."
      ],
      "metadata": {
        "id": "o8_fLUlbjbEn"
      },
      "id": "o8_fLUlbjbEn"
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.encoding = onehot_encode\n",
        "\n",
        "        sequences1 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name1)])[:,:,1:]\n",
        "        sequences2 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name2)])[:,:,1:]\n",
        "        sequences3 = torch.stack([self.encoding(seq, max_len) for seq in parse_fasta(file_name3)])[:,:,1:]\n",
        "        self.data = torch.cat((sequences1, sequences2, sequences3))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = torch.stack([onehot_encode(seq, max_len) for seq in parse_fasta(file_name4)])[:,:,1:]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "ShVn_fXNTFy1"
      },
      "id": "ShVn_fXNTFy1",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch Datasets\n",
        "train_dataset = TrainDataset()\n",
        "val_dataset = TestDataset()\n",
        "\n",
        "# Create DataLoaders for the Datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c-3Hl4NElUe4"
      },
      "id": "c-3Hl4NElUe4",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the LSTM Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "ItsoiY3OY1Ve"
      },
      "id": "ItsoiY3OY1Ve"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rewrite the code to build the model: **Protein sequence LSTM Variational AutoEncoder (VAE)**\n",
        "\n",
        "Write it in Keras 3 as subclass of `keras.Model` to handle variable length sequences (and missing characters).\n",
        "\n",
        "Sources:\n",
        "- VAE in Keras 3: https://keras.io/examples/generative/vae/\n",
        "- LSTM Autoencoder: https://machinelearningmastery.com/lstm-autoencoders/\n",
        "- Variable length: https://machinelearningmastery.com/handle-missing-timesteps-sequence-prediction-problems-python/\n"
      ],
      "metadata": {
        "id": "4AKZbyCahwZ6"
      },
      "id": "4AKZbyCahwZ6"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KZcoro0Zu9-A"
      },
      "id": "KZcoro0Zu9-A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling layer"
      ],
      "metadata": {
        "id": "AZq4z0JnvBa2"
      },
      "id": "AZq4z0JnvBa2"
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"Uses (z_mean, z_log_var) to sample z, the vector encoding a sequence.\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = keras.ops.shape(z_mean)[0]\n",
        "        dim = keras.ops.shape(z_mean)[1]\n",
        "        epsilon = keras.random.normal(shape=(batch, dim))\n",
        "        return z_mean + keras.ops.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "F2UKmYnRqiW0"
      },
      "id": "F2UKmYnRqiW0",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "K-OeJWfDvX-t"
      },
      "id": "K-OeJWfDvX-t"
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64\n",
        "# input_shape = (max_len, 1)  # (max_len, 1) for integer encoding\n",
        "input_shape = (max_len, 21)  # (max_len, 21) for one-hot encoding\n",
        "\n",
        "encoder_inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Masking(mask_value=0.0)(encoder_inputs)\n",
        "z_mean = layers.LSTM(latent_dim, activation='relu',\n",
        "                     input_shape=input_shape, name=\"z_mean\")(x)\n",
        "z_log_var = layers.LSTM(latent_dim, activation='relu',\n",
        "                        input_shape=input_shape, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "wwthT3fRvcoK",
        "outputId": "032022e4-663d-447e-9328-b79ef63065a4"
      },
      "id": "wwthT3fRvcoK",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (\u001b[38;5;33mAny\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mLSTM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m22,016\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (\u001b[38;5;33mSampling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n",
              "│                           │                        │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n",
              "│                           │                        │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,032\u001b[0m (172.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> (172.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "KRsFMEjV2cwN"
      },
      "id": "KRsFMEjV2cwN"
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.RepeatVector(max_len)(latent_inputs)\n",
        "x = layers.LSTM(latent_dim, activation='relu', return_sequences=True)(x)\n",
        "decoder_outputs = layers.TimeDistributed(layers.Dense(21))(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "RyVG3dRg2ejP",
        "outputId": "196be4bc-0847-4fbc-a1be-917e8371bd29"
      },
      "id": "RyVG3dRg2ejP",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │      \u001b[38;5;34m33,024\u001b[0m │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m221\u001b[0m, \u001b[38;5;34m21\u001b[0m)               │       \u001b[38;5;34m1,365\u001b[0m │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │      <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,365</span> │\n",
              "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,389\u001b[0m (134.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,389</span> (134.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,389\u001b[0m (134.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,389</span> (134.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Model"
      ],
      "metadata": {
        "id": "hFntz4ZJ5trY"
      },
      "id": "hFntz4ZJ5trY"
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]"
      ],
      "metadata": {
        "id": "mob3gBeT5BMS"
      },
      "id": "mob3gBeT5BMS",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LJ67OFHcMxia"
      },
      "id": "LJ67OFHcMxia"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder, decoder).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    for i, x in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        x = x.to(device)\n",
        "        z_mean, z_log_var, z = model.encoder(x)\n",
        "        reconstruction = model.decoder(z)\n",
        "\n",
        "        # Compute reconstruction loss and kl divergence\n",
        "        # x = activations.sigmoid(x / 4)\n",
        "        # reconstruction = activations.sigmoid(reconstruction / 4)\n",
        "        # print(reconstruction)\n",
        "\n",
        "        reconstruction_loss = keras.ops.mean(\n",
        "            keras.ops.sum(\n",
        "                keras.losses.binary_crossentropy(x, reconstruction),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "        kl_loss = -0.5 * (1 + z_log_var - keras.ops.square(z_mean) - keras.ops.exp(z_log_var))\n",
        "        kl_loss = keras.ops.mean(keras.ops.sum(kl_loss, axis=1))\n",
        "\n",
        "        # Backprop and optimize\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_dataloader), reconstruction_loss.item(), kl_loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu-aFtsi_aR8",
        "outputId": "9675a411-a9fb-4742-caec-3119c0931de0"
      },
      "id": "yu-aFtsi_aR8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/30], Step [10/28], Reconst Loss: 796.1511, KL Div: 0.1215\n",
            "Epoch[1/30], Step [20/28], Reconst Loss: 645.0278, KL Div: 0.1289\n",
            "Epoch[2/30], Step [10/28], Reconst Loss: 536.7051, KL Div: 0.1370\n",
            "Epoch[2/30], Step [20/28], Reconst Loss: 489.1587, KL Div: 0.1347\n",
            "Epoch[3/30], Step [10/28], Reconst Loss: 483.3050, KL Div: 0.1339\n",
            "Epoch[3/30], Step [20/28], Reconst Loss: 415.3433, KL Div: 0.1350\n",
            "Epoch[4/30], Step [10/28], Reconst Loss: 341.9256, KL Div: 0.1360\n",
            "Epoch[4/30], Step [20/28], Reconst Loss: 348.0709, KL Div: 0.1344\n",
            "Epoch[5/30], Step [10/28], Reconst Loss: 277.3434, KL Div: 0.1289\n",
            "Epoch[5/30], Step [20/28], Reconst Loss: 309.0907, KL Div: 0.1323\n",
            "Epoch[6/30], Step [10/28], Reconst Loss: 303.1607, KL Div: 0.1304\n",
            "Epoch[6/30], Step [20/28], Reconst Loss: 259.0059, KL Div: 0.1386\n",
            "Epoch[7/30], Step [10/28], Reconst Loss: 269.4931, KL Div: 0.1342\n",
            "Epoch[7/30], Step [20/28], Reconst Loss: 254.0221, KL Div: 0.1338\n",
            "Epoch[8/30], Step [10/28], Reconst Loss: 210.8120, KL Div: 0.1301\n",
            "Epoch[8/30], Step [20/28], Reconst Loss: 190.7527, KL Div: 0.1304\n",
            "Epoch[9/30], Step [10/28], Reconst Loss: 211.2030, KL Div: 0.1382\n",
            "Epoch[9/30], Step [20/28], Reconst Loss: 199.8968, KL Div: 0.1376\n",
            "Epoch[10/30], Step [10/28], Reconst Loss: 191.4024, KL Div: 0.1337\n",
            "Epoch[10/30], Step [20/28], Reconst Loss: 213.2086, KL Div: 0.1401\n",
            "Epoch[11/30], Step [10/28], Reconst Loss: 190.1422, KL Div: 0.1285\n",
            "Epoch[11/30], Step [20/28], Reconst Loss: 167.1606, KL Div: 0.1345\n",
            "Epoch[12/30], Step [10/28], Reconst Loss: 175.0820, KL Div: 0.1339\n",
            "Epoch[12/30], Step [20/28], Reconst Loss: 189.9550, KL Div: 0.1358\n",
            "Epoch[13/30], Step [10/28], Reconst Loss: 170.4796, KL Div: 0.1335\n",
            "Epoch[13/30], Step [20/28], Reconst Loss: 151.1854, KL Div: 0.1292\n",
            "Epoch[14/30], Step [10/28], Reconst Loss: 166.4020, KL Div: 0.1335\n",
            "Epoch[14/30], Step [20/28], Reconst Loss: 154.0341, KL Div: 0.1389\n",
            "Epoch[15/30], Step [10/28], Reconst Loss: 161.0072, KL Div: 0.1302\n",
            "Epoch[15/30], Step [20/28], Reconst Loss: 164.3614, KL Div: 0.1314\n",
            "Epoch[16/30], Step [10/28], Reconst Loss: 138.5009, KL Div: 0.1372\n",
            "Epoch[16/30], Step [20/28], Reconst Loss: 160.0312, KL Div: 0.1352\n",
            "Epoch[17/30], Step [10/28], Reconst Loss: 172.2480, KL Div: 0.1344\n",
            "Epoch[17/30], Step [20/28], Reconst Loss: 156.2125, KL Div: 0.1263\n",
            "Epoch[18/30], Step [10/28], Reconst Loss: 142.2052, KL Div: 0.1252\n",
            "Epoch[18/30], Step [20/28], Reconst Loss: 145.0122, KL Div: 0.1347\n",
            "Epoch[19/30], Step [10/28], Reconst Loss: 139.3967, KL Div: 0.1226\n",
            "Epoch[19/30], Step [20/28], Reconst Loss: 127.2339, KL Div: 0.1321\n",
            "Epoch[20/30], Step [10/28], Reconst Loss: 135.0866, KL Div: 0.1310\n",
            "Epoch[20/30], Step [20/28], Reconst Loss: 129.9467, KL Div: 0.1385\n",
            "Epoch[21/30], Step [10/28], Reconst Loss: 121.2588, KL Div: 0.1386\n",
            "Epoch[21/30], Step [20/28], Reconst Loss: 119.0747, KL Div: 0.1353\n",
            "Epoch[22/30], Step [10/28], Reconst Loss: 127.4964, KL Div: 0.1342\n",
            "Epoch[22/30], Step [20/28], Reconst Loss: 125.8831, KL Div: 0.1368\n",
            "Epoch[23/30], Step [10/28], Reconst Loss: 124.0097, KL Div: 0.1344\n",
            "Epoch[23/30], Step [20/28], Reconst Loss: 118.6828, KL Div: 0.1329\n",
            "Epoch[24/30], Step [10/28], Reconst Loss: 107.0826, KL Div: 0.1351\n",
            "Epoch[24/30], Step [20/28], Reconst Loss: 111.2411, KL Div: 0.1264\n",
            "Epoch[25/30], Step [10/28], Reconst Loss: 124.6725, KL Div: 0.1345\n",
            "Epoch[25/30], Step [20/28], Reconst Loss: 115.4298, KL Div: 0.1369\n",
            "Epoch[26/30], Step [10/28], Reconst Loss: 117.7163, KL Div: 0.1353\n",
            "Epoch[26/30], Step [20/28], Reconst Loss: 113.0794, KL Div: 0.1324\n",
            "Epoch[27/30], Step [10/28], Reconst Loss: 119.7039, KL Div: 0.1293\n",
            "Epoch[27/30], Step [20/28], Reconst Loss: 127.1617, KL Div: 0.1306\n",
            "Epoch[28/30], Step [10/28], Reconst Loss: 115.9675, KL Div: 0.1339\n",
            "Epoch[28/30], Step [20/28], Reconst Loss: 112.2525, KL Div: 0.1323\n",
            "Epoch[29/30], Step [10/28], Reconst Loss: 113.5426, KL Div: 0.1373\n",
            "Epoch[29/30], Step [20/28], Reconst Loss: 117.6938, KL Div: 0.1349\n",
            "Epoch[30/30], Step [10/28], Reconst Loss: 103.6776, KL Div: 0.1298\n",
            "Epoch[30/30], Step [20/28], Reconst Loss: 103.1773, KL Div: 0.1388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and load only the model parameters (recommended).\n",
        "torch.save(model.state_dict(), f'{folder_path}/params.ckpt')"
      ],
      "metadata": {
        "id": "BFFUISOOhLFx"
      },
      "id": "BFFUISOOhLFx",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VAE(encoder, decoder).to(device)\n",
        "# model.load_state_dict(torch.load(f'{folder_path}/params.ckpt'))"
      ],
      "metadata": {
        "id": "CcJBt_aNhlEG"
      },
      "id": "CcJBt_aNhlEG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}