{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mLxnQ-qHr",
        "outputId": "d9ec5370-41f5-4808-d0df-74750ddd41f6"
      },
      "id": "3i2mLxnQ-qHr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.4/279.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install Bio --quiet\n",
        "from Bio import SeqIO"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.275033900Z",
          "start_time": "2023-10-29T05:21:04.751989100Z"
        },
        "id": "1373a93c978d2fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b8124b-120c-4620-df5c-ddf861737a8f"
      },
      "id": "1373a93c978d2fb5"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==3.0.0 --upgrade --quiet\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch\n",
        "import keras\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQQNsD3Dfz7z",
        "outputId": "b00a06ea-b6f6-49d0-a034-d62e7e9f6119"
      },
      "id": "SQQNsD3Dfz7z",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/997.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/997.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/997.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m788.5/997.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m993.3/997.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "nTavCEWq6jXX"
      },
      "id": "nTavCEWq6jXX"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "def parse_fasta(file_path):\n",
        "    sequences = []\n",
        "    with open(file_path, 'r') as fasta_file:\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(record.seq)\n",
        "    return sequences\n",
        "\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY-'\n",
        "\n",
        "def integer_encode(sequence, max_length):\n",
        "    sequence = sequence.replace('X', '-')\n",
        "    encoding = [amino_acids.index(aa) for aa in sequence]\n",
        "    # Pad the sequence to the specified maximum length\n",
        "    if len(encoding) < max_length:\n",
        "        encoding += [0] * (max_length - len(encoding))\n",
        "    return torch.tensor(encoding)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:08.319409200Z",
          "start_time": "2023-10-29T05:21:08.296000400Z"
        },
        "id": "2525961040f75438"
      },
      "id": "2525961040f75438"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1273, 440])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "folder_path = 'drive/MyDrive/ae_training'\n",
        "file_name = f'{folder_path}/card1_1273x130.fasta'\n",
        "max_len = 440\n",
        "\n",
        "sequences = parse_fasta(file_name)\n",
        "encoded_sequences = [integer_encode(seq, max_len) for seq in sequences]\n",
        "data = torch.stack(encoded_sequences)\n",
        "data.shape"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-29T05:21:09.164320800Z",
          "start_time": "2023-10-29T05:21:08.311283200Z"
        },
        "id": "55bb307a28da7571",
        "outputId": "d0f29b1e-0d2b-4ad1-ee86-d9e184ed609d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55bb307a28da7571"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the autoencoder"
      ],
      "metadata": {
        "id": "ItsoiY3OY1Ve"
      },
      "id": "ItsoiY3OY1Ve"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, RepeatVector, Masking\n",
        "from keras.layers import Flatten, Dense, Dropout, Lambda\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras import losses\n",
        "\n",
        "\n",
        "def create_lstm_vae(input_dim,\n",
        "    timesteps,\n",
        "    batch_size,\n",
        "    intermediate_dim,\n",
        "    latent_dim,\n",
        "    epsilon_std=1.):\n",
        "\n",
        "    \"\"\"\n",
        "    Creates an LSTM Variational Autoencoder (VAE). Returns VAE, Encoder, Generator.\n",
        "\n",
        "    # Arguments\n",
        "        input_dim: int.\n",
        "        timesteps: int, input timestep dimension.\n",
        "        batch_size: int.\n",
        "        intermediate_dim: int, output shape of LSTM.\n",
        "        latent_dim: int, latent z-layer shape.\n",
        "        epsilon_std: float, z-layer sigma.\n",
        "    \"\"\"\n",
        "    x = Input(shape=(timesteps, input_dim,))\n",
        "    masked_inputs = Masking(mask_value=0.0)(x)  # Assuming 0.0 is the mask value\n",
        "\n",
        "    # LSTM encoding\n",
        "    h = LSTM(intermediate_dim)(masked_inputs)\n",
        "\n",
        "    # VAE Z layer\n",
        "    z_mean = Dense(latent_dim)(h)\n",
        "    z_log_sigma = Dense(latent_dim)(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_sigma = args\n",
        "        epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                                  mean=0., stddev=epsilon_std)\n",
        "        return z_mean + z_log_sigma * epsilon\n",
        "\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    # so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
        "\n",
        "    # decoded LSTM layer\n",
        "    decoder_h = LSTM(intermediate_dim, return_sequences=True)\n",
        "    decoder_mean = LSTM(input_dim, return_sequences=True)\n",
        "\n",
        "    h_decoded = RepeatVector(timesteps)(z)\n",
        "    h_decoded = decoder_h(h_decoded)\n",
        "\n",
        "    # decoded layer\n",
        "    x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "    # end-to-end autoencoder\n",
        "    vae = Model(x, x_decoded_mean)\n",
        "\n",
        "    # encoder, from inputs to latent space\n",
        "    encoder = Model(x, z_mean)\n",
        "\n",
        "    # generator, from latent space to reconstructed inputs\n",
        "    decoder_input = Input(shape=(latent_dim,))\n",
        "\n",
        "    _h_decoded = RepeatVector(timesteps)(decoder_input)\n",
        "    _h_decoded = decoder_h(_h_decoded)\n",
        "\n",
        "    _x_decoded_mean = decoder_mean(_h_decoded)\n",
        "    generator = Model(decoder_input, _x_decoded_mean)\n",
        "\n",
        "    def vae_loss(x, x_decoded_mean):\n",
        "        xent_loss = losses.mse(x, x_decoded_mean)\n",
        "        kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
        "        loss = xent_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
        "\n",
        "    return vae, encoder, generator"
      ],
      "metadata": {
        "id": "Jp-Sx8WGQ7Kx"
      },
      "id": "Jp-Sx8WGQ7Kx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LJ67OFHcMxia"
      },
      "id": "LJ67OFHcMxia"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kOEE1_2lIkX"
      },
      "id": "1kOEE1_2lIkX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}